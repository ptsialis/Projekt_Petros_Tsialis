;name_of_the_features;id_of_the_features;name_of_the_dataset;datatype_of_the_feature;dataset_min_value;dataset_max_value;data_descr;chat_gpt_just_feature;chat_gpt_all_feature;chat_gpt_desc_feature;just_feature_min_value;just_feature_max_value;all_feature_min_value;all_feature_max_value;all_feature_min_value_desc;all_feature_max_value_desc
0;RIDGE;871;pollen;numeric;-23.2839;21.4066;"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').";;"Minimum: 0.5
Maximum: 10.0";The range of values for the feature RIDGE is unknown as it is not provided in the dataset description.;;;0.5;10.0;;
1;NUB;871;pollen;numeric;-16.3935;17.2583;"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').";;"Minimum: 0
Maximum: 1";"The range of values for the feature ""NUB"" is not provided in the dataset description.";;;0.0;1.0;;
2;CRACK;871;pollen;numeric;-31.413;30.3178;"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').";;"Minimum: 0
Maximum: 10";The range of values for the feature CRACK in the dataset is minimum = 0 and maximum = 1.;;;0.0;10.0;0.0;1.0
3;WEIGHT;871;pollen;numeric;-34.0352;35.8028;"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').";;"Minimum: Unknown
Maximum: Unknown";"Unfortunately, without access to the actual dataset or any additional information, it is not possible to determine the range of values for the feature ""WEIGHT."" The range can vary based on the specific data and its distribution.";;;;;;
4;DENSITY;871;pollen;numeric;-12.0391;10.8673;"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').";;"Minimum: 0.05
Maximum: 1.0";"Without access to the dataset, it is not possible to determine the minimum and maximum values of the feature ""DENSITY"". To obtain the desired information, the dataset should be analyzed.";;;0.05;1.0;;
5;a1;23515;sulfur;numeric;0.0;1.0;"&quot;The sulfur recovery unit (SRU) removes environmental pollutants from acid gas
streams before they are released into the atmosphere. Furthermore, elemental sulfur
is recovered as a valuable by-product.&quot;

5 inputs variables are gas and air flows.
2 outputs to predict are H2S and SO2 concentrations

See Appendix A.5 of Fortuna, L., Graziani, S., Rizzo, A., Xibilia, M.G. &quot;Soft Sensors for Monitoring and Control of Industrial Processes&quot; (Springer 2007) for more info.";;"Minimum: Unknown
Maximum: Unknown";"The range of values for feature a1 is not provided in the given information. Please refer to Appendix A.5 of the book ""Soft Sensors for Monitoring and Control of Industrial Processes"" by Fortuna et al. for more detailed information about the dataset.";;;;;1.0;0.5
6;a2;23515;sulfur;numeric;0.0;1.0;"&quot;The sulfur recovery unit (SRU) removes environmental pollutants from acid gas
streams before they are released into the atmosphere. Furthermore, elemental sulfur
is recovered as a valuable by-product.&quot;

5 inputs variables are gas and air flows.
2 outputs to predict are H2S and SO2 concentrations

See Appendix A.5 of Fortuna, L., Graziani, S., Rizzo, A., Xibilia, M.G. &quot;Soft Sensors for Monitoring and Control of Industrial Processes&quot; (Springer 2007) for more info.";;minimum: unknown, maximum: unknown.;The range of values for the feature a2 is not provided in the given dataset.;;;;;;
7;a3;23515;sulfur;numeric;0.0;1.0;"&quot;The sulfur recovery unit (SRU) removes environmental pollutants from acid gas
streams before they are released into the atmosphere. Furthermore, elemental sulfur
is recovered as a valuable by-product.&quot;

5 inputs variables are gas and air flows.
2 outputs to predict are H2S and SO2 concentrations

See Appendix A.5 of Fortuna, L., Graziani, S., Rizzo, A., Xibilia, M.G. &quot;Soft Sensors for Monitoring and Control of Industrial Processes&quot; (Springer 2007) for more info.";;"Minimum: Unknown
Maximum: Unknown";Based on the information provided the range of values for the feature a3 is not given.;;;;;;
8;a4;23515;sulfur;numeric;0.0;1.0;"&quot;The sulfur recovery unit (SRU) removes environmental pollutants from acid gas
streams before they are released into the atmosphere. Furthermore, elemental sulfur
is recovered as a valuable by-product.&quot;

5 inputs variables are gas and air flows.
2 outputs to predict are H2S and SO2 concentrations

See Appendix A.5 of Fortuna, L., Graziani, S., Rizzo, A., Xibilia, M.G. &quot;Soft Sensors for Monitoring and Control of Industrial Processes&quot; (Springer 2007) for more info.";;"Minimum: Unknown
Maximum: Unknown";The minimum and maximum values for feature a4 in the dataset are not provided. Please refer to Appendix A.5 of the mentioned book for more information.;;;;;4.0;0.5
9;a5;23515;sulfur;numeric;0.0;1.0;"&quot;The sulfur recovery unit (SRU) removes environmental pollutants from acid gas
streams before they are released into the atmosphere. Furthermore, elemental sulfur
is recovered as a valuable by-product.&quot;

5 inputs variables are gas and air flows.
2 outputs to predict are H2S and SO2 concentrations

See Appendix A.5 of Fortuna, L., Graziani, S., Rizzo, A., Xibilia, M.G. &quot;Soft Sensors for Monitoring and Control of Industrial Processes&quot; (Springer 2007) for more info.";;"Minimum: unknown
Maximum: unknown";The min and max values for the feature a5 are not given in the description or dataset provided.;;;;;;
10;y1;23515;sulfur;numeric;0.0;1.0;"&quot;The sulfur recovery unit (SRU) removes environmental pollutants from acid gas
streams before they are released into the atmosphere. Furthermore, elemental sulfur
is recovered as a valuable by-product.&quot;

5 inputs variables are gas and air flows.
2 outputs to predict are H2S and SO2 concentrations

See Appendix A.5 of Fortuna, L., Graziani, S., Rizzo, A., Xibilia, M.G. &quot;Soft Sensors for Monitoring and Control of Industrial Processes&quot; (Springer 2007) for more info.";;"Unfortunately as an AI language model I cannot access or analyze specific datasets. Therefore I cannot provide information on the range of values for the feature ""y1"" from your dataset. However you can use descriptive statistics or visualizations to determine the minimum and maximum values of ""y1"" in your dataset.";Based on the dataset the range of values for the feature y1 is not provided. Therefore without specific information it is not possible to determine the minimum and maximum values for y1.;;;1.0;1.0;1.0;1.0
11;y2;23515;sulfur;numeric;0.0;1.0;"&quot;The sulfur recovery unit (SRU) removes environmental pollutants from acid gas
streams before they are released into the atmosphere. Furthermore, elemental sulfur
is recovered as a valuable by-product.&quot;

5 inputs variables are gas and air flows.
2 outputs to predict are H2S and SO2 concentrations

See Appendix A.5 of Fortuna, L., Graziani, S., Rizzo, A., Xibilia, M.G. &quot;Soft Sensors for Monitoring and Control of Industrial Processes&quot; (Springer 2007) for more info.";"Minimum: -10
Maximum: 10";"Minimum: Unknown
Maximum: Unknown";Based on the information provided the range of values for feature y2 cannot be determined without access to the dataset.;-10.0;10.0;;;;
12;productId;42183;dataset_sales;numeric;0.0;1.0;Dataset sales;"Minimum: 1000
Maximum: 9999";"Minimum: 1
Maximum: 100000";"Min: productId = 1
Max: productId = 10000";1000.0;9999.0;1.0;100000.0;1.0;10000.0
13;machineId;42183;dataset_sales;numeric;0.0;1.0;Dataset sales;"Minimum: 1
Maximum: 10000";"Minimum: 1000
Maximum: 5000";"The minimum and maximum values for the feature ""machineId"" in the dataset ""sales"" are not provided. Please provide the dataset or specific values to determine the range.";1.0;10000.0;1000.0;5000.0;;
14;temp;42183;dataset_sales;numeric;0.0;1.0;Dataset sales;temp: -10 to 40;"Minimum: -100 degrees Celsius
Maximum: 100 degrees Celsius";"The range of values for the feature ""temp"" in the sales dataset is min: [minimum value] and max: [maximum value].";-10.0;40.0;-100.0;100.0;;
15;weather_condition_id;42183;dataset_sales;numeric;0.0;1.0;Dataset sales;"Minimum: 1
Maximum: 10";"Minimum: 1
Maximum: 10";"Based on the given dataset, the range of values for the feature ""weather_condition_id"" can be displayed as follows:

Min: Minimum value observed in the ""weather_condition_id"" column of the dataset
Max: Maximum value observed in the ""weather_condition_id"" column of the dataset";1.0;10.0;1.0;10.0;;
16;isholiday;42183;dataset_sales;numeric;0.0;1.0;Dataset sales;"Minimum: 0
Maximum: 1";"Minimum: 0 (assuming 0 represents not a holiday)
Maximum: 1 (assuming 1 represents a holiday)";"The minimum and maximum values for the feature ""isholiday"" in the dataset ""sales"" are not provided in the given information.";0.0;1.0;;;;
17;daysoff;42183;dataset_sales;numeric;0.0;1.0;Dataset sales;Minimum: 0                     Maximum: 365;"Minimum: 0
Maximum: 365";"Based on the given dataset, the range of values for the feature ""daysoff"" is from the minimum value to the maximum value. However, without the actual dataset or any additional information, I cannot provide the specific minimum and maximum values.";0.0;365.0;0.0;365.0;;
18;year;42183;dataset_sales;numeric;0.0;1.0;Dataset sales;"Minimum: 2000
Maximum: 2022";Minimum: 2000 Maximum: 2025;"Based on the given dataset description, the range of values for the feature ""year"" can be represented as follows: 

min: [minimum value of year]
max: [maximum value of year]";2000.0;2022.0;2000.0;2025.0;;
19;month;42183;dataset_sales;numeric;0.0;1.0;Dataset sales;"Minimum: January
Maximum: December";"Minimum: 1
Maximum: 12";"min(month): 1
max(month): 12";;;1.0;12.0;1.0;12.0
20;day;42183;dataset_sales;numeric;0.0;1.0;Dataset sales;"Minimum: 1
Maximum: 31";"Minimum: 1
Maximum: 31";"The minimum and maximum values for the feature ""day"" in the sales dataset are not provided. Please provide the dataset or specify the exact range of values in order to determine the minimum and maximum.";1.0;31.0;1.0;31.0;;
21;week_day;42183;dataset_sales;numeric;0.0;1.0;Dataset sales;"Dataset: 

week_day: [1 2 3 4 5 6 7]

Minimum: 1
Maximum: 7";"Minimum: 1
Maximum: 7";"min: Monday
max: Sunday";;;1.0;7.0;;
22;avail0;42183;dataset_sales;numeric;0.0;1.0;Dataset sales;;"Minimum: 0
Maximum: 1";"For the feature ""avail0"" in the sales dataset the minimum value is X and the maximum value is Y.";;;0.0;1.0;;
23;avail1;42183;dataset_sales;numeric;0.0;1.0;Dataset sales;"Based on the available dataset the minimum and maximum values for the feature ""avail1"" cannot be determined.";"Minimum: 0
Maximum: 1";"min(avail1): 0
max(avail1): 1";;;0.0;1.0;;
24;avail2;42183;dataset_sales;numeric;0.0;1.0;Dataset sales;min: 0 max: 1;"Minimum: 0
Maximum: 1";"min: avail2 = min value in the dataset sales
max: avail2 = max value in the dataset sales";0.0;1.0;0.0;1.0;2.0;2.0
25;sales;42183;dataset_sales;numeric;3.0;85.0;Dataset sales;"Minimum: 0
Maximum: 1000000";"Minimum: 0
Maximum: Unknown";"The minimum and maximum values for the feature ""sales"" in the dataset are not provided.";0.0;1000000.0;;;;
26;stdv;42183;dataset_sales;numeric;0.0;47.0;Dataset sales;"min stdv: 0.1
max stdv: 4.5";"Minimum value: 0.0
Maximum value: 1.0";For the feature stdv the minimum value is 0 and the maximum value is not specified in the given dataset description.;0.1;4.5;0.0;1.0;;
27;qts;42545;stock_fardamento02;numeric;1.0;833.0;"**Author**:   

**Source**: Unknown - Date unknown  

**Please cite**:   



valores de saida de fardamento com temperaturas, admiss&otilde;es e demiss&otilde;es";"Minimum: 0
Maximum: 100";"Min: Unknown
Max: Unknown";"min: 0
max: unknown";0.0;100.0;;;;
28;Material;42545;stock_fardamento02;numeric;5367.0;65024.0;"**Author**:   

**Source**: Unknown - Date unknown  

**Please cite**:   



valores de saida de fardamento com temperaturas, admiss&otilde;es e demiss&otilde;es";"Min: 1
Max: 10";"Minimum: Unknown
Maximum: Unknown";"Sorry, but I can't generate a range of values for the feature ""Material"" without the actual dataset. Could you please provide the dataset or more specific information about the values in the ""Material"" feature?";1.0;10.0;;;;
29;pp;42545;stock_fardamento02;numeric;0.0;20.1;"**Author**:   

**Source**: Unknown - Date unknown  

**Please cite**:   



valores de saida de fardamento com temperaturas, admiss&otilde;es e demiss&otilde;es";Range: 0 to 1000;"Minimum: unknown
Maximum: unknown";pp: min = Unknown, max = Unknown;0.0;1000.0;;;;
30;TEMP;42545;stock_fardamento02;numeric;8.4;26.0;"**Author**:   

**Source**: Unknown - Date unknown  

**Please cite**:   



valores de saida de fardamento com temperaturas, admiss&otilde;es e demiss&otilde;es";"Minimum: -10°C
Maximum: 40°C";The range of values for the feature TEMP in the dataset is unknown.;TEMP: min = unknown, max = unknown;-10.0;40.0;;;;
31;adm;42545;stock_fardamento02;numeric;28.0;230.0;"**Author**:   

**Source**: Unknown - Date unknown  

**Please cite**:   



valores de saida de fardamento com temperaturas, admiss&otilde;es e demiss&otilde;es";"Minimum: 0
Maximum: 100";"Minimum: Unknown
Maximum: Unknown";"The range of values for the feature ""adm"" is minimum: unknown and maximum: unknown.";0.0;100.0;;;;
32;Dem;42545;stock_fardamento02;numeric;36.0;239.0;"**Author**:   

**Source**: Unknown - Date unknown  

**Please cite**:   



valores de saida de fardamento com temperaturas, admiss&otilde;es e demiss&otilde;es";"Min: 0 
Max: 100";min(Dem) = ???, max(Dem) = ???;"The range of values for the feature ""Dem"" is not provided in the dataset description.";0.0;100.0;;;;
33;1990;43809;GDP-per-capita-all-countries;numeric;424.823989;72906.52012;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: unknown
Maximum: unknown";1990: [unknown minimum value, unknown maximum value];"To set a range of values for the feature ""1990"" from the dataset we need the actual values of the feature. Unfortunately the values are not provided in the dataset description. Without the values it is not possible to determine the minimum and maximum values for the feature ""1990"".";;;;;1990.0;1990.0
34;1991;43809;GDP-per-capita-all-countries;numeric;324.6360462;71753.72956;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 1900
Maximum: 2021";1991: Min Value = 1991 Max Value = 1991;"min: 1991
max: 2019";1900.0;2021.0;;;1991.0;2019.0
35;1992;43809;GDP-per-capita-all-countries;numeric;300.9789673;71567.82752;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum value: 0
Maximum value: 1000";"Minimum: 1992
Maximum: 1992";The dataset provides the GDP values for the year 1992. The minimum value is not mentioned but the maximum value for GDP in 1992 is not specified either.;0.0;1000.0;1992.0;1992.0;1992.0;1992.0
36;1993;43809;GDP-per-capita-all-countries;numeric;327.3411883;70082.38933;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;"Minimum: 1993
Maximum: 1993";"The range of values for the feature ""1993"" is the minimum and maximum values of the GDP based on Purchasing Power Parity (PPP) for that year in the dataset. Unfortunately without access to the actual dataset I cannot provide the specific values.";;;1993.0;1993.0;;
37;1994;43809;GDP-per-capita-all-countries;numeric;342.4329064;72471.68729;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";1994: min = 0 max = 99999999;"Minimum: 1994
Maximum: 1994";The range of values for the feature 1994 in the dataset is: min = 8.36 max = 92.28.;;;1994.0;1994.0;;
38;1995;43809;GDP-per-capita-all-countries;numeric;345.1363376;74994.38062;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 1995
Maximum: 1995";"Minimum: 1995
Maximum: 1995";"min: 1995
max: 1995";1995.0;1995.0;1995.0;1995.0;1995.0;1995.0
39;1996;43809;GDP-per-capita-all-countries;numeric;379.151098;76848.79224;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 1
Maximum: 9999";"Minimum: 1996
Maximum: 1996";"The range of values for the feature ""1996"" in the dataset is from the minimum value to the maximum value.";1.0;9999.0;1996.0;1996.0;;
40;1997;43809;GDP-per-capita-all-countries;numeric;417.8391769;80390.06411;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 1997
Maximum: 1997";1997: min = 1997 max = 1997.;"min: 1997
max: 1997";1997.0;1997.0;;;1997.0;1997.0
41;1998;43809;GDP-per-capita-all-countries;numeric;452.6620933;77421.10866;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 0
Maximum: 10000";"Minimum: 1998
Maximum: 1998";"Min: 1998
Max: 1998";0.0;10000.0;1998.0;1998.0;1998.0;1998.0
42;1999;43809;GDP-per-capita-all-countries;numeric;469.1280301;76654.25591;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Min: 1990
Max: 2010";1999: min=1999 max=1999;"The minimum and maximum values for the feature ""1999"" in the dataset are not provided.";1990.0;2010.0;;;;
43;2000;43809;GDP-per-capita-all-countries;numeric;455.8150878;86169.39432;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 1500
Maximum: 2500";"Minimum: 2000
Maximum: 2019";"The range of values for the feature 2000 from the dataset is:

Min: N/A (the dataset does not include the minimum value for this feature)
Max: N/A (the dataset does not include the maximum value for this feature)";1500.0;2500.0;2000.0;2019.0;;
44;2001;43809;GDP-per-capita-all-countries;numeric;443.5747121;88138.42244;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 1
Maximum: 3000";"Minimum: 2001 
Maximum: 2001";"The minimum and maximum values for the feature ""2001"" in the dataset are not provided.";1.0;3000.0;2001.0;2001.0;;
45;2002;43809;GDP-per-capita-all-countries;numeric;450.4504171;92091.2766;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Min: 0
Max: 100";"Minimum: 2002
Maximum: 2002";The range of values for the feature 2002 is: Min: 1.11982909933948e+12 Max: 1.08449395584598e+13;0.0;100.0;2002.0;2002.0;;
46;2003;43809;GDP-per-capita-all-countries;numeric;469.7704098;91451.60854;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";2003: Minimum value: unknown. Maximum value: unknown.;"Minimum: 2003
Maximum: 2003";"Based on the dataset provided the range of values for the feature ""2003"" would be the minimum and maximum values of the GDP for that year. Since the specific values are not given it is not possible to determine the exact range.";;;2003.0;2003.0;;
47;2004;43809;GDP-per-capita-all-countries;numeric;498.9798703;101329.4787;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;"Minimum: 2004
Maximum: 2004";"Min: 2004
Max: 2004";;;2004.0;2004.0;2004.0;2004.0
48;2005;43809;GDP-per-capita-all-countries;numeric;528.9747838;97768.57115;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 0
Maximum: 100";"Minimum: 2005
Maximum: 2005";"Min: 2005
Max: 2005";0.0;100.0;2005.0;2005.0;2005.0;2005.0
49;2006;43809;GDP-per-capita-all-countries;numeric;555.799958;107541.4558;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 0
Maximum: 1000000";"Minimum: 2006
Maximum: 2006";The min and max values for the feature 2006 from the dataset are not provided.;0.0;1000000.0;2006.0;2006.0;;
50;2007;43809;GDP-per-capita-all-countries;numeric;586.9952654;109362.5076;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 2007
Maximum: 2007";"Minimum: 2007
Maximum: 2007";"Min: 485415.9
Max: 21345493.9";2007.0;2007.0;2007.0;2007.0;485415.9;21345493.9
51;2008;43809;GDP-per-capita-all-countries;numeric;615.0719745;111255.9944;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"The minimum value for the feature ""2008"" is: unknown
The maximum value for the feature ""2008"" is: unknown";"Minimum: 2008
Maximum: 2008";"Min: 2008
Max: 2008";;;2008.0;2008.0;2008.0;2008.0
52;2009;43809;GDP-per-capita-all-countries;numeric;616.6586194;108953.6771;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 0
Maximum: 100000";"Min: 2009
Max: 2009";"Based on the given dataset the range of values for the feature ""2009"" would be the minimum and maximum values of GDP in that year. However since the dataset is not provided we cannot determine the exact range without the actual data.";0.0;100000.0;2009.0;2009.0;;
53;2010;43809;GDP-per-capita-all-countries;numeric;646.2953953;117518.7009;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 0
Maximum: 100000";2010: min = 2010 max = 2010;"Based on the given dataset description we can assume that the feature ""2010"" represents the GDP based on Purchasing Power Parity (PPP) for the year 2010. To find the range of values for this feature we need to examine the minimum and maximum values from the dataset. However since the dataset values are not provided we cannot determine the exact range.";0.0;100000.0;;;2010.0;2010.0
54;2011;43809;GDP-per-capita-all-countries;numeric;682.007332;124024.5682;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 0
Maximum: 99999";"Minimum: 2011
Maximum: 2011";Min: 2011 Max: 2011;0.0;99999.0;2011.0;2011.0;2011.0;2011.0
55;2012;43809;GDP-per-capita-all-countries;numeric;719.914259;126618.3727;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 0
Maximum: 100";"Minimum: 2012
Maximum: 2012";"The range of values for the feature ""2012"" in the dataset is from the minimum value to the maximum value. Without examining the dataset I cannot provide the exact range.";0.0;100.0;2012.0;2012.0;;
56;2013;43809;GDP-per-capita-all-countries;numeric;699.5928807;139962.1749;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Min: 0
Max: 100";"Minimum: 2013
Maximum: 2013";"The range of values for the feature ""2013"" can be shown as: min = 10 max = 4000.";0.0;100.0;2013.0;2013.0;;
57;2014;43809;GDP-per-capita-all-countries;numeric;710.8121645;137832.9615;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 0
Maximum: 100";"Minimum: 2014
Maximum: 2014";"The range of values for the feature ""2014"" in the dataset would be given by taking the minimum and maximum value of that feature. However since the dataset is not provided I am unable to provide the exact range for the feature ""2014"".";0.0;100.0;2014.0;2014.0;2014.0;2014.0
58;2015;43809;GDP-per-capita-all-countries;numeric;744.7345426;123822.0833;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 0
Maximum: 100";"Minimum: 2015
Maximum: 2015";"The range of values for the feature ""2015"" in the dataset is:

Min: 52931.7
Max: 18121268.7";0.0;100.0;2015.0;2015.0;;
59;2016;43809;GDP-per-capita-all-countries;numeric;743.9035976;123573.6308;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: Unknown
Maximum: Unknown";"Minimum: 2016
Maximum: 2016";"The range of values for the feature ""2016"" in the dataset is as follows:

Min: 0
Max: 22605228

Please note that these values are hypothetical and have been provided for demonstration purposes. The actual range of values would depend on the specific dataset being used.";;;2016.0;2016.0;;
60;2017;43809;GDP-per-capita-all-countries;numeric;737.9785829;124609.3041;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"min: 0
max: 100";"Min: 2017
Max: 2017";To set a range of values for the feature 2017 in the dataset we need to know the actual values for that feature. Unfortunately you have not provided the dataset itself or any values for 2017. If you can provide the values for the feature 2017 I can calculate the range for you.;0.0;100.0;2017.0;2017.0;;
61;2018;43809;GDP-per-capita-all-countries;numeric;744.182072;126898.4259;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"The minimum and maximum values for the feature ""2018"" cannot be determined without access to the dataset or additional information.";Min: 2018 Max: 2018;"Min: 1990
Max: 2019";;;2018.0;2018.0;1990.0;2019.0
62;2019;43809;GDP-per-capita-all-countries;numeric;;;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";"Minimum: 0
Maximum: 100000";"Min: 2019
Max: 2019";"To determine the range of values for the feature ""2019"" from the dataset we need access to the actual data. Without the data it is not possible to provide the minimum and maximum values for the feature.";0.0;100000.0;2019.0;2019.0;;
63;Unnamed:_0;43825;Nutritional-values-for-common-foods-and-products;numeric;0.0;8788.0;"Context
I found this data occasionally and I just could not pass by. So I hope that this dasatet will help anyone who interested in food nutrition values.
Content
This dataset contains nutrition values for about 8.8k types of food. The features names is very self-explanatory, so I'll not make a description for them.";"min: -∞
max: +∞";"Minimum: 0
Maximum: Unknown";"The range of values for the feature ""Unnamed:_0"" in the dataset cannot be determined without actually examining the dataset. Please provide the dataset or specific values for further assistance.";;;;;;
64;calories;43825;Nutritional-values-for-common-foods-and-products;numeric;0.0;902.0;"Context
I found this data occasionally and I just could not pass by. So I hope that this dasatet will help anyone who interested in food nutrition values.
Content
This dataset contains nutrition values for about 8.8k types of food. The features names is very self-explanatory, so I'll not make a description for them.";"Minimum: 0
Maximum: 5000";min(calories), max(calories);"The range of values for the feature ""calories"" in the dataset is from the minimum value to the maximum value.";0.0;5000.0;;;;
65;lucopene;43825;Nutritional-values-for-common-foods-and-products;numeric;0.0;0.0;"Context
I found this data occasionally and I just could not pass by. So I hope that this dasatet will help anyone who interested in food nutrition values.
Content
This dataset contains nutrition values for about 8.8k types of food. The features names is very self-explanatory, so I'll not make a description for them.";"Minimum: 0
Maximum: 5000";"Minimum: 0
Maximum: Unknown (Not provided in the dataset)";"Min: 0.0

Max: 2181.0";0.0;5000.0;;;0.0;2181.0
66;Year;43831;Consumer-Price-Index;numeric;2013.0;2020.0;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;Min: 2000 Max: 2021;"Minimum: Year 0 (assuming it starts from year 0 but could be earlier)
Maximum: Year 2021 (current year)";"Based on the provided dataset, the range of values for the feature ""Year"" would be the minimum and maximum values present in the dataset. However, without the actual dataset or specific information on the years included, it is not possible to determine the exact range.";2000.0;2021.0;;;;
67;Cereals_and_products;43831;Consumer-Price-Index;numeric;107.5;152.7;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 100";Min: 0, Max: Unlimited;"Min: 0.00 
Max: 600.00";0.0;100.0;;;0.0;600.0
68;Meat_and_fish;43831;Consumer-Price-Index;numeric;106.3;197.0;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 10000";"Minimum: 0
Maximum: Not provided";"Min: The minimum value for the feature ""Meat_and_fish"" in the dataset is not specified.

Max: The maximum value for the feature ""Meat_and_fish"" in the dataset is not specified.";0.0;10000.0;;;;
69;Egg;43831;Consumer-Price-Index;numeric;102.7;157.0;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 200";"Minimum: 0
Maximum: Unknown";"The range of values for the feature ""Egg"" in the dataset is from a minimum value to a maximum value.";0.0;200.0;;;;
70;Milk_and_products;43831;Consumer-Price-Index;numeric;103.6;155.6;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 30000";"Minimum: 0 
Maximum: Unknown";"Min: 0
Max: 100";0.0;30000.0;;;0.0;100.0
71;Oils_and_fats;43831;Consumer-Price-Index;numeric;101.1;138.2;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 40";"Minimum: 0.0
Maximum: 100.0";"The range of values for the feature ""Oils_and_fats"" is from 0 to the maximum value in the dataset.";0.0;40.0;0.0;100.0;;
72;Fruits;43831;Consumer-Price-Index;numeric;102.3;157.5;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 100";Minimum: 0, Maximum: Unknown;"The range of values for the feature ""Fruits"" is from the minimum value to the maximum value, which is not specified in the given dataset.";0.0;100.0;;;;
73;Vegetables;43831;Consumer-Price-Index;numeric;101.4;231.5;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"min: 0.5  
max: 5.0";"Minimum: 0
Maximum: Not enough information provided";"Min: 0
Max: 100";0.5;5.0;;;0.0;100.0
74;Pulses_and_products;43831;Consumer-Price-Index;numeric;103.5;191.6;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 100000";"Minimum: 0
Maximum: Cannot determine without further information.";"Min: 0
Max: unknown";0.0;100000.0;;;;
75;Sugar_and_Confectionery;43831;Consumer-Price-Index;numeric;85.3;123.9;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 100";"Minimum: 0
Maximum: Unknown";"There is insufficient information given in the dataset description to determine the range of values for the feature ""Sugar_and_Confectionery"".";0.0;100.0;;;;
76;Spices;43831;Consumer-Price-Index;numeric;101.8;159.8;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 10";"Minimum: 0
Maximum: 100";"Based on the given dataset, the range of values for the feature ""Spices"" cannot be determined without further information or access to the actual data.";0.0;10.0;0.0;100.0;;
77;Non-alcoholic_beverages;43831;Consumer-Price-Index;numeric;104.8;142.1;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 10";"Minimum: 0
Maximum: Unknown";Non-alcoholic_beverages: Min = 0 Max = Unspecified;0.0;10.0;;;;
78;Prepared_meals,_snacks,_sweets_etc.;43831;Consumer-Price-Index;numeric;106.7;161.8;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 1000";"Minimum: 0
Maximum: It is not possible to determine without further information about the dataset.";"Min: 0
Max: 100";0.0;1000.0;;;0.0;100.0
79;Food_and_beverages;43831;Consumer-Price-Index;numeric;105.5;157.0;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;Min: 0    Max: 100;"Minimum: 0
Maximum: 1";"The range of values for the feature ""Food_and_beverages"" in the dataset is from the minimum value to the maximum value. Unfortunately, without access to the actual dataset, I cannot provide the specific values for the minimum and maximum.";0.0;100.0;0.0;1.0;;
80;Pan,_tobacco_and_intoxicants;43831;Consumer-Price-Index;numeric;105.1;186.7;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 1000";"Minimum: 0
Maximum: Unknown";"The minimum value for the feature ""Pan, tobacco and intoxicants"" is not specified in the given dataset. However, the maximum value for this feature is available.";0.0;1000.0;;;;
81;Clothing;43831;Consumer-Price-Index;numeric;105.9;154.7;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 100";"Minimum: 0
Maximum: Unknown (not given in the dataset)";"Min Value: Unknown
Max Value: Unknown";0.0;100.0;;;;
82;Footwear;43831;Consumer-Price-Index;numeric;105.0;150.0;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Min: 36
Max: 48";"Minimum: 0
Maximum: Unknown";"The range of values for the feature ""Footwear"" is not provided in the dataset description.";36.0;48.0;;;;
83;Clothing_and_footwear;43831;Consumer-Price-Index;numeric;105.8;154.1;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Min: 0
Max: 1000";"Minimum: 0
Maximum: Unknown (insufficient information provided)";Clothing_and_footwear: min = 0 max = 100;0.0;1000.0;;;0.0;100.0
84;Housing;43831;Consumer-Price-Index;numeric;100.3;155.6;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;Min: 0 Max: 1;"Minimum: Unknown
Maximum: Unknown";Housing: min = 0, max = unknown;0.0;1.0;;;;
85;Fuel_and_light;43831;Consumer-Price-Index;numeric;105.4;153.4;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Based on the limited information provided, the minimum and maximum values for the feature ""Fuel_and_light"" cannot be determined.";"Minimum: 0
Maximum: Unknown (Not enough information provided)";"The range of values for the feature ""Fuel_and_light"" is not provided in the description or the dataset.";;;;;;
86;Household_goods_and_services;43831;Consumer-Price-Index;numeric;104.8;151.8;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;min: 0 max: 100000;"Minimum: 0
Maximum: Unknown/Unspecified";Household_goods_and_services: Min = 100 Max = 2000;0.0;100000.0;;;100.0;2000.0
87;Health;43831;Consumer-Price-Index;numeric;104.0;158.2;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;Min: 0.5 Max: 10.;Minimum: 0, Maximum: Unknown;"The range of values for the feature ""Health"" can be obtained by finding the minimum and maximum values in the dataset. However, without access to the actual dataset, I cannot provide the specific range. Please refer to the dataset to find the minimum and maximum values for the ""Health"" feature.";0.5;10.0;;;;
88;Transport_and_communication;43831;Consumer-Price-Index;numeric;103.2;141.4;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"minimum: 1
maximum: 100";"Minimum: 0
Maximum: Cannot determine without additional information";"Min value: 0
Max value: Not provided.";1.0;100.0;;;;
89;Recreation_and_amusement;43831;Consumer-Price-Index;numeric;102.9;153.2;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 100";"Minimum: 0
Maximum: unknown";"Min: 0
Max: 100";0.0;100.0;;;0.0;100.0
90;Education;43831;Consumer-Price-Index;numeric;103.5;161.9;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 20";"Minimum: Unknown
Maximum: Unknown";Min: 0 Max: 100;0.0;20.0;;;0.0;100.0
91;Personal_care_and_effects;43831;Consumer-Price-Index;numeric;102.1;152.2;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Min: 0
Max: 1000";"Based on the given dataset, the range of values for the feature ""Personal_care_and_effects"" cannot be determined without further information.";"Min: 0
Max: 100";0.0;1000.0;;;0.0;100.0
92;Miscellaneous;43831;Consumer-Price-Index;numeric;103.7;151.7;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"Minimum: 0
Maximum: 1000";"Minimum: 0
Maximum: unknown";"Min: 0
Max: 100";0.0;1000.0;;;0.0;100.0
93;General_index;43831;Consumer-Price-Index;numeric;104.0;152.7;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;"minimum: 0
maximum: 100";"Minimum: 0
Maximum: 100";"Based on the given dataset description and features, it is not possible to determine the range of values for the feature ""General_index"" without the actual data.";0.0;100.0;0.0;100.0;;
94;Unnamed:_0;43836;features-and-price-of-computer-components;numeric;0.0;919.0;"Context
The most common website that provided computer hardware components we chose the Newegg website it has hardware systems, Buy PC Parts, Laptops, Electronics  More. Now Shipping to Saudi Arabia! Track Order and more with fast shipping.
to determine which the best component with the best price here we can provide you this dataset. 
Content
Implement the Web scraping by using  the python language and using selenium on python, to extract the data from newegg that contain CPU, GPU, power, ram, monitor, storage 
the** data contains**:

the brand name
items_Decribtion
ratings
prices
Category (CPU, GPU,motherboard, ram, powersuplly, storage  )

Acknowledgements
Thank you for the MISK academy and general assembly for guiding us.
Inspiration
we recommend using EDA to clean data and also recommend to build model predictive price or build assumption analysis";"Minimum: 0
Maximum: 100";Min: 0, Max: unknown;"Since the question asks for the range of values for the feature ""Unnamed:_0"" and it is not specified whether ""Unnamed:_0"" is a numerical or categorical feature I am unable to provide a specific range of values. 

However if ""Unnamed:_0"" is a numerical feature the range of values can be determined by finding the minimum and maximum values in the dataset.";0.0;100.0;;;;
95;MEAN_TEMPERATURE_CALGARY;43843;Eighty-years-of-Canadian-climate-data;numeric;-37.5;26.2;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: -30°C
Maximum: 35°C";"Minimum: -50°C
Maximum: 40°C";"The range of values for the feature MEAN_TEMPERATURE_CALGARY is as follows:
Min: lowest value in the dataset
Max: highest value in the dataset";-30.0;35.0;-50.0;40.0;;
96;TOTAL_PRECIPITATION_CALGARY;43843;Eighty-years-of-Canadian-climate-data;numeric;0.0;92.6;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum value: 0
Maximum value: 100";"Minimum: 0
Maximum: 100";"min TOTAL_PRECIPITATION_CALGARY: 0.0
max TOTAL_PRECIPITATION_CALGARY: Unknown";0.0;100.0;0.0;100.0;;
97;MEAN_TEMPERATURE_EDMONTON;43843;Eighty-years-of-Canadian-climate-data;numeric;-40.8;24.7;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: -45 
Maximum: 35";"Minimum: -40°C
Maximum: 30°C";The min and max values for the feature MEAN_TEMPERATURE_EDMONTON are not provided in the given dataset description.;-45.0;35.0;-40.0;30.0;;
98;TOTAL_PRECIPITATION_EDMONTON;43843;Eighty-years-of-Canadian-climate-data;numeric;0.0;75.6;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: 0
Maximum: 500";"Minimum: 0
Maximum: 100";The range of values for the feature 'TOTAL_PRECIPITATION_EDMONTON' is from a minimum value of 0 to a maximum value of 65.;0.0;500.0;0.0;100.0;0.0;65.0
99;MEAN_TEMPERATURE_HALIFAX;43843;Eighty-years-of-Canadian-climate-data;numeric;-23.5;27.0;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Min: -30 degrees Celsius
Max: 40 degrees Celsius";"Minimum: 
Maximum:";"MIN_MEAN_TEMPERATURE_HALIFAX:  -18.3
MAX_MEAN_TEMPERATURE_HALIFAX:  26.4";-30.0;40.0;;;-18.3;26.4
100;TOTAL_PRECIPITATION_HALIFAX;43843;Eighty-years-of-Canadian-climate-data;numeric;0.0;218.2;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: 0 mm
Maximum: 1000 mm";"Minimum: 0
Maximum: 100";The range of values for the feature TOTAL_PRECIPITATION_HALIFAX is not provided in the given information.;0.0;1000.0;0.0;100.0;;
101;MEAN_TEMPERATURE_MONCTON;43843;Eighty-years-of-Canadian-climate-data;numeric;-27.4;27.2;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: -40 

Maximum: 40";"Minimum: -50°C
Maximum: 40°C";"The range of values for the feature MEAN_TEMPERATURE_MONCTON is as follows:

Min: -34.6
Max: 33.6";-40.0;40.0;-50.0;40.0;-34.6;33.6
102;TOTAL_PRECIPITATION_MONCTON;43843;Eighty-years-of-Canadian-climate-data;numeric;0.0;131.8;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: 0 (mm)
Maximum: 200 (mm)";"Minimum: 0
Maximum: 500 (assuming unit is in millimeters)";"Min: 0.0
Max: 123.7";0.0;200.0;0.0;500.0;0.0;123.7
103;MEAN_TEMPERATURE_MONTREAL;43843;Eighty-years-of-Canadian-climate-data;numeric;-30.9;30.3;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: -50 degrees Celsius
Maximum: 40 degrees Celsius";"Minimum: Unknown
Maximum: Unknown";"The range of values for the feature MEAN_TEMPERATURE_MONTREAL is:

Min: -
Max: -";-50.0;40.0;;;;
104;TOTAL_PRECIPITATION_MONTREAL;43843;Eighty-years-of-Canadian-climate-data;numeric;0.0;93.5;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: 0 mm
Maximum: 200 mm";"Minimum: 0 (mm)
Maximum: 100 (mm)";"Min: 0
Max: 250";0.0;200.0;0.0;100.0;0.0;250.0
105;MEAN_TEMPERATURE_OTTAWA;43843;Eighty-years-of-Canadian-climate-data;numeric;-31.3;30.0;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: -40°C
Maximum: 40°C";"Minimum: -50°C
Maximum: 40°C";"The range of values for the feature MEAN_TEMPERATURE_OTTAWA in the dataset is as follows:
Min: ___________
Max: ___________";-40.0;40.0;-50.0;40.0;;
106;TOTAL_PRECIPITATION_OTTAWA;43843;Eighty-years-of-Canadian-climate-data;numeric;0.0;135.4;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: 0 mm
Maximum: 100 mm";"Minimum: 0
Maximum: 1000";The range of values for the feature TOTAL_PRECIPITATION_OTTAWA is not provided in the given dataset.;0.0;100.0;0.0;1000.0;;
107;MEAN_TEMPERATURE_QUEBEC;43843;Eighty-years-of-Canadian-climate-data;numeric;-30.6;28.9;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: -30°C
Maximum: 30°C";"Minimum: -40°C
Maximum: 40°C";The range of values for the feature MEAN_TEMPERATURE_QUEBEC is not provided in the dataset description.;-30.0;30.0;-40.0;40.0;;
108;TOTAL_PRECIPITATION_QUEBEC;43843;Eighty-years-of-Canadian-climate-data;numeric;0.0;108.5;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: 0
Maximum: 100 (assuming precipitation is measured in mm)";"Minimum: 0 mm
Maximum: 500 mm";The range of values for the feature TOTAL_PRECIPITATION_QUEBEC can be determined by finding the minimum and maximum values in the dataset. Unfortunately, the dataset is not provided, so I cannot give you the specific values. However, you can obtain the min and max values by analyzing the dataset using statistical software or programming languages like Python or R.;0.0;100.0;0.0;500.0;;
109;MEAN_TEMPERATURE_SASKATOON;43843;Eighty-years-of-Canadian-climate-data;numeric;-41.7;32.1;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: -40 degrees Celsius
Maximum: 40 degrees Celsius";"Minimum: -40°C
Maximum: 35°C";The range of values for the feature MEAN_TEMPERATURE_SASKATOON is not provided in the given dataset.;-40.0;40.0;-40.0;35.0;;
110;TOTAL_PRECIPITATION_SASKATOON;43843;Eighty-years-of-Canadian-climate-data;numeric;0.0;96.6;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Sorry, as an AI text-based assistant, I don't have direct access to real-time data. Thus, I'm unable to provide you with the exact range for the feature ""TOTAL_PRECIPITATION_SASKATOON"" in a specific dataset.";"Minimum: 0mm
Maximum: 100mm";"Min: 0.0
Max: 72.8";;;0.0;100.0;0.0;72.8
111;MEAN_TEMPERATURE_STJOHNS;43843;Eighty-years-of-Canadian-climate-data;numeric;-21.3;25.2;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: -30°C 
Maximum: 35°C";"Minimum: Unknown
Maximum: Unknown";The range of values for the feature MEAN_TEMPERATURE_STJOHNS is missing and cannot be determined without access to the actual dataset. Please refer to the dataset for the minimum and maximum values.;-30.0;35.0;;;;
112;TOTAL_PRECIPITATION_STJOHNS;43843;Eighty-years-of-Canadian-climate-data;numeric;0.0;121.2;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: 0mm
Maximum: 500mm";"Minimum: 0
Maximum: 100";The minimum and maximum values for the feature TOTAL_PRECIPITATION_STJOHNS are not provided in the dataset description.;0.0;500.0;0.0;100.0;;
113;MEAN_TEMPERATURE_TORONTO;43843;Eighty-years-of-Canadian-climate-data;numeric;-24.7;31.8;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: -30°C
Maximum: 40°C";"Minimum: -40°C
Maximum: 40°C";The range of values for the feature MEAN_TEMPERATURE_TORONTO is not provided in the given dataset description.;-30.0;40.0;-40.0;40.0;;
114;TOTAL_PRECIPITATION_TORONTO;43843;Eighty-years-of-Canadian-climate-data;numeric;0.0;126.0;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: 0
Maximum: 300mm";"Minimum: 0
Maximum: 100";min: 0.0 max: 125.1;0.0;300.0;0.0;100.0;0.0;125.1
115;MEAN_TEMPERATURE_VANCOUVER;43843;Eighty-years-of-Canadian-climate-data;numeric;-14.5;28.4;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: -10°C
Maximum: 35°C";"Minimum: N/A
Maximum: N/A
As a language model, I don't have access to real-time data or the ability to make guesses. Therefore, I cannot provide the minimum and maximum values for the feature ""MEAN_TEMPERATURE_VANCOUVER"" in the given dataset.";The range of values for the feature MEAN_TEMPERATURE_VANCOUVER is not mentioned in the given information.;-10.0;35.0;;;;
116;TOTAL_PRECIPITATION_VANCOUVER;43843;Eighty-years-of-Canadian-climate-data;numeric;0.0;91.6;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: 0 mm
Maximum: 500 mm";"Minimum: 0
Maximum: 300";The min and max values for the feature TOTAL_PRECIPITATION_VANCOUVER are not provided in the dataset description.;0.0;500.0;0.0;300.0;;
117;MEAN_TEMPERATURE_WHITEHORSE;43843;Eighty-years-of-Canadian-climate-data;numeric;-48.1;23.9;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: -40°C
Maximum: 30°C";"Minimum: -50°C
Maximum: 25°C";The range of values for the feature MEAN_TEMPERATURE_WHITEHORSE is from the minimum value to the maximum value in the dataset.;-40.0;30.0;-50.0;25.0;;
118;TOTAL_PRECIPITATION_WHITEHORSE;43843;Eighty-years-of-Canadian-climate-data;numeric;0.0;44.9;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Min: 0 mm
Max: 100 mm";"Minimum: 0
Maximum: 500";Min: 0   Max: 300;0.0;100.0;0.0;500.0;0.0;300.0
119;MEAN_TEMPERATURE_WINNIPEG;43843;Eighty-years-of-Canadian-climate-data;numeric;-38.6;30.9;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: -46°C
Maximum: 38°C";"Minimum: unknown
Maximum: unknown";"Min: -38.2°C
Max: 36.0°C";-46.0;38.0;;;-38.2;36.0
120;TOTAL_PRECIPITATION_WINNIPEG;43843;Eighty-years-of-Canadian-climate-data;numeric;0.0;83.8;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";"Minimum: 0 mm
Maximum: 100 mm";"Minimum: 0 mm 
Maximum: 1000 mm";The range of values for the feature TOTAL_PRECIPITATION_WINNIPEG is not provided in the given information.;0.0;100.0;0.0;1000.0;;
121;total_cases;43844;Coronavirus-Worldwide-Dataset;numeric;0.0;20075600.0;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0
Maximum: 1000000";"Minimum: 0
Maximum: unlimited";"The range of values for the feature ""total_cases"" in the dataset is approximately:
Minimum: 0
Maximum: Unknown without specific data";0.0;1000000.0;;;;
122;new_cases;43844;Coronavirus-Worldwide-Dataset;numeric;-2461.0;298083.0;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";Minimum: 0 Maximum: 1000;"Minimum: 0
Maximum: Not possible to determine without specific data.";"The range of values for the feature ""new_cases"" in the dataset is from the minimum to the maximum value.";0.0;1000.0;;;;
123;total_deaths;43844;Coronavirus-Worldwide-Dataset;numeric;0.0;736372.0;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0 deaths
Maximum: 1 million deaths";"minimum: 0
maximum: 10000000";"The range of values for the feature ""total_deaths"" is from the minimum value to the maximum value in the dataset. Without knowing the actual dataset, I cannot provide specific values.";0.0;1.0;0.0;10000000.0;;
124;new_deaths;43844;Coronavirus-Worldwide-Dataset;numeric;-1918.0;10504.0;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Based on the given information, it is impossible for me to provide a specific range of values for the feature ""new_deaths"" without knowing the dataset or any additional details.";"Minimum: 0
Maximum: Unknown";"The range of values for the feature ""new_deaths"" is 0 to the maximum value in the dataset.";;;;;;
125;total_cases_per_million;43844;Coronavirus-Worldwide-Dataset;numeric;0.0;39312.614;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0
Maximum: 20000";"Minimum: 0 cases per million
Maximum: can vary depending on the dataset and time period";"The feature ""total_cases_per_million"" has a range of values from the minimum to the maximum in the dataset. The minimum value is not specified in the information provided. The maximum value is also not specified.";0.0;20000.0;;;;
126;new_cases_per_million;43844;Coronavirus-Worldwide-Dataset;numeric;-265.189;4944.376;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0
Maximum: 50000";"Minimum: 0
Maximum: 20000";"The range of values for the feature ""new_cases_per_million"" is not provided in the dataset description.";0.0;50000.0;0.0;20000.0;;
127;total_deaths_per_million;43844;Coronavirus-Worldwide-Dataset;numeric;0.0;1237.551;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0
Maximum: 10000";"Minimum: 0
Maximum: 16000";"min: 0
max: unknown";0.0;10000.0;0.0;16000.0;;
128;new_deaths_per_million;43844;Coronavirus-Worldwide-Dataset;numeric;-41.023;200.04;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0
Maximum: 1000";"Minimum: 0
Maximum: 2000";The range of values for the feature new_deaths_per_million is not provided in the information given. To determine the range, the dataset needs to be analyzed.;0.0;1000.0;0.0;2000.0;;
129;new_tests;43844;Coronavirus-Worldwide-Dataset;numeric;-3743.0;926876.0;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Min: 0
Max: 1000";"Minimum: 0
Maximum: No specific maximum value";"Min: 0
Max: Unknown (not provided in the dataset description)";0.0;1000.0;;;;
130;total_tests;43844;Coronavirus-Worldwide-Dataset;numeric;1.0;61792571.0;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"minimum: 0
maximum: 1000000";"Minimum: 0 
Maximum: Infinity";"The range of values for the feature ""total_tests"" is not provided in the given dataset description.";0.0;1000000.0;0.0;;;
131;total_tests_per_thousand;43844;Coronavirus-Worldwide-Dataset;numeric;0.0;707.957;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0

Maximum: 1000";"Minimum: 0
Maximum: Unknown";The range of values for the feature total_tests_per_thousand cannot be determined without examining the actual dataset.;0.0;1000.0;;;;
132;new_tests_per_thousand;43844;Coronavirus-Worldwide-Dataset;numeric;-0.398;22.359;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"The minimum value for the feature ""new_tests_per_thousand"" could be 0 and the maximum value could be 10.";"Minimum: 0
Maximum: 100";"The minimum and maximum values for the feature ""new_tests_per_thousand"" are not provided in the given dataset description.";0.0;10.0;0.0;100.0;;
133;new_tests_smoothed;43844;Coronavirus-Worldwide-Dataset;numeric;0.0;822470.0;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0
Maximum: 1 million";"Minimum: 0
Maximum: Unknown";"The min and max values for the feature ""new_tests_smoothed"" are not specified in the given dataset description. To find the specific range of values for this feature, you would need to access the dataset or refer to the data documentation.";0.0;1.0;;;;
134;new_tests_smoothed_per_thousand;43844;Coronavirus-Worldwide-Dataset;numeric;0.0;15.82;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;"Minimum: 0
Maximum: 10";"The range of values for the feature ""new_tests_smoothed_per_thousand"" is not provided in the given dataset description. In order to determine the minimum and maximum values, you would need to analyze the actual data from the dataset.";;;0.0;10.0;;
135;tests_per_case;43844;Coronavirus-Worldwide-Dataset;numeric;1.398;47299.0;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0
Maximum: 1000";"Minimum: 0
Maximum: Infinity";"The range of values for the feature ""tests_per_case"" from the dataset is undefined since a specific range cannot be determined without knowing the actual values within the dataset.";0.0;1000.0;0.0;;;
136;positive_rate;43844;Coronavirus-Worldwide-Dataset;numeric;0.0;0.715;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0
Maximum: 1";"Minimum: 0
Maximum: 100 (assuming the ""positive_rate"" represents a percentage)";"min: 0.0
max: 1.0";0.0;1.0;0.0;100.0;0.0;1.0
137;stringency_index;43844;Coronavirus-Worldwide-Dataset;numeric;0.0;100.0;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0.0
Maximum: 100.0";"Minimum: 0
Maximum: 100";The min and max values for the feature `stringency_index` are not provided in the dataset description. Can you please provide the actual dataset or more context to determine the range of values?;0.0;100.0;0.0;100.0;;
138;population;43844;Coronavirus-Worldwide-Dataset;numeric;809.0;7794798729.0;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0
Maximum: 1000000000";Minimum: 1000 | Maximum: 1000000000;"The range of values for the feature ""population"" cannot be determined without access to the dataset. Can you provide the dataset or specify the range?";0.0;1000000000.0;1000.0;1000000000.0;;
139;population_density;43844;Coronavirus-Worldwide-Dataset;numeric;0.137;19347.5;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 1
Maximum: 10000";"Minimum: 0.02
Maximum: 19347.5";"Min: 1 (minimum value for population density)
Max: (no maximum value provided in the dataset)";1.0;10000.0;0.02;19347.5;;
140;median_age;43844;Coronavirus-Worldwide-Dataset;numeric;15.1;48.2;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"I'm sorry, but as an AI language model, I don't have access to real-time data or the ability to make specific predictions about a dataset I don't know. Therefore, I cannot provide a specific range for the feature ""median_age.""";"Minimum: 0
Maximum: 85";"The minimum and maximum values for the feature ""median_age"" are not provided in the dataset description. To determine the range of values for this feature, you would need to analyze the dataset or provide more specific information.";;;0.0;85.0;;
141;aged_65_older;43844;Coronavirus-Worldwide-Dataset;numeric;1.144;27.049;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0
Maximum: 27.049";"Minimum: 2.1
Maximum: 27.5";"min: 1.2
max: 27.049999999999997";0.0;27.049;2.1;27.5;1.2;27.049999999999997
142;aged_70_older;43844;Coronavirus-Worldwide-Dataset;numeric;0.526;18.493;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0.1
Maximum: 28.2";"Minimum: 0
Maximum: 27.049";"The range of values for the feature ""aged_70_older"" in the dataset can be determined by finding the minimum and maximum values. However without access to the actual dataset I cannot provide the specific range. Please refer to the dataset or perform data analysis to obtain the minimum and maximum values for the feature ""aged_70_older"".";0.1;28.2;0.0;27.049;70.0;70.0
143;gdp_per_capita;43844;Coronavirus-Worldwide-Dataset;numeric;661.24;116935.6;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Min: 1000
Max: 50000";"Minimum: 500
Maximum: 100000";"Min: 128.343
Max: 116935.6";1000.0;50000.0;500.0;100000.0;128.343;116935.6
144;extreme_poverty;43844;Coronavirus-Worldwide-Dataset;numeric;0.1;77.6;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0
Maximum: 100";Range of values for feature 'extreme_poverty': 0 77.6;"The range of values for the feature ""extreme_poverty"" in the dataset is as follows:

Min: 0.0
Max: 77.6";0.0;100.0;0.0;77.6;0.0;77.6
145;cardiovasc_death_rate;43844;Coronavirus-Worldwide-Dataset;numeric;79.37;724.417;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0.1
Maximum: 100";"Minimum: 30.1
Maximum: 724.4";"The range of values for the feature ""cardiovasc_death_rate"" in the dataset is:

Min: 79.37
Max: 724.42";0.1;100.0;30.1;724.4;79.37;724.42
146;diabetes_prevalence;43844;Coronavirus-Worldwide-Dataset;numeric;0.99;23.36;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 4%
Maximum: 15%";"Minimum: 0.99
Maximum: 30.79";"The range of values for the feature ""diabetes_prevalence"" is from the minimum value to the maximum value in the dataset. Based on the information provided, we would need access to the actual dataset in order to determine the specific range of values for this feature.";4.0;15.0;0.99;30.79;;
147;female_smokers;43844;Coronavirus-Worldwide-Dataset;numeric;0.1;44.0;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum value: 0
Maximum value: 1";"Minimum: 0
Maximum: Unknown";"The range of values for the feature ""female_smokers"" in the dataset is from the minimum value to the maximum value.";0.0;1.0;;;;
148;male_smokers;43844;Coronavirus-Worldwide-Dataset;numeric;7.7;78.1;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";Sorry, but I can't provide the answer you're looking for. As a language model AI, I don't have access to specific datasets unless provided by you.;Minimum: 0 Maximum: 51;"The range of values for the feature ""male_smokers"" in the dataset is:

Min: 7.7

Max: 78.1";;;0.0;51.0;7.7;78.1
149;handwashing_facilities;43844;Coronavirus-Worldwide-Dataset;numeric;1.188;98.999;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0
Maximum: 1";"Minimum: 0
Maximum: 100";"The range of values for the feature ""handwashing_facilities"" is from the minimum value to the maximum value in the dataset.";0.0;1.0;0.0;100.0;;
150;hospital_beds_per_thousand;43844;Coronavirus-Worldwide-Dataset;numeric;0.1;13.8;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 0.1 beds per thousand.
Maximum: 20 beds per thousand.";Minimum: 0 maximum: 13.8;"The range of values for the feature ""hospital_beds_per_thousand"" cannot be determined without the actual dataset. Please provide the dataset or specific values for the feature in order to determine the range.";0.1;20.0;0.0;13.8;;
151;life_expectancy;43844;Coronavirus-Worldwide-Dataset;numeric;53.28;86.75;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";"Minimum: 60

Maximum: 90";"Minimum: 54.6
Maximum: 86.8";"The range of values for the feature ""life_expectancy"" in the dataset is between the minimum and maximum values.";60.0;90.0;54.6;86.8;;
152;Unnamed:_0;43845;Music-Dataset--1950-to-2019;numeric;0.0;82451.0;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: 1
Maximum: 100";"Minimum value: 0
Maximum value: Unknown";"The range of values for the feature ""Unnamed:_0"" in the dataset cannot be determined without further information or access to the dataset.";1.0;100.0;;;;
153;release_date;43845;Music-Dataset--1950-to-2019;numeric;1950.0;2019.0;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: 1995
Maximum: 2021";"Minimum: 1900

Maximum: 2022";"Min: 1950
Max: 2019";1995.0;2021.0;1900.0;2022.0;1950.0;2019.0
154;len;43845;Music-Dataset--1950-to-2019;numeric;1.0;199.0;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";min(lenthat) = 0 max(lenthat) = 100;"Minimum: 0
Maximum: Unknown";The range of values for the feature 'len' in this dataset is from the minimum value of 0.089365 to the maximum value of 7.285776.;0.0;100.0;;;0.089365;7.285776
155;dating;43845;Music-Dataset--1950-to-2019;numeric;0.000290782;0.647705684;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: 0
Maximum: 10";"Minimum: 0
Maximum: 1";"The range of values for the feature ""dating"" in the dataset is from the minimum to the maximum value. However, as the dataset is not provided, I am unable to give you the specific range values.";0.0;10.0;0.0;1.0;;
156;violence;43845;Music-Dataset--1950-to-2019;numeric;0.000284495;0.981781376;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";Min: 0 | Max: 10;"Minimum: 0
Maximum: 1";"To provide the range of values for the feature ""violence"" from the dataset, we need to analyze the minimum and maximum values. However, without access to the dataset itself, we cannot provide the specific range for the feature.";0.0;10.0;0.0;1.0;;
157;world/life;43845;Music-Dataset--1950-to-2019;numeric;0.000290782;0.962105263;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Min: 0.0
Max: 10.0";"Minimum: 0
Maximum: 1";"Based on the dataset provided, the range of values for the feature ""world/life"" is not provided.";0.0;10.0;0.0;1.0;;
158;night/time;43845;Music-Dataset--1950-to-2019;numeric;0.000289185;0.97368421;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: 18:00 (6:00 PM)
Maximum: 06:00 (6:00 AM)";"Minimum: 0
Maximum: 1";"Based on the dataset description, the range of values for the feature ""night/time"" cannot be determined without inspecting the actual values. Please provide the dataset or a sample of the values for a more accurate answer.";;;0.0;1.0;;
159;shake_the_audience;43845;Music-Dataset--1950-to-2019;numeric;0.000284495;0.497463245;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"min: 0
max: 1";"Minimum: 0
Maximum: 1";"The range of values for the feature ""shake_the_audience"" is not provided in the given information.";0.0;1.0;0.0;1.0;;
160;family/gospel;43845;Music-Dataset--1950-to-2019;numeric;0.000289185;0.54530302;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: 0
Maximum: 1";"Minimum: 0
Maximum: 1";"Based on the dataset provided, the range of values for the feature ""family/gospel"" is not given.";0.0;1.0;0.0;1.0;;
161;romantic;43845;Music-Dataset--1950-to-2019;numeric;0.000284495;0.940789474;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: 0 
Maximum: 1";"Minimum: 0
Maximum: 1";"min romantic: 0.0
max romantic: 1.0";0.0;1.0;0.0;1.0;0.0;1.0
162;communication;43845;Music-Dataset--1950-to-2019;numeric;0.000290782;0.645829372;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: 0 (no communication)
Maximum: 10 (excellent communication)";"Minimum: Unspecified
Maximum: Unspecified";Communication feature range: min = 0 max = 1;0.0;10.0;;;0.0;1.0
163;obscene;43845;Music-Dataset--1950-to-2019;numeric;0.000289185;0.992297817;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Feature: Obscene
Minimum value: 0
Maximum value: 1";"Minimum: 0
Maximum: 1";"Based on the dataset description, the range of values for the feature ""obscene"" is not provided.";0.0;1.0;0.0;1.0;;
164;music;43845;Music-Dataset--1950-to-2019;numeric;0.000289185;0.956937798;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: 0
Maximum: 1";"Minimum: 0
Maximum: 1";"The range of values for the feature ""music"" in the dataset is not provided.";0.0;1.0;0.0;1.0;;
165;movement/places;43845;Music-Dataset--1950-to-2019;numeric;0.000284495;0.638020876;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: 0
Maximum: 1000";"Minimum: Unknown
Maximum: Unknown";"The min and max values for the feature ""movement/places"" in the dataset are not provided in the given information.";0.0;1000.0;;;;
166;light/visual_perceptions;43845;Music-Dataset--1950-to-2019;numeric;0.000284495;0.667781877;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Min: 0.5
Max: 1.5";"Minimum: Unknown
Maximum: Unknown";"Based on the dataset provided, the range of values for the feature ""light/visual_perceptions"" is not provided.";0.5;1.5;;;;
167;family/spiritual;43845;Music-Dataset--1950-to-2019;numeric;0.000284495;0.618072522;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Based on the given dataset, the minimum and maximum values for the feature ""family/spiritual"" cannot be determined without further information.";"Minimum: Data not provided
Maximum: Data not provided";"The range of values for the feature ""family/spiritual"" in the dataset is not provided.";;;;;;
168;like/girls;43845;Music-Dataset--1950-to-2019;numeric;0.000284495;0.594458741;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: 0
Maximum: 100";"Minimum: 0
Maximum: 1";"The min and max values for the feature ""like/girls"" in the dataset are not provided.";0.0;100.0;0.0;1.0;;
169;sadness;43845;Music-Dataset--1950-to-2019;numeric;0.000284495;0.981424148;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: 1
Maximum: 10";"Minimum: unknown
Maximum: unknown";"For the feature ""sadness"" in the dataset, the minimum value is not provided. The maximum value is also not provided.";1.0;10.0;;;;
170;feelings;43845;Music-Dataset--1950-to-2019;numeric;0.000289185;0.958810069;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";min(feelings) = 1 max(feelings) = 10;"Minimum: 0
Maximum: 10";"The range of values for the feature ""feelings"" from the dataset is as follows:

Min: 0
Max: 100";1.0;10.0;0.0;10.0;0.0;100.0
171;danceability;43845;Music-Dataset--1950-to-2019;numeric;0.005415358;0.99350157;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Min: 0.0
Max: 1.0";"Minimum: 0.0
Maximum: 1.0";"The range of values for the feature ""danceability"" in the dataset is from the minimum value of 0.0 to the maximum value of 1.0.";0.0;1.0;0.0;1.0;0.0;1.0
172;loudness;43845;Music-Dataset--1950-to-2019;numeric;0.0;1.0;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: -60 dB
Maximum: 0 dB";"Minimum: Unknown
Maximum: Unknown";"The range of values for the feature ""loudness"" in the dataset is approximately:

Min: -60.0
Max: 0.0";-60.0;0.0;;;-60.0;0.0
173;acousticness;43845;Music-Dataset--1950-to-2019;numeric;2.81e-07;1.0;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: 0
Maximum: 1";"Minimum: 0
Maximum: 1";The range of values for the feature 'acousticness' in the dataset is from 0 to 1.;0.0;1.0;0.0;1.0;0.0;1.0
174;instrumentalness;43845;Music-Dataset--1950-to-2019;numeric;0.0;0.996963563;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";0.0 to 1.0;"minimum: 0
maximum: 1";"The range of values for the feature ""instrumentalness"" in the dataset is from 0 to 1.";0.0;1.0;0.0;1.0;0.0;1.0
175;valence;43845;Music-Dataset--1950-to-2019;numeric;0.0;1.0;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: 0
Maximum: 1";"Minimum: 0
Maximum: 1";"The range of values for the feature ""valence"" in the dataset is from min: 0.0 to max: 1.0.";0.0;1.0;0.0;1.0;0.0;1.0
176;energy;43845;Music-Dataset--1950-to-2019;numeric;0.0;1.0;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: 0
Maximum: 100";"Minimum: 0
Maximum: 1";"Based on the given dataset, the range of values for the feature ""energy"" can be determined by finding the minimum and maximum values of this feature. However, since the dataset is not provided, I cannot directly compute the range. Please provide the dataset or specific values for the feature ""energy"" to determine the range.";0.0;100.0;0.0;1.0;;
177;age;43845;Music-Dataset--1950-to-2019;numeric;0.014285714;1.0;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";"Minimum: 0
Maximum: 100";"Minimum: 0
Maximum: Unknown";"The range of values for the feature ""age"" in the given dataset is the minimum age to the maximum age.";0.0;100.0;;;;
178;age;43904;law-school-admission-bianry;numeric;3.0;69.0;"Law School Admissions (Binarized) 
 Survey among students attending law school in the U.S. in 1991. 
 The dataset was obtained from the R-package fairml. 
 The response variable has been changed to a binary version: Whether ugpa is greater than 3.
 The race1 variables has been binarized to labels white and non-white.";"Minimum: 0
Maximum: 100";"Minimum: Unknown
Maximum: Unknown";age: min = 20 max = 65;0.0;100.0;;;20.0;65.0
179;decile1;43904;law-school-admission-bianry;numeric;1.0;10.0;"Law School Admissions (Binarized) 
 Survey among students attending law school in the U.S. in 1991. 
 The dataset was obtained from the R-package fairml. 
 The response variable has been changed to a binary version: Whether ugpa is greater than 3.
 The race1 variables has been binarized to labels white and non-white.";"Minimum: 1
Maximum: 10";"Minimum and maximum values for the feature ""decile1"" are currently unknown.";"min(decile1): 1
max(decile1): 10";1.0;10.0;;;;
180;decile3;43904;law-school-admission-bianry;numeric;1.0;10.0;"Law School Admissions (Binarized) 
 Survey among students attending law school in the U.S. in 1991. 
 The dataset was obtained from the R-package fairml. 
 The response variable has been changed to a binary version: Whether ugpa is greater than 3.
 The race1 variables has been binarized to labels white and non-white.";"Minimum: 0
Maximum: 10";"Minimum: Unknown
Maximum: Unknown";The minimum and maximum values for the feature decile3 in the given dataset are not provided.;0.0;10.0;;;;
181;fam_inc;43904;law-school-admission-bianry;numeric;1.0;5.0;"Law School Admissions (Binarized) 
 Survey among students attending law school in the U.S. in 1991. 
 The dataset was obtained from the R-package fairml. 
 The response variable has been changed to a binary version: Whether ugpa is greater than 3.
 The race1 variables has been binarized to labels white and non-white.";"MIN: $0
MAX: $500000";"Minimum: Unknown
Maximum: Unknown";"The range of values for the feature ""fam_inc"" in the Law School Admissions dataset is: minimum value - maximum value.";0.0;500000.0;;;;
182;lsat;43904;law-school-admission-bianry;numeric;11.0;48.0;"Law School Admissions (Binarized) 
 Survey among students attending law school in the U.S. in 1991. 
 The dataset was obtained from the R-package fairml. 
 The response variable has been changed to a binary version: Whether ugpa is greater than 3.
 The race1 variables has been binarized to labels white and non-white.";"Minimum: 120.0
Maximum: 180.0";"Min: Unknown
Max: Unknown";"Min: -2.5729 
Max: 1.8196";120.0;180.0;;;-2.5729;1.8196
183;CreditScore;45062;shrutime;numeric;350.0;850.0;This data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.Source: https://www.kaggle.com/datasets/shrutimechlearn/churn-modelling;min: 300 max: 850;"Minimum: 300
Maximum: 850";CreditScore: Min = 350 Max = 850;300.0;850.0;300.0;850.0;350.0;850.0
184;Age;45062;shrutime;numeric;18.0;92.0;This data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.Source: https://www.kaggle.com/datasets/shrutimechlearn/churn-modelling;"Minimum: 18
Maximum: 70";"Minimum age: 18 

Maximum age: 99";"The range of values for the feature ""Age"" in the dataset is:

Min: 18
Max: 92";18.0;70.0;18.0;99.0;18.0;92.0
185;Balance;45062;shrutime;numeric;0.0;250898.09;This data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.Source: https://www.kaggle.com/datasets/shrutimechlearn/churn-modelling;"Minimum: 0
Maximum: 10000000";"Minimum: 0
Maximum: Unknown";"Min: 0
Max: 250898.09";0.0;10000000.0;;;0.0;250898.09
186;EstimatedSalary;45062;shrutime;numeric;11.58;199992.48;This data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.Source: https://www.kaggle.com/datasets/shrutimechlearn/churn-modelling;"Minimum: $15000
Maximum: $200000";"Minimum: 0
Maximum: 10000000";The range of values for the feature EstimatedSalary in the given dataset is from the minimum value of 11586 to the maximum value of 199992.;15000.0;200000.0;0.0;10000000.0;11586.0;199992.0
187;class;45062;shrutime;numeric;0.0;1.0;This data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.Source: https://www.kaggle.com/datasets/shrutimechlearn/churn-modelling;"Minimum: 1
Maximum: 10";"Minimum: 0
Maximum: 1";"The range of values for the feature ""class"" is 0 (customer continues to be a customer) and 1 (customer left the bank or closed his account).";1.0;10.0;0.0;1.0;0.0;1.0
188;year;45106;MTPL_SHAP_Tutorial;numeric;2018.0;2019.0;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";"Minimum: 1970
Maximum: 2021";min(year) = 2000 max(year) = 2022;"min(year) = 1
max(year) = 2023";1970.0;2021.0;2000.0;2022.0;1.0;2023.0
189;town;45106;MTPL_SHAP_Tutorial;numeric;0.0;1.0;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";min: 0 max: 100;"Minimum: Unknown
Maximum: Unknown";"The range of values for the feature ""town"" in the given dataset cannot be determined without access to the actual data. Please refer to the dataset provided by Mayer Meier and Wuthrich (2023) for the specific range of values for the ""town"" feature.";0.0;100.0;;;;
190;driver_age;45106;MTPL_SHAP_Tutorial;numeric;18.0;88.0;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";min: 18 max: 80;"Minimum: 18 years
Maximum: 99 years";"The range of values for the feature ""driver_age"" in the dataset is as follows:

Min: The minimum driver age in the dataset
Max: The maximum driver age in the dataset";18.0;80.0;18.0;99.0;;
191;car_weight;45106;MTPL_SHAP_Tutorial;numeric;950.0;3120.0;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";;"Minimum: 1000
Maximum: 5000";"The min and max values for the feature ""car_weight"" in the dataset are not provided.";;;1000.0;5000.0;;
192;car_power;45106;MTPL_SHAP_Tutorial;numeric;50.0;341.0;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";"Minimum: 50
Maximum: 500";;"The minimum and maximum values for the feature ""car_power"" in the given dataset are not provided in the Dataset description.";50.0;500.0;;;;
193;car_age;45106;MTPL_SHAP_Tutorial;numeric;0.0;23.0;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";"Minimum: 1 year
Maximum: 30 years";;min(car_age) = 0, max(car_age) = unknown without access to the dataset.;1.0;30.0;;;;
194;claim_nb;45106;MTPL_SHAP_Tutorial;numeric;0.0;4.0;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";"Minimum: 0 
Maximum: 100";;"The range of values for the feature ""claim_nb"" is not provided. You can compute it by finding the minimum and maximum values from the dataset.";0.0;100.0;;;;
195;year;45106;MTPL_SHAP_Tutorial;numeric;2018.0;2019.0;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";"Minimum: 1970
Maximum: 2021";;"The range of values for the feature ""year"" is from the minimum value to the maximum value in the dataset.

Min: [minimum value of year]

Max: [maximum value of year]";1970.0;2021.0;;;;
196;town;45106;MTPL_SHAP_Tutorial;numeric;0.0;1.0;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";"Min: 1
Max: 100";;;1.0;100.0;;;;
197;driver_age;45106;MTPL_SHAP_Tutorial;numeric;18.0;88.0;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";"Minimum: 18
Maximum: 99";;Sorry, but I can't help with that request.;18.0;99.0;;;;
198;car_weight;45106;MTPL_SHAP_Tutorial;numeric;950.0;3120.0;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";"Minimum: 1000 lbs
Maximum: 6000 lbs";;"Min: 800 kg
Max: 5000 kg";1000.0;6000.0;;;800.0;5000.0
199;car_power;45106;MTPL_SHAP_Tutorial;numeric;50.0;341.0;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";"Minimum: 50
Maximum: 500";;"Min: 0 
Max: 500";50.0;500.0;;;0.0;500.0
200;car_age;45106;MTPL_SHAP_Tutorial;numeric;0.0;23.0;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";"Minimum: 1 year
Maximum: 20 years";;"The range of values for the feature ""car_age"" in the dataset is from the minimum value to the maximum value. Without access to the actual dataset, I cannot determine the exact range.";1.0;20.0;;;;
201;claim_nb;45106;MTPL_SHAP_Tutorial;numeric;0.0;4.0;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";"Minimum: 0
Maximum: 100";;"The minimum and maximum values of the feature ""claim_nb"" in the dataset are not provided. Please refer to the dataset or the mentioned research paper for specific information on the range of values for this feature.";0.0;100.0;;;;
202;normalized-losses;45080;autos;numeric;37.625922;273.722584;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 65
Maximum: 256";"min: -3

max: +3";;;65.0;256.0;-3.0;3.0
203;wheel-base;45080;autos;numeric;83.069816;127.194382;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;min: 86.6  max: 120.9;"The range of values for the feature ""wheel-base"" in the dataset is the minimum and maximum values.";;;86.6;120.9;;
204;length;45080;autos;numeric;134.019251;216.548564;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: Assumed to be 150 inches
Maximum: Assumed to be 230 inches";"The range of values for the feature ""length"" in the dataset is as follows:
Min: 141.1
Max: 208.1";;;150.0;230.0;141.1;208.1
205;width;45080;autos;numeric;60.270307;75.596629;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: Unknown
Maximum: Unknown";"The range of values for the feature ""width"" in the dataset is approximately 60.3 to 72.3.";;;;;60.3;72.3
206;height;45080;autos;numeric;46.979469;62.50061;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Based on the given dataset features the range of values for the feature ""height"" is between a minimum of 47 inches and a maximum of 59 inches.";"The range of values for the feature ""height"" in the given dataset is as follows:
Min: 47.8
Max: 59.8";;;47.0;59.0;47.8;59.8
207;curb-weight;45080;autos;numeric;1509.552607;4716.212861;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 1488
Maximum: 4066";"The range of values for the feature ""curb-weight"" in the given dataset is:

Min: 1488

Max: 4066";;;1488.0;4066.0;1488.0;4066.0
208;engine-size;45080;autos;numeric;9.891578;381.012483;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 61
Maximum: 326";"The range of values for the feature ""engine-size"" in the dataset is as follows: 

Minimum: 61 
Maximum: 326";;;61.0;326.0;61.0;326.0
209;bore;45080;autos;numeric;2.554261;4.072103;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 2.54
Maximum: 3.94";"The range of values for the feature ""bore"" in the dataset is 2.54-3.94.";;;2.54;3.94;2.54;-3.94
210;stroke;45080;autos;numeric;1.713911;4.458423;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 2.36
Maximum: 4.17";"The range of values for the feature ""stroke"" in the dataset is 2.07 to 4.17.";;;2.36;4.17;2.07;4.17
211;compression-ratio;45080;autos;numeric;-11.806341;42.161764;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 7
Maximum: 23";"Based on the given dataset the range of values for the feature ""compression-ratio"" is 7.0 to 23.0.";;;7.0;23.0;7.0;23.0
212;horsepower;45080;autos;numeric;39.520425;303.922617;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 48
Maximum: 288";"The range of values for the feature ""horsepower"" in the dataset is from 48 to 288.";;;48.0;288.0;48.0;288.0
213;peak-rpm;45080;autos;numeric;3406.968387;6931.555398;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 3800
Maximum: 7000";"min: 4150
max: 6600";;;3800.0;7000.0;4150.0;6600.0
214;city-mpg;45080;autos;numeric;11.110762;54.824617;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"The range of values for the feature ""city-mpg"" is 8 to 49.";"min: 13
max: 49";;;8.0;49.0;13.0;49.0
215;highway-mpg;45080;autos;numeric;11.470231;61.696829;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;Minimum: 10 Maximum: 54;"The range of values for the feature ""highway-mpg"" in this dataset is 16 to 54.";;;10.0;54.0;16.0;54.0
216;price;45080;autos;numeric;-12038.16054;63918.81917;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum price: $5118
Maximum price: $45400";"The range of values for the feature ""price"" in the dataset is: 
Minimum price: $5118 
Maximum price: $45400.";;;5118.0;45400.0;5118.0;45400.0
217;class;45080;autos;numeric;-3.0;3.0;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: compact

Maximum: suv";"The range of values for the feature ""class"" in the dataset is given as follows:

Min: -
Max: -";;;;;;
218;Vehicle_Reference_df_res;45079;road-safety;numeric;1.0;37.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 18";"The range of values for the feature ""Vehicle_Reference_df_res"" cannot be determined without analyzing the dataset.";;;0.0;18.0;;
219;Vehicle_Type;45079;road-safety;numeric;2.0;98.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;Vehicle_Type range: min = 1 max = 20;"Based on the given information, the min and max values for the feature ""Vehicle_Type"" cannot be determined without access to the actual dataset.";;;1.0;20.0;;
220;Vehicle_Manoeuvre;45079;road-safety;numeric;1.0;18.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: 18";"The minimum and maximum values for the feature ""Vehicle_Manoeuvre"" in the dataset are not provided.";;;1.0;18.0;;
221;Vehicle_Location-Restricted_Lane;45079;road-safety;numeric;0.0;9.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 9";"Min: 0
Max: 2";;;0.0;9.0;0.0;2.0
222;Hit_Object_in_Carriageway;45079;road-safety;numeric;0.0;12.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 9";"The range of values for the feature ""Hit_Object_in_Carriageway"" in the dataset is not provided. Please refer to the dataset or provide more information to determine the range.";;;0.0;9.0;;
223;Hit_Object_off_Carriageway;45079;road-safety;numeric;0.0;11.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Min: 0
Max: 9";"The range of values for the feature ""Hit_Object_off_Carriageway"" is not provided in the list of features.";;;0.0;9.0;;
224;Age_of_Driver;45079;road-safety;numeric;12.0;97.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum Age_of_Driver: 0
Maximum Age_of_Driver: 120";"The range of values for the feature ""Age_of_Driver"" in this dataset is from the minimum value to the maximum value. However, without the dataset itself, I cannot provide the specific min and max values for the age of the driver.";;;0.0;120.0;;
225;Age_Band_of_Driver;45079;road-safety;numeric;3.0;11.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 16
Maximum: 96";"min: 1
max: 25";;;16.0;96.0;1.0;25.0
226;Engine_Capacity_(CC);45079;road-safety;numeric;48.0;18000.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0 CC
Maximum: Unknown";"Min Engine_Capacity_(CC): 1
Max Engine_Capacity_(CC): 99999";;;;;1.0;99999.0
227;Propulsion_Code;45079;road-safety;numeric;1.0;12.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: 9";"The range of values for the feature ""Propulsion_Code"" in the dataset is not provided.";;;1.0;9.0;;
228;Age_of_Vehicle;45079;road-safety;numeric;1.0;91.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 99";Age_of_Vehicle: Min = 1 Max = 36;;;0.0;99.0;1.0;36.0
229;Location_Easting_OSGR;45079;road-safety;numeric;90609.0;655282.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 999999";min: 23242 max: 655646;;;0.0;999999.0;23242.0;655646.0
230;Location_Northing_OSGR;45079;road-safety;numeric;10628.0;1142228.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0

Maximum: 999999";"min: -100000
max: 1760000";;;0.0;999999.0;-100000.0;1760000.0
231;Longitude;45079;road-safety;numeric;-6.311427;1.758443;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: -180
Maximum: 180";"The range of values for the feature ""Longitude"" in the dataset is approximately -11.511 to 1.7595.";;;-180.0;180.0;-11.511;1.7595
232;Latitude;45079;road-safety;numeric;49.915618;60.161843;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: -90
Maximum: 90";The min value of the feature Latitude is not provided in the dataset description. The max value of the feature Latitude is also not provided in the dataset description.;;;-90.0;90.0;;
233;Police_Force;45079;road-safety;numeric;1.0;98.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: 98";"Min: 1
Max: 98";;;1.0;98.0;1.0;98.0
234;Number_of_Vehicles;45079;road-safety;numeric;1.0;37.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: Unknown";"The range of values for the feature ""Number_of_Vehicles"" in the dataset is from the minimum value of 1 to the maximum value of 67.";;;;;1.0;67.0
235;Number_of_Casualties;45079;road-safety;numeric;1.0;38.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;Minimum: 0  Maximum: 10;"The range of values for the feature ""Number_of_Casualties"" in this dataset is from 1 to the maximum number of casualties reported in a single accident.";;;0.0;10.0;;
236;Local_Authority_(District);45079;road-safety;numeric;1.0;940.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;Minimum: 1 Maximum: 999;"Min: 1

Max: 941";;;1.0;999.0;1.0;941.0
237;1st_Road_Number;45079;road-safety;numeric;0.0;9914.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1st_Road_Number = 1
Maximum: 1st_Road_Number = 9999";"The range of values for the feature ""1st_Road_Number"" is: 
Minimum: 1 
Maximum: 9998";;;;;;
238;2nd_Road_Number;45079;road-safety;numeric;0.0;9999.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 9999";"min(2nd_Road_Number) = 0
max(2nd_Road_Number) = 9999";;;0.0;9999.0;;
239;Vehicle_Reference_df;45079;road-safety;numeric;1.0;27.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: 30";"Min: 1
Max: 5";;;1.0;30.0;1.0;5.0
240;Casualty_Reference;45079;road-safety;numeric;1.0;38.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: Unknown (not enough information provided)";"The range of values for the feature ""Casualty_Reference"" in the dataset is from 1 to the maximum value in the dataset.";;;;;;
241;Age_of_Casualty;45079;road-safety;numeric;0.0;101.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 120";"The range of values for the feature ""Age_of_Casualty"" in the given dataset is from the minimum value of 0 to the maximum value of 98.";;;0.0;120.0;0.0;98.0
242;Age_Band_of_Casualty;45079;road-safety;numeric;1.0;11.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: 11";"The range of values for the feature ""Age_Band_of_Casualty"" in the dataset is from the minimum value to the maximum value. However, without access to the actual dataset, it is not possible to determine the specific range of values.";;;1.0;11.0;;
243;Pedestrian_Location;45079;road-safety;numeric;0.0;10.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;Minimum: 1 Maximum: 8;"Based on the given dataset, the range of values for the feature ""Pedestrian_Location"" cannot be determined without further information or exploration of the dataset.";;;1.0;8.0;;
244;Pedestrian_Movement;45079;road-safety;numeric;0.0;9.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;Minimum: 1 Maximum: 9;"To set a range of values for the feature ""Pedestrian_Movement"", we need to know the minimum and maximum values from the dataset. Unfortunately, the dataset description provided does not include this information. Could you please provide the minimum and maximum values for the ""Pedestrian_Movement"" feature?";;;1.0;9.0;;
245;Casualty_Type;45079;road-safety;numeric;0.0;98.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1

Maximum: 9";"The range of values for the feature ""Casualty_Type"" is as follows:
Min: 1
Max: 9";;;1.0;9.0;1.0;9.0
246;Casualty_IMD_Decile;45079;road-safety;numeric;1.0;10.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: 10";The range of values for the feature Casualty_IMD_Decile is not possible to determine without access to the actual dataset or further information.;;;1.0;10.0;;
247;class;45079;road-safety;numeric;1.0;2.0;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 1";"The range of values for the feature ""class"" is not provided in the dataset description.";;;0.0;1.0;;
248;0;45077;qsar;numeric;2.0;6.496;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 0
Maximum: 40";The range of values for feature 0 in the QSAR biodegradation dataset is from the minimum value to the maximum value.;;;0.0;40.0;;
249;1;45077;qsar;numeric;0.8039;9.1775;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 0
Maximum: 1";The range of values for feature 1 in the QSAR biodegradation dataset is [0 40].;;;0.0;1.0;;
250;7;45077;qsar;numeric;0.0;60.7;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 7
Maximum: 7";"Min: -3.105
Max: 8.456";;;7.0;7.0;-3.105;8.456
251;11;45077;qsar;numeric;-5.256;4.722;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 11
Maximum: 11";min: 0 max: 40;;;11.0;11.0;0.0;40.0
252;12;45077;qsar;numeric;1.544;5.701;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 11
Maximum: 14";Based on the given dataset the range of values for feature 12 is not specified. To determine the range you would need to access the dataset directly or refer to the reference paper mentioned in the dataset description.;;;11.0;14.0;;
253;13;45077;qsar;numeric;0.0;4.491;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;The range of values for feature 13 in the dataset is 0-40.;Based on the provided details the range of values for feature 13 in the dataset is not available.;;;;;;
254;14;45077;qsar;numeric;4.174;12.609;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"minimum: 0
maximum: 40";The minimum and maximum values for feature 14 in the QSAR biodegradation dataset are not provided in the given information.;;;0.0;40.0;;
255;16;45077;qsar;numeric;0.957;1.311;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 16
Maximum: 16";Based on the given dataset the range of values for feature 16 is not provided.;;;16.0;16.0;;
256;17;45077;qsar;numeric;1.022;1.377;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 17

Maximum: 17";Based on the given dataset description the minimum and maximum values for feature 17 cannot be determined without access to the actual data.;;;17.0;17.0;;
257;21;45077;qsar;numeric;0.863;1.641;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 21  
Maximum: 21";The range of values for feature 21 in the QSAR biodegradation dataset is not provided.;;;21.0;21.0;;
258;26;45077;qsar;numeric;1.0;2.859;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 26
Maximum: 26";The range of values for feature 26 in the QSAR biodegradation dataset is not provided in the information provided.;;;26.0;26.0;;
259;27;45077;qsar;numeric;-1.099;1.073;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Min: 27
Max: 27";Based on the given dataset description the range of values for feature 27 cannot be determined without examining the actual data.;;;27.0;27.0;;
260;29;45077;qsar;numeric;0.0;71.167;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Min: 29
Max: 29";Based on the given dataset the minimum and maximum values for feature 29 are not provided.;;;29.0;29.0;;
261;30;45077;qsar;numeric;0.444;17.537;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;Minimum: 30 Maximum: 37;Based on the provided dataset the range of values for feature 30 is not known.;;;30.0;37.0;;
262;35;45077;qsar;numeric;2.267;10.695;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum value: 35 
Maximum value: 35";Based on the given dataset description the range of values for feature 35 cannot be determined without further information.;;;35.0;35.0;;
263;36;45077;qsar;numeric;1.467;5.825;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 36
Maximum: 36";The range of values for feature 36 in the QSAR biodegradation dataset is unknown as the specific values are not provided in the given dataset description.;;;36.0;36.0;;
264;38;45077;qsar;numeric;4.917;14.7;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 38
Maximum: 38";"Min: 0
Max: 38";;;38.0;38.0;0.0;38.0
265;2;45077;qsar;numeric;0.0;12.0;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 2
Maximum: 40";The range of values for feature 2 in the QSAR biodegradation dataset is from the minimum value to the maximum value. Unfortunately without the actual dataset the exact range cannot be determined.;;;2.0;40.0;;
266;4;45077;qsar;numeric;0.0;36.0;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 2
Maximum: 40";The range of values for feature 4 in the QSAR biodegradation dataset is 0 to 1.;;;2.0;40.0;;
267;5;45077;qsar;numeric;0.0;13.0;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 2
Maximum: 40";The range of values for feature 5 in the QSAR biodegradation dataset is from min: 0 to max: 2.326.;;;2.0;40.0;;
268;6;45077;qsar;numeric;0.0;18.0;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 6 

Maximum: 6";;;;6.0;6.0;;
269;8;45077;qsar;numeric;0.0;24.0;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 4
Maximum: 10";The range of values for feature 8 is not provided in the Dataset description.;;;4.0;10.0;;
270;9;45077;qsar;numeric;0.0;12.0;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 9
Maximum: 9";The range of values for feature 9 in the QSAR biodegradation dataset is from the minimum value to the maximum value.;;;9.0;9.0;;
271;10;45077;qsar;numeric;0.0;44.0;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;The range of values for feature 10 in the dataset can be 6 to 10.;For feature 10 in the QSAR biodegradation dataset the range of values is not specified in the given information.;;;;;;
272;15;45077;qsar;numeric;0.0;40.0;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;The range of values for feature 15 in the dataset is 0 to 40.;The minimum and maximum values for feature 15 in the QSAR biodegradation dataset are not provided in the given information. To determine the range you would need to analyze the dataset or access the data source directly.;;;;;;
273;31;45077;qsar;numeric;0.0;8.0;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Min: 31
Max: 31";The range of values for feature 31 is not provided in the dataset description.;;;31.0;31.0;;
274;32;45077;qsar;numeric;0.0;12.0;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 32
Maximum: 32";The range of values for feature 32 is as follows: min = 3.113 max = 8.464.;;;32.0;32.0;;
275;33;45077;qsar;numeric;0.0;18.0;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 33
Maximum: 33";Based on the given dataset description I cannot determine the range of values for feature 33 without access to the actual data.;;;33.0;33.0;;
276;37;45077;qsar;numeric;0.0;8.0;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 37
Maximum: 37";The minimum and maximum values for feature 37 in the QSAR biodegradation dataset are not provided in the given information.;;;37.0;37.0;;
277;40;45077;qsar;numeric;0.0;27.0;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 40
Maximum: 40";"The min and max values for feature 40 in the QSAR biodegradation dataset are as follows:

Min: 0
Max: 1";;;40.0;40.0;;
278;Customer_care_calls;45074;Shipping;numeric;2.0;7.0;An international e-commerce company based wants to discover key insights from their customer database. They want to use some of the most advanced machine learning techniques to study their customers. The company sells electronic products;;"Minimum: 1
Maximum: 10";The range of values for the feature Customer_care_calls is between the minimum value of 1 and the maximum value of 10.;;;1.0;10.0;1.0;10.0
279;Customer_rating;45074;Shipping;numeric;1.0;5.0;An international e-commerce company based wants to discover key insights from their customer database. They want to use some of the most advanced machine learning techniques to study their customers. The company sells electronic products;;"Minimum: 1
Maximum: 5";Min: 1 Max: 5;;;1.0;5.0;1.0;5.0
280;Prior_purchases;45074;Shipping;numeric;2.0;10.0;An international e-commerce company based wants to discover key insights from their customer database. They want to use some of the most advanced machine learning techniques to study their customers. The company sells electronic products;;"Minimum: 0
Maximum: 100";"The range of values for the feature ""Prior_purchases"" is from 0 (min) to an unspecified maximum value (max).";;;0.0;100.0;;
281;Discount_offered;45074;Shipping;numeric;1.0;65.0;An international e-commerce company based wants to discover key insights from their customer database. They want to use some of the most advanced machine learning techniques to study their customers. The company sells electronic products;;"Minimum: 0
Maximum: 100";"min: 0
max: 100";;;0.0;100.0;0.0;100.0
282;Weight_in_gms;45074;Shipping;numeric;1001.0;7846.0;An international e-commerce company based wants to discover key insights from their customer database. They want to use some of the most advanced machine learning techniques to study their customers. The company sells electronic products;;"Min: 100 g

Max: 5000 g";"Min: 0 gms
Max: Unknown";;;100.0;5000.0;;
283;class;45074;Shipping;numeric;0.0;1.0;An international e-commerce company based wants to discover key insights from their customer database. They want to use some of the most advanced machine learning techniques to study their customers. The company sells electronic products;;"Minimum: 0
Maximum: 1";"The range of values for the feature ""class"" is min: 1 and max: 10.";;;0.0;1.0;1.0;10.0
284;lineNo;45073;eye_movements;numeric;1.0;10927.0;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 1
Maximum: It depends on the number of lines in the dataset.";"The min and max values for the feature ""lineNo"" in this dataset are not mentioned in the provided description. Additional information or access to the dataset would be required to determine the range of values for this feature.";;;;;;
285;assgNo;45073;eye_movements;numeric;1.0;336.0;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 1
Maximum: Unknown";"The range of values for the feature ""assgNo"" in the dataset is from the minimum value to the maximum value. Unfortunately, without access to the dataset, we cannot provide the specific range. Please refer to the dataset source for the actual minimum and maximum values.";;;;;;
286;prevFixDur;45073;eye_movements;numeric;0.0;1036.0;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: unspecified";"The range of values for the feature ""prevFixDur"" is not provided in the dataset description.";;;;;;
287;firstfixDur;45073;eye_movements;numeric;20.0;777.0;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: unknown";"The range of values for the feature ""firstfixDur"" in the dataset is:

Min: 0
Max: (Unknown)";;;;;;
288;firstPassFixDur;45073;eye_movements;numeric;20.0;1392.0;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";"min(firstPassFixDur) = 0.0  
max(firstPassFixDur) = 78.5";;;;;0.0;78.5
289;nextFixDur;45073;eye_movements;numeric;0.0;1133.0;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";"The minimum value for the feature ""nextFixDur"" is not provided in the given dataset description.";;;;;;
290;firstSaccLen;45073;eye_movements;numeric;0.0;1686.4404;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";"The min and max values for the feature ""firstSaccLen"" are not provided in the given description.";;;;;;
291;lastSaccLen;45073;eye_movements;numeric;0.0;1924.1347;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";The range of values for the feature lastSaccLen is not provided in the given dataset description.;;;;;;
292;prevFixPos;45073;eye_movements;numeric;0.0;1070.3616;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";The range of values for the feature prevFixPos is not provided in the given dataset description.;;;;;;
293;landingPos;45073;eye_movements;numeric;1.118;1348.7161;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum landingPos: 0
Maximum landingPos: Unknown";"Based on the given dataset description, the feature ""landingPos"" represents the landing position of the eye fixations on each word in the eye movement trajectory. To provide a range of values for this feature, we would need access to the actual dataset. Without the dataset, it is not possible to determine the minimum and maximum values for the ""landingPos"" feature.";;;;;;
294;leavingPos;45073;eye_movements;numeric;0.5;1343.5316;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Any positive value within the dataset.";"The range for the feature ""leavingPos"" is not provided in the dataset description.";;;;;;
295;totalFixDur;45073;eye_movements;numeric;20.0;1392.0;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";"The range of values for the feature ""totalFixDur"" in the dataset is not provided in the given information.";;;;;;
296;meanFixDur;45073;eye_movements;numeric;20.0;757.0;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";"Based on the given dataset description, we can see that one of the features is ""meanFixDur"". To determine the range of values for this feature, we need to analyze the dataset itself. Unfortunately, without access to the dataset, we cannot provide the specific range of values for ""meanFixDur"" (i.e., the minimum and maximum values).";;;;;;
297;regressLen;45073;eye_movements;numeric;0.0;24987.0;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";"The range of values for the feature ""regressLen"" in the given dataset is as follows:

Min: Minimum value of regressLen in the dataset
Max: Maximum value of regressLen in the dataset";;;;;;
298;regressDur;45073;eye_movements;numeric;0.0;11140.0;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: unknown";"Based on the given dataset description, the minimum and maximum values for the feature ""regressDur"" are not provided.";;;;;;
299;pupilDiamMax;45073;eye_movements;numeric;-4.3255;4.4917;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: -infinity
Maximum: +infinity";"The range of values for the feature ""pupilDiamMax"" from the given dataset is not available without analyzing the data.";;;0.0;;;
300;pupilDiamLag;45073;eye_movements;numeric;-1.206;4.4917;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0.1
Maximum: 5.0";"Based on the given dataset description, the range of values for the feature ""pupilDiamLag"" is not provided. Therefore, it is not possible to determine the minimum and maximum values for this feature.";;;0.1;5.0;;
301;timePrtctg;45073;eye_movements;numeric;0.0005;0.318;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: 100";"The range of values for the feature ""timePrtctg"" is not provided in the dataset description. Therefore, we cannot determine the minimum and maximum values for this feature.";;;0.0;100.0;;
302;titleNo;45073;eye_movements;numeric;1.0;10.0;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 1
Maximum: unknown";"The range of values for the feature ""titleNo"" in the dataset is from the minimum value to the maximum value. Unfortunately, without access to the dataset, we cannot provide the specific numerical range.";;;;;;
303;wordNo;45073;eye_movements;numeric;1.0;10.0;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 1
Maximum: Unknown (data not provided)";"The minimum value for the feature ""wordNo"" is not specified in the provided information.";;;;;;
304;class;45073;eye_movements;numeric;0.0;1.0;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;Minimum: 0 Maximum: 1;"The range of the feature ""class"" in the dataset is from ""I"" to ""R"".";;;0.0;1.0;;
305;wage_eur;45012;fifa;numeric;500.0;350000.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;Minimum: 0 Maximum: 1000000;"Min wage_eur: 1000
Max wage_eur: 5000000";;;0.0;1000000.0;1000.0;5000000.0
306;age;45012;fifa;numeric;16.0;54.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 15
Maximum: 45";"Min age: 16
Max age: 45";;;15.0;45.0;16.0;45.0
307;height_cm;45012;fifa;numeric;155.0;206.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 150 cm
Maximum: 220 cm";"Based on the given dataset, the range of values for the feature ""height_cm"" can be determined by finding the minimum and maximum values.";;;150.0;220.0;;
308;weight_kg;45012;fifa;numeric;49.0;110.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;Min: 50 kg Max: 100 kg;The range of values for the feature weight_kg is approximately: min = 50 kg max = 110 kg.;;;50.0;100.0;50.0;110.0
309;overall;45012;fifa;numeric;47.0;93.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: Unknown
Maximum: Unknown";"The range of values for the feature ""overall"" in the dataset is from the minimum value of overall to the maximum value of overall.";;;;;;
310;potential;45012;fifa;numeric;49.0;95.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 1
Maximum: 99";"To set a range of values for the feature ""potential"" in the dataset, we need to find the minimum and maximum values. 
From the given dataset description, the min and max values for the feature ""potential"" are as follows:

Min: Unknown
Max: Unknown

Unfortunately, without access to the actual dataset, we cannot determine the specific values for the range of ""potential"".";;;1.0;99.0;;
311;attacking_crossing;45012;fifa;numeric;6.0;94.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;;"Based on the information provided I will provide the range of values for the feature ""attacking_crossing"" from the dataset.

Minimum value: 1
Maximum value: 99";;;;;1.0;99.0
312;attacking_finishing;45012;fifa;numeric;2.0;95.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 99";"The range of values for the feature ""attacking_finishing"" is:

Minimum value: unknown
Maximum value: unknown

Since no specific information about the range of values for the feature ""attacking_finishing"" is provided, we cannot determine the minimum and maximum values.";;;0.0;99.0;;
313;attacking_heading_accuracy;45012;fifa;numeric;5.0;93.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 99";"The range of values for the feature ""attacking_heading_accuracy"" in the dataset is from the minimum value to the maximum value.";;;0.0;99.0;;
314;attacking_short_passing;45012;fifa;numeric;7.0;94.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 100";"The range of values for the feature ""attacking_short_passing"" is not specified in the given dataset. In order to determine the min and max values for this feature, you would need to analyze the dataset or consult the data source.";;;0.0;100.0;;
315;attacking_volleys;45012;fifa;numeric;3.0;90.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 99";"The range of values for the feature ""attacking_volleys"" is from the minimum to the maximum value in the dataset. Unfortunately, I don't have access to the dataset, so I cannot provide the exact range.";;;0.0;99.0;;
316;skill_dribbling;45012;fifa;numeric;4.0;96.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 99";"Min skill_dribbling: 1
Max skill_dribbling: 99";;;0.0;99.0;1.0;99.0
317;skill_curve;45012;fifa;numeric;6.0;94.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 1  
Maximum: 99";"The range of values for the feature ""skill_curve"" is from the minimum to the maximum value in the dataset.";;;1.0;99.0;;
318;skill_fk_accuracy;45012;fifa;numeric;4.0;94.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 99";The range of values for the feature skill_fk_accuracy in the dataset is from 1 to 99.;;;0.0;99.0;1.0;99.0
319;skill_long_passing;45012;fifa;numeric;9.0;93.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 100";"The min value for the feature ""skill_long_passing"" is not provided in the given dataset. The max value for this feature is also not provided.";;;0.0;100.0;;
320;skill_ball_control;45012;fifa;numeric;8.0;96.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 1
Maximum: 99";The range of values for the feature skill_ball_control is [1 99].;;;1.0;99.0;1.0;99.0
321;movement_acceleration;45012;fifa;numeric;14.0;97.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 100";"The range of values for the feature ""movement_acceleration"" in the dataset is from the minimum to the maximum value.";;;0.0;100.0;;
322;movement_sprint_speed;45012;fifa;numeric;15.0;97.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 1
Maximum: 99";"The range of values for the feature ""movement_sprint_speed"" in the dataset is from the minimum value to the maximum value.";;;1.0;99.0;;
323;movement_agility;45012;fifa;numeric;18.0;96.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: Undetermined
Maximum: Undetermined";"The range of values for the feature ""movement_agility"" from the dataset is as follows:

Min: The minimum value of movement_agility.
Max: The maximum value of movement_agility.";;;;;;
324;movement_reactions;45012;fifa;numeric;25.0;94.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: unknown
Maximum: unknown";"The range of values for the feature ""movement_reactions"" in the dataset is from the minimum value to the maximum value.";;;;;;
325;movement_balance;45012;fifa;numeric;15.0;96.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum value: 0
Maximum value: 100";"The range of values for the feature ""movement_balance"" in the dataset is minimum: 10 maximum: 98.";;;0.0;100.0;10.0;98.0
326;defending_standing_tackle;45012;fifa;numeric;5.0;93.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum value: 0
Maximum value: 99";"The range of values for the feature ""defending_standing_tackle"" is not provided in the dataset description.";;;0.0;99.0;;
327;defending_sliding_tackle;45012;fifa;numeric;5.0;92.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Min: 0
Max: 99";"The range of values for the feature ""defending_sliding_tackle"" in the dataset is from the minimum value to the maximum value.";;;0.0;99.0;;
328;goalkeeping_diving;45012;fifa;numeric;2.0;91.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 1
Maximum: 99";"The range of values for the feature ""goalkeeping_diving"" in the dataset is minimum = 14 and maximum = 92.";;;1.0;99.0;14.0;92.0
329;goalkeeping_handling;45012;fifa;numeric;2.0;92.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 5
Maximum: 95";;;;5.0;95.0;;
330;goalkeeping_kicking;45012;fifa;numeric;2.0;93.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 5
Maximum: 95";"The range of values for the feature ""goalkeeping_kicking"" is as follows:

Minimum: Unknown
Maximum: Unknown

Without access to the dataset or information on the range of values, it is not possible to determine the exact minimum and maximum values for the feature.";;;5.0;95.0;;
331;goalkeeping_positioning;45012;fifa;numeric;2.0;92.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 1
Maximum: 99";"The range of values for the feature ""goalkeeping_positioning"" is from 1 to 99.";;;1.0;99.0;1.0;99.0
332;goalkeeping_reflexes;45012;fifa;numeric;2.0;90.0;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 1
Maximum: 99";"The range of values for the feature ""goalkeeping_reflexes"" is from 1 to 99.";;;1.0;99.0;1.0;99.0
333;passenger_count;44986;nyc_taxi_green;numeric;0.0;9.0;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 1
Maximum: 6";"The range of values for the feature ""passenger_count"" in the dataset is from 0 (minimum value) to 9 (maximum value).";;;1.0;6.0;0.0;9.0
334;tip_amount;44986;nyc_taxi_green;numeric;-10.56;250.7;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 0
Maximum: 100";The range of values for the feature 'tip_amount' in the dataset is minimum = 0 and maximum = unknown.;;;0.0;100.0;;
335;tolls_amount;44986;nyc_taxi_green;numeric;0.0;98.0;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 0
Maximum: 200";"The minimum and maximum values for the feature ""tolls_amount"" are not provided in the given information.";;;0.0;200.0;;
336;total_amount;44986;nyc_taxi_green;numeric;-63.36;712.38;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 0
Maximum: 100000";"The range of values for the feature ""total_amount"" in the given dataset can be determined by examining the minimum and maximum values. 

Min total_amount: $0.00 
Max total_amount: $338.00";;;0.0;100000.0;0.0;338.0
337;lpep_pickup_datetime_day;44986;nyc_taxi_green;numeric;1.0;31.0;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;Minimum: 1 Maximum: 31;"The range of values for the feature ""lpep_pickup_datetime_day"" is from the minimum value to the maximum value in the dataset.";;;1.0;31.0;;
338;lpep_pickup_datetime_hour;44986;nyc_taxi_green;numeric;0.0;23.0;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 0
Maximum: 23";"The minimum and maximum values for the feature ""lpep_pickup_datetime_hour"" are not provided in the given dataset. To determine the range, you would need to analyze the data or calculate it based on the actual values in the dataset.";;;0.0;23.0;;
339;lpep_pickup_datetime_minute;44986;nyc_taxi_green;numeric;0.0;59.0;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 0 
Maximum: 59";"The range of values for the feature ""lpep_pickup_datetime_minute"" is from 0 to 59.";;;0.0;59.0;0.0;59.0
340;lpep_dropoff_datetime_day;44986;nyc_taxi_green;numeric;1.0;31.0;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 1

Maximum: 31";"The range of values for the feature ""lpep_dropoff_datetime_day"" is the minimum value and the maximum value in the dataset.";;;1.0;31.0;;
341;lpep_dropoff_datetime_hour;44986;nyc_taxi_green;numeric;0.0;23.0;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 0
Maximum: 23";"The range of values for the feature ""lpep_dropoff_datetime_hour"" is from 0 to 23.";;;0.0;23.0;0.0;23.0
342;lpep_dropoff_datetime_minute;44986;nyc_taxi_green;numeric;0.0;59.0;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 0
Maximum: 59";"The range of values for the feature ""lpep_dropoff_datetime_minute"" in the dataset is from 0 to 59.";;;0.0;59.0;0.0;59.0
343;ln_votes_pop;44985;space_ga;numeric;-3.057045019;0.100083459;"**Data Description**

The dataset contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.

Given population, education levels in the population, number of owned houses, incomes and coordinates, the goal is to predict the number of votes per population (logarithmic).

**Attribute Description**

1. *ln_votes_pop* - logarithm of total number of votes - logarithm of populaiton (ln(votes/pop)), target feature
2. *pop* - the population in each county of 18 years of age or older
3. *education* - the population in each county with a 12th grade or higher education
4. *houses* - the number of owner-occupied housing units
5. *income* - the aggregate income
6. *xcoord* - X spatial coordinate of the county
7. *ycoord* - Y spatial coordinate of the county";;"Minimum: -∞
Maximum: ∞";The range of values for the feature ln_votes_pop is not provided in the dataset description.;;;;;;
344;pop;44985;space_ga;numeric;4.369447852;15.51043143;"**Data Description**

The dataset contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.

Given population, education levels in the population, number of owned houses, incomes and coordinates, the goal is to predict the number of votes per population (logarithmic).

**Attribute Description**

1. *ln_votes_pop* - logarithm of total number of votes - logarithm of populaiton (ln(votes/pop)), target feature
2. *pop* - the population in each county of 18 years of age or older
3. *education* - the population in each county with a 12th grade or higher education
4. *houses* - the number of owner-occupied housing units
5. *income* - the aggregate income
6. *xcoord* - X spatial coordinate of the county
7. *ycoord* - Y spatial coordinate of the county";;min(pop), max(pop);"The range of values for the feature ""pop"" is from the minimum value to the maximum value in the dataset. 

Min: Minimum value of ""pop"" feature
Max: Maximum value of ""pop"" feature";;;;;;
345;education;44985;space_ga;numeric;3.63758616;14.94512462;"**Data Description**

The dataset contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.

Given population, education levels in the population, number of owned houses, incomes and coordinates, the goal is to predict the number of votes per population (logarithmic).

**Attribute Description**

1. *ln_votes_pop* - logarithm of total number of votes - logarithm of populaiton (ln(votes/pop)), target feature
2. *pop* - the population in each county of 18 years of age or older
3. *education* - the population in each county with a 12th grade or higher education
4. *houses* - the number of owner-occupied housing units
5. *income* - the aggregate income
6. *xcoord* - X spatial coordinate of the county
7. *ycoord* - Y spatial coordinate of the county";;"Minimum: 0
Maximum: 100";education (min max): 12.0 100.0;;;0.0;100.0;12.0;100.0
346;houses;44985;space_ga;numeric;3.135494216;14.09571247;"**Data Description**

The dataset contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.

Given population, education levels in the population, number of owned houses, incomes and coordinates, the goal is to predict the number of votes per population (logarithmic).

**Attribute Description**

1. *ln_votes_pop* - logarithm of total number of votes - logarithm of populaiton (ln(votes/pop)), target feature
2. *pop* - the population in each county of 18 years of age or older
3. *education* - the population in each county with a 12th grade or higher education
4. *houses* - the number of owner-occupied housing units
5. *income* - the aggregate income
6. *xcoord* - X spatial coordinate of the county
7. *ycoord* - Y spatial coordinate of the county";;"min(houses) = unknown,
max(houses) = unknown";"The range of values for the feature ""houses"" is from the minimum value of 65 to the maximum value of 5456.";;;;;65.0;5456.0
347;income;44985;space_ga;numeric;7.586803535;17.94399105;"**Data Description**

The dataset contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.

Given population, education levels in the population, number of owned houses, incomes and coordinates, the goal is to predict the number of votes per population (logarithmic).

**Attribute Description**

1. *ln_votes_pop* - logarithm of total number of votes - logarithm of populaiton (ln(votes/pop)), target feature
2. *pop* - the population in each county of 18 years of age or older
3. *education* - the population in each county with a 12th grade or higher education
4. *houses* - the number of owner-occupied housing units
5. *income* - the aggregate income
6. *xcoord* - X spatial coordinate of the county
7. *ycoord* - Y spatial coordinate of the county";;"Minimum income: 0
Maximum income: 9999999999999";Minimum value for feature 'income': Not provided in the given dataset description.;;;0.0;9999999999999.0;;
348;xcoord;44985;space_ga;numeric;-124229902.0;-67609990.0;"**Data Description**

The dataset contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.

Given population, education levels in the population, number of owned houses, incomes and coordinates, the goal is to predict the number of votes per population (logarithmic).

**Attribute Description**

1. *ln_votes_pop* - logarithm of total number of votes - logarithm of populaiton (ln(votes/pop)), target feature
2. *pop* - the population in each county of 18 years of age or older
3. *education* - the population in each county with a 12th grade or higher education
4. *houses* - the number of owner-occupied housing units
5. *income* - the aggregate income
6. *xcoord* - X spatial coordinate of the county
7. *ycoord* - Y spatial coordinate of the county";;"Min: -180
Max: 180";"The minimum and maximum values for the feature ""xcoord"" in the given dataset are not provided.";;;-180.0;180.0;;
349;ycoord;44985;space_ga;numeric;25117067.0;48833747.0;"**Data Description**

The dataset contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.

Given population, education levels in the population, number of owned houses, incomes and coordinates, the goal is to predict the number of votes per population (logarithmic).

**Attribute Description**

1. *ln_votes_pop* - logarithm of total number of votes - logarithm of populaiton (ln(votes/pop)), target feature
2. *pop* - the population in each county of 18 years of age or older
3. *education* - the population in each county with a 12th grade or higher education
4. *houses* - the number of owner-occupied housing units
5. *income* - the aggregate income
6. *xcoord* - X spatial coordinate of the county
7. *ycoord* - Y spatial coordinate of the county";;"Minimum: lowest value in the dataset for ycoord
Maximum: highest value in the dataset for ycoord";"The range of values for the feature ""ycoord"" in the dataset is: 

Min: Minimum value of ycoord in the dataset
Max: Maximum value of ycoord in the dataset";;;;;;
350;theta1;44981;pumadyn32nh;numeric;-2.3559788;2.3560933;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value for theta1: Unknown
Maximum value for theta1: Unknown";"The range of values for the feature theta1 in the dataset is:
Minimum: -3.1416
Maximum: 3.1416";;;;;;
351;theta2;44981;pumadyn32nh;numeric;-2.3560923;2.3559392;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";To determine the range of values for the feature theta2 we need to analyze the dataset. Unfortunately you have not provided the dataset itself. Without the dataset it is not possible to calculate the minimum and maximum values for theta2. Please provide the dataset so that I can help you with this task.;;;;;2.0;2.0
352;theta3;44981;pumadyn32nh;numeric;-2.3561923;2.3560761;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: No information provided

Maximum: No information provided";"Min: Theta3 cannot be determined without the actual data. 

Max: Theta3 cannot be determined without the actual data.";;;;;3.0;3.0
353;theta4;44981;pumadyn32nh;numeric;-2.3561554;2.3554484;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value of theta4: Unknown.
Maximum value of theta4: Unknown.";The range of values for the feature theta4 in the dataset can be determined by calculating its minimum and maximum values.;;;;;;
354;theta5;44981;pumadyn32nh;numeric;-2.3558931;2.3557348;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";To determine the range of values for the feature theta5 we need to look at the dataset or the actual values. As a language model AI I don't have access to the specific dataset and cannot compute the range for you. However you can compute it using any programming language or statistical software by finding the minimum and maximum values of theta5 from the dataset.;;;;;5.0;5.0
355;theta6;44981;pumadyn32nh;numeric;-2.356149;2.3555894;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value: -Infinity 
Maximum value: +Infinity";"The range of values for the feature theta6 in the dataset is:
Min: -pi (approximately -3.1416)
Max: pi (approximately 3.1416)";;;0.0;;;
356;thetad1;44981;pumadyn32nh;numeric;-2.3558835;2.3561468;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";"Min: -10.0
Max: 10.0";;;;;-10.0;10.0
357;thetad2;44981;pumadyn32nh;numeric;-2.3553779;2.3558753;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: -∞
Maximum: +∞";"The range of values for the feature thetad2 in this dataset is:

Minimum: Not provided
Maximum: Not provided";;;;;;
358;thetad3;44981;pumadyn32nh;numeric;-2.3555789;2.3558805;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";The range of values for the feature thetad3 in the dataset is from the minimum value to the maximum value.;;;;;;
359;thetad4;44981;pumadyn32nh;numeric;-2.3557642;2.3561293;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value: Unknown
Maximum value: Unknown";The range of values for the feature thetad4 is from the minimum value to the maximum value in the dataset.;;;;;;
360;thetad5;44981;pumadyn32nh;numeric;-2.3559181;2.3559142;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: unknown
Maximum: unknown";The feature thetad5 has a range of values from the minimum to the maximum in the dataset.;;;;;;
361;thetad6;44981;pumadyn32nh;numeric;-2.3556409;2.3558045;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Sorry but as a language model AI I don't have access to the specific data or domain knowledge required to determine the range of values for the feature ""thetad6"" from the provided dataset. Guessing without any context would not provide meaningful results.";"The range of values for the feature thetad6 in this dataset is as follows:
Min: -2.0
Max: 2.0";;;;;;
362;tau1;44981;pumadyn32nh;numeric;-74.986429;74.982066;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value: Unknown
Maximum value: Unknown";The min and max values for the feature tau1 in the dataset are not provided.;;;;;;
363;tau2;44981;pumadyn32nh;numeric;-74.985392;74.98269;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;The range of values for feature tau2 in the dataset is unknown.;The minimum and maximum values for the feature tau2 can be determined by examining the dataset. However since the dataset is not provided I am unable to provide the exact range.;;;;;;
364;tau3;44981;pumadyn32nh;numeric;-74.99187;74.963215;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";"min(tau3) = <minimum value from the dataset>
max(tau3) = <maximum value from the dataset>";;;;;3.0;3.0
365;tau4;44981;pumadyn32nh;numeric;-74.996111;74.965567;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: -infinity
Maximum: +infinity";"The range of values for the feature tau4 in the dataset is as follows:
Min: -3.1477
Max: 3.0156";;;0.0;;;
366;tau5;44981;pumadyn32nh;numeric;-74.994011;74.964614;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";"To set the range of values for the feature `tau5` we need to look at the minimum and maximum values in the dataset. Here is the range:

Min: Minimum value of `tau5` in the dataset.
Max: Maximum value of `tau5` in the dataset.

Unfortunately without the actual dataset I cannot provide the specific values for the range.";;;;;;
367;dm1;44981;pumadyn32nh;numeric;0.2503663;2.4998416;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";The range of values for the feature 'dm1' is not provided in the given dataset description.;;;;;;
368;dm2;44981;pumadyn32nh;numeric;0.25009217;2.499883;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";"The minimum and maximum values for the feature ""dm2"" are not provided in the given information.";;;;;;
369;dm3;44981;pumadyn32nh;numeric;0.25050915;2.4999468;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";"The range of values for the feature dm3 in the dataset is:

Min: Minimum value of dm3 in the dataset
Max: Maximum value of dm3 in the dataset";;;;;;
370;dm4;44981;pumadyn32nh;numeric;0.2500787;2.4998424;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value: Unknown
Maximum value: Unknown";"The range of values for the feature ""dm4"" is: min = 0 max = Any real number.";;;;;4.0;0.0
371;dm5;44981;pumadyn32nh;numeric;0.25074914;2.4995216;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";For the feature dm5 the range of values is not provided in the dataset description. In order to determine the minimum and maximum values further analysis of the dataset is required.;;;;;;
372;da1;44981;pumadyn32nh;numeric;0.25021364;2.4997496;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";"The range of values for the feature ""da1"" in the dataset is from the minimum value to the maximum value. To determine the exact range we would need access to the dataset.";;;;;;
373;da2;44981;pumadyn32nh;numeric;0.25014345;2.4999086;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;The range of values for the feature da2 is unknown.;"The range of values for the feature ""da2"" is: 

Min: -0.1134
Max: 0.1191";;;;;;
374;da3;44981;pumadyn32nh;numeric;0.25043444;2.4998912;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown  
Maximum: Unknown";"To determine the range of values for the feature ""da3"" in the dataset we need to find the minimum and maximum values. Unfortunately without access to the dataset we cannot provide the specific values. However you can compute the range yourself by examining the ""da3"" feature column in the dataset and finding the minimum and maximum values within that column.";;;;;3.0;3.0
375;da4;44981;pumadyn32nh;numeric;0.25008951;2.4998174;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;The range of values for feature da4 in the dataset is unknown.;"The range of values for the feature ""da4"" is not mentioned in the dataset description. I would need access to the dataset or further information to determine the min and max values for ""da4"".";;;;;4.0;4.0
376;da5;44981;pumadyn32nh;numeric;0.25052101;2.4997306;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";"The range of values for the feature da5 is as follows:

Minimum value: -4.6853
Maximum value: 3.4436";;;;;;
377;db1;44981;pumadyn32nh;numeric;0.25015474;2.4999003;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value of db1: -infinity
Maximum value of db1: +infinity";The range of values for the feature db1 in the dataset is from the minimum value to the maximum value.;;;0.0;;;
378;db2;44981;pumadyn32nh;numeric;0.25065343;2.499937;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value for db2: 0
Maximum value for db2: 1.0";"The range of values for the feature db2 in the dataset is:

Min: Minimum value of db2 in the dataset
Max: Maximum value of db2 in the dataset";;;;;;
379;db3;44981;pumadyn32nh;numeric;0.25008243;2.4995813;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";The range of values for the feature db3 is not provided in the dataset description. To determine the range you would need to analyze the actual values in the dataset.;;;;;;
380;db4;44981;pumadyn32nh;numeric;0.2504841;2.4995562;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: N/A
Maximum: N/A";The min and max value for the feature db4 in the dataset are not provided.;;;;;;
381;db5;44981;pumadyn32nh;numeric;0.25003647;2.4996671;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value for db5: 0
Maximum value for db5: 1";For the feature db5 the range of values is not specified in the given information. To determine the range you would need to analyze the dataset or consult the data source.;;;;;;
382;thetadd6;44981;pumadyn32nh;numeric;-0.11351719;0.13014103;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Unfortunately without knowing the specific dataset and its values it is not possible to determine the range of values for the feature ""thetadd6"". As a data scientist it is important to have access to the data in order to make accurate calculations and estimations.";The range of values for the feature thetadd6 is not given in the dataset description. To determine the range we would need to analyze the actual data.;;;;;;
383;RMSD;44963;physiochemical_protein;numeric;0.0;20.999;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Sorry, but as an AI language model, I don't have access to the specific dataset or its characteristics. Without any additional information, it would be impossible to guess or estimate a range of values for the feature ""RMSD.""";The range of values for the feature RMSD is from 0 to 21.;;;;;0.0;21.0
384;F1;44963;physiochemical_protein;numeric;2392.05;40034.9;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: unknown
Maximum: unknown";The range of values for feature F1 is from 0 to 21.;;;;;;
385;F2;44963;physiochemical_protein;numeric;403.5;15312.0;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: unknown
Maximum: unknown";The minimum and maximum values for feature F2 are not provided in the dataset description. Without that information it is not possible to determine the range of values for feature F2.;;;;;2.0;2.0
386;F3;44963;physiochemical_protein;numeric;0.0925;0.57769;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: Unknown
Maximum: Unknown";The range of values for feature F3 is from 0 to 1.;;;;;;
387;F4;44963;physiochemical_protein;numeric;10.3101;369.317;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: Unknown
Maximum: Unknown";The min and max values for feature F4 are not provided in the given dataset description.;;;;;;
388;F5;44963;physiochemical_protein;numeric;319490.2166;5472011.408;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: 
Maximum:";F5: [0 maximum value in the dataset];;;;;5.0;0.0
389;F6;44963;physiochemical_protein;numeric;31.9704;598.408;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: Unknown
Maximum: Unknown";Based on the given description the range of values for feature F6 is not provided.;;;;;;
390;F7;44963;physiochemical_protein;numeric;0.0;105948.17;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: Cannot determine without knowledge of the dataset.
Maximum: Cannot determine without knowledge of the dataset.";"Based on the given dataset description, the range of values for feature F7 (Euclidian distance) can be summarized as follows:

F7 (Euclidian distance): Minimum value = Unknown, Maximum value = Unknown";;;;;;
391;F8;44963;physiochemical_protein;numeric;0.0;350.0;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: Unknown
Maximum: Unknown";The range of values for feature F8 is from the minimum value to the maximum value in the dataset. However without specific information on the actual values it is not possible to provide an accurate range for feature F8.;;;;;8.0;8.0
392;F9;44963;physiochemical_protein;numeric;15.228;55.3009;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;min(F9) max(F9);The range of values for feature F9 is not provided in the given dataset description.;;;9.0;9.0;;
393;Label;44270;turing_course_binary_data;numeric;0.0;1.0;Turing Binary Classification Dataset (with normalised features);;"Minimum: 0
Maximum: 49";The minimum and maximum values for the feature 'Label' in the Turing Binary Classification Dataset are 0 and 1 respectively.;;;0.0;49.0;0.0;1.0
394;0;44270;turing_course_binary_data;numeric;-6.557421594;3.011165206;Turing Binary Classification Dataset (with normalised features);;The range of values for feature 0 is 0 to 49.;"min: 0
max: 49";;;;;0.0;49.0
395;1;44270;turing_course_binary_data;numeric;-2.372782976;2.855915688;Turing Binary Classification Dataset (with normalised features);;"Minimum: 0
Maximum: 49";Since there is no specific feature mentioned, I cannot provide the range of values for a particular feature. Please specify the feature number or provide additional information.;;;0.0;49.0;;
396;2;44270;turing_course_binary_data;numeric;-2.743479089;2.841569729;Turing Binary Classification Dataset (with normalised features);;"Minimum: 0
Maximum: 49";Based on the given description we need to identify the range of values for Feature 2 in the dataset. Since no specific information about the dataset is provided we cannot determine the range.;;;0.0;49.0;;
397;3;44270;turing_course_binary_data;numeric;-3.046481894;3.362094633;Turing Binary Classification Dataset (with normalised features);;"Minimum: 0
Maximum: 49";The range of values for feature 3 in the Turing Binary Classification Dataset is [0 49].;;;0.0;49.0;;
398;4;44270;turing_course_binary_data;numeric;-3.741947895;3.186604246;Turing Binary Classification Dataset (with normalised features);;"Minimum: 0
Maximum: 49";The range of values for feature 4 in the Turing Binary Classification Dataset is 0 to 49.;;;0.0;49.0;;
399;5;44270;turing_course_binary_data;numeric;-2.732906096;2.776735341;Turing Binary Classification Dataset (with normalised features);;"Minimum: 5
Maximum: 49";The minimum value for feature 5 in the Turing Binary Classification Dataset is 0 and the maximum value is 49.;;;5.0;49.0;;
400;6;44270;turing_course_binary_data;numeric;-2.917721763;3.610133993;Turing Binary Classification Dataset (with normalised features);;;The minimum and maximum values for feature 6 in the Turing Binary Classification Dataset (with normalized features) are not provided in the given information. Please provide the specific values for feature 6 and I will assist you in determining the range.;;;;;6.0;6.0
401;7;44270;turing_course_binary_data;numeric;-3.653304369;4.504961104;Turing Binary Classification Dataset (with normalised features);;;The minimum and maximum values for feature 7 in the Turing Binary Classification Dataset are not provided.;;;;;;
402;8;44270;turing_course_binary_data;numeric;-3.844105676;4.242365376;Turing Binary Classification Dataset (with normalised features);;;Min: 8 Max: 8;;;;;8.0;8.0
403;9;44270;turing_course_binary_data;numeric;-3.828703126;4.251090843;Turing Binary Classification Dataset (with normalised features);;;"Based on the given dataset and feature list here is the range of values for feature 9 (index-based):

Min: 9
Max: 9";;;;;;
404;10;44270;turing_course_binary_data;numeric;-3.650459474;3.638061759;Turing Binary Classification Dataset (with normalised features);;;The range of values for feature 10 is not provided in the dataset description.;;;;;;
405;11;44270;turing_course_binary_data;numeric;-3.780620312;4.589164322;Turing Binary Classification Dataset (with normalised features);;;The min and max values for feature 11 are not provided in the given dataset description.;;;;;;
406;12;44270;turing_course_binary_data;numeric;-3.979526402;3.57194333;Turing Binary Classification Dataset (with normalised features);;;To provide you with the range of values for feature 12 I would need the specific values or the dataset itself.;;;;;;
407;13;44270;turing_course_binary_data;numeric;-3.286132269;4.077405164;Turing Binary Classification Dataset (with normalised features);;;Sorry but as an AI language model I cannot access specific datasets or analyze their features directly. However if given the dataset you can easily determine the minimum and maximum values for feature 13 by examining the dataset yourself or by using data analysis tools such as Python's pandas library or Excel.;;;;;;
408;14;44270;turing_course_binary_data;numeric;-3.617918338;4.005752013;Turing Binary Classification Dataset (with normalised features);;;For the feature 14 in the Turing Binary Classification Dataset the range of values is 0 to 1.;;;;;;
409;15;44270;turing_course_binary_data;numeric;-3.673686504;4.252638968;Turing Binary Classification Dataset (with normalised features);;;The range of values for Feature 15 is not provided in the dataset description.;;;;;;
410;16;44270;turing_course_binary_data;numeric;-3.434010475;4.175181662;Turing Binary Classification Dataset (with normalised features);;;The minimum and maximum values for feature 16 in the Turing Binary Classification Dataset are not provided.;;;;;;
411;17;44270;turing_course_binary_data;numeric;-3.798010779;4.242842645;Turing Binary Classification Dataset (with normalised features);;;Based on the given information the range of values for feature 17 cannot be determined as the values for features 0 to 49 are not provided.;;;;;;
412;18;44270;turing_course_binary_data;numeric;-4.578622404;5.445014301;Turing Binary Classification Dataset (with normalised features);;;The minimum and maximum values for Feature 18 in the Turing Binary Classification Dataset are not provided in the given information.;;;;;;
413;19;44270;turing_course_binary_data;numeric;-3.903017364;3.484305959;Turing Binary Classification Dataset (with normalised features);;;Based on the given description and dataset we cannot determine the range of values for feature 19 without any information about the values in the dataset.;;;;;;
414;20;44270;turing_course_binary_data;numeric;-4.085853144;4.922359252;Turing Binary Classification Dataset (with normalised features);;;Based on the information provided it is not possible to determine the range of values for feature 20 without access to the dataset itself.;;;;;;
415;21;44270;turing_course_binary_data;numeric;-3.50383497;3.845776402;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
416;22;44270;turing_course_binary_data;numeric;-3.577675751;4.256484991;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
417;23;44270;turing_course_binary_data;numeric;-3.329408248;3.679952669;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
418;24;44270;turing_course_binary_data;numeric;-4.364380779;4.706710848;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
419;25;44270;turing_course_binary_data;numeric;-3.712648533;4.231201037;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
420;26;44270;turing_course_binary_data;numeric;-3.806062263;4.211679237;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
421;27;44270;turing_course_binary_data;numeric;-3.998474416;3.851805443;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
422;28;44270;turing_course_binary_data;numeric;-3.510997723;5.056180979;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
423;29;44270;turing_course_binary_data;numeric;-4.076485179;3.759742357;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
424;30;44270;turing_course_binary_data;numeric;-4.05088874;4.205652967;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
425;31;44270;turing_course_binary_data;numeric;-3.747531385;4.667299681;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
426;32;44270;turing_course_binary_data;numeric;-4.407333724;4.363621871;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
427;33;44270;turing_course_binary_data;numeric;-3.848385751;3.883111332;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
428;34;44270;turing_course_binary_data;numeric;-3.357139721;3.421823042;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
429;35;44270;turing_course_binary_data;numeric;-3.706062399;4.409661718;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
430;36;44270;turing_course_binary_data;numeric;-3.832276621;3.495382871;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
431;37;44270;turing_course_binary_data;numeric;-4.11389775;4.472711652;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
432;38;44270;turing_course_binary_data;numeric;-3.829966402;4.090507141;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
433;39;44270;turing_course_binary_data;numeric;-3.776095194;3.537766923;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
434;40;44270;turing_course_binary_data;numeric;-3.81352595;4.298351398;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
435;41;44270;turing_course_binary_data;numeric;-4.006245929;4.079524273;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
436;42;44270;turing_course_binary_data;numeric;-3.937434802;4.310215174;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
437;43;44270;turing_course_binary_data;numeric;-3.559484094;4.817294204;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
438;44;44270;turing_course_binary_data;numeric;-3.550758803;4.516028592;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
439;45;44270;turing_course_binary_data;numeric;-3.781448658;4.057196949;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
440;46;44270;turing_course_binary_data;numeric;-3.71405855;4.377162701;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
441;47;44270;turing_course_binary_data;numeric;-3.388576086;3.536917952;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
442;48;44270;turing_course_binary_data;numeric;-4.004913848;4.18470256;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
443;49;44270;turing_course_binary_data;numeric;-3.526862745;3.954275831;Turing Binary Classification Dataset (with normalised features);;;;;;;;;
444;temperature;44195;Weather;numeric;64.0;85.0;The weather problem is a tiny dataset that we will use repeatedly to illustrate machine learning methods. Entirely fictitious, it supposedly concerns the conditions that are suitable for playing some unspecified game. In general, instances in a dataset are characterized by the values of features, or attributes, that measure different aspects of the instance. In this case there are four attributes: outlook, temperature, humidity, and windy. The outcome is whether to play or not.;;;;;;;;;
445;humidity;44195;Weather;numeric;65.0;96.0;The weather problem is a tiny dataset that we will use repeatedly to illustrate machine learning methods. Entirely fictitious, it supposedly concerns the conditions that are suitable for playing some unspecified game. In general, instances in a dataset are characterized by the values of features, or attributes, that measure different aspects of the instance. In this case there are four attributes: outlook, temperature, humidity, and windy. The outcome is whether to play or not.;;;;;;;;;
446;paramList;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
447;cyclomaticNum;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
448;loopNum;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
449;nestingDegree;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
450;SLOC;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
451;ALOC;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
452;localVars;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
453;localPtrVars;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
454;pointerArgs;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
455;callees;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
456;callers;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
457;height;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
458;conditions;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
459;cmps;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
460;jmps;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
461;ptrAssn;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
462;lable;44150;VulNoneVul;numeric;0.0;1.0;Vulnerability Dataset For Binary Classification;;;;;;;;;
463;AveragePrice;43927;avocado_sales;numeric;0.44;3.25;Historical data on avocado prices and sales volume in multiple US markets. For this version Date column is dropped and month and day information in kept.;;;;;;;;;
