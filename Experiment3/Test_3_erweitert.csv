;name_of_the_features;id_of_the_features;name_of_the_dataset;datatype_of_the_feature;dataset_min_value;dataset_max_value;data_descr;chat_gpt_just_feature;chat_gpt_all_feature;chat_gpt_desc_feature
0;RIDGE;871;pollen;numeric;-23,2839;21,4066;"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').";;;
1;NUB;871;pollen;numeric;-16,3935;17,2583;"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').";;;
2;CRACK;871;pollen;numeric;-31,413;30,3178;"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').";;;
3;WEIGHT;871;pollen;numeric;-34,0352;35,8028;"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').";;;
4;DENSITY;871;pollen;numeric;-12,0391;10,8673;"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').";;;
5;a1;23515;sulfur;numeric;0;1;"&quot;The sulfur recovery unit (SRU) removes environmental pollutants from acid gas
streams before they are released into the atmosphere. Furthermore, elemental sulfur
is recovered as a valuable by-product.&quot;

5 inputs variables are gas and air flows.
2 outputs to predict are H2S and SO2 concentrations

See Appendix A.5 of Fortuna, L., Graziani, S., Rizzo, A., Xibilia, M.G. &quot;Soft Sensors for Monitoring and Control of Industrial Processes&quot; (Springer 2007) for more info.";;;
6;a2;23515;sulfur;numeric;0;1;"&quot;The sulfur recovery unit (SRU) removes environmental pollutants from acid gas
streams before they are released into the atmosphere. Furthermore, elemental sulfur
is recovered as a valuable by-product.&quot;

5 inputs variables are gas and air flows.
2 outputs to predict are H2S and SO2 concentrations

See Appendix A.5 of Fortuna, L., Graziani, S., Rizzo, A., Xibilia, M.G. &quot;Soft Sensors for Monitoring and Control of Industrial Processes&quot; (Springer 2007) for more info.";;;
7;a3;23515;sulfur;numeric;0;1;"&quot;The sulfur recovery unit (SRU) removes environmental pollutants from acid gas
streams before they are released into the atmosphere. Furthermore, elemental sulfur
is recovered as a valuable by-product.&quot;

5 inputs variables are gas and air flows.
2 outputs to predict are H2S and SO2 concentrations

See Appendix A.5 of Fortuna, L., Graziani, S., Rizzo, A., Xibilia, M.G. &quot;Soft Sensors for Monitoring and Control of Industrial Processes&quot; (Springer 2007) for more info.";;;
8;a4;23515;sulfur;numeric;0;1;"&quot;The sulfur recovery unit (SRU) removes environmental pollutants from acid gas
streams before they are released into the atmosphere. Furthermore, elemental sulfur
is recovered as a valuable by-product.&quot;

5 inputs variables are gas and air flows.
2 outputs to predict are H2S and SO2 concentrations

See Appendix A.5 of Fortuna, L., Graziani, S., Rizzo, A., Xibilia, M.G. &quot;Soft Sensors for Monitoring and Control of Industrial Processes&quot; (Springer 2007) for more info.";;;
9;a5;23515;sulfur;numeric;0;1;"&quot;The sulfur recovery unit (SRU) removes environmental pollutants from acid gas
streams before they are released into the atmosphere. Furthermore, elemental sulfur
is recovered as a valuable by-product.&quot;

5 inputs variables are gas and air flows.
2 outputs to predict are H2S and SO2 concentrations

See Appendix A.5 of Fortuna, L., Graziani, S., Rizzo, A., Xibilia, M.G. &quot;Soft Sensors for Monitoring and Control of Industrial Processes&quot; (Springer 2007) for more info.";;;
10;y1;23515;sulfur;numeric;0;1;"&quot;The sulfur recovery unit (SRU) removes environmental pollutants from acid gas
streams before they are released into the atmosphere. Furthermore, elemental sulfur
is recovered as a valuable by-product.&quot;

5 inputs variables are gas and air flows.
2 outputs to predict are H2S and SO2 concentrations

See Appendix A.5 of Fortuna, L., Graziani, S., Rizzo, A., Xibilia, M.G. &quot;Soft Sensors for Monitoring and Control of Industrial Processes&quot; (Springer 2007) for more info.";;;
11;y2;23515;sulfur;numeric;0;1;"&quot;The sulfur recovery unit (SRU) removes environmental pollutants from acid gas
streams before they are released into the atmosphere. Furthermore, elemental sulfur
is recovered as a valuable by-product.&quot;

5 inputs variables are gas and air flows.
2 outputs to predict are H2S and SO2 concentrations

See Appendix A.5 of Fortuna, L., Graziani, S., Rizzo, A., Xibilia, M.G. &quot;Soft Sensors for Monitoring and Control of Industrial Processes&quot; (Springer 2007) for more info.";;;
12;productId;42183;dataset_sales;numeric;0;1;Dataset sales;;;
13;machineId;42183;dataset_sales;numeric;0;1;Dataset sales;;;
14;temp;42183;dataset_sales;numeric;0;1;Dataset sales;;;
15;weather_condition_id;42183;dataset_sales;numeric;0;1;Dataset sales;;;
16;isholiday;42183;dataset_sales;numeric;0;1;Dataset sales;;;
17;daysoff;42183;dataset_sales;numeric;0;1;Dataset sales;;;
18;year;42183;dataset_sales;numeric;0;1;Dataset sales;;;
19;month;42183;dataset_sales;numeric;0;1;Dataset sales;;;
20;day;42183;dataset_sales;numeric;0;1;Dataset sales;;;
21;week_day;42183;dataset_sales;numeric;0;1;Dataset sales;;;
22;avail0;42183;dataset_sales;numeric;0;1;Dataset sales;;;
23;avail1;42183;dataset_sales;numeric;0;1;Dataset sales;;;
24;avail2;42183;dataset_sales;numeric;0;1;Dataset sales;;;
25;sales;42183;dataset_sales;numeric;3;85;Dataset sales;;;
26;stdv;42183;dataset_sales;numeric;0;47;Dataset sales;;;
27;qts;42545;stock_fardamento02;numeric;1;833;"**Author**:   

**Source**: Unknown - Date unknown  

**Please cite**:   



valores de saida de fardamento com temperaturas, admiss&otilde;es e demiss&otilde;es";;;
28;Material;42545;stock_fardamento02;numeric;5367;65024;"**Author**:   

**Source**: Unknown - Date unknown  

**Please cite**:   



valores de saida de fardamento com temperaturas, admiss&otilde;es e demiss&otilde;es";;;
29;pp;42545;stock_fardamento02;numeric;0;20,1;"**Author**:   

**Source**: Unknown - Date unknown  

**Please cite**:   



valores de saida de fardamento com temperaturas, admiss&otilde;es e demiss&otilde;es";;;
30;TEMP;42545;stock_fardamento02;numeric;8,4;26;"**Author**:   

**Source**: Unknown - Date unknown  

**Please cite**:   



valores de saida de fardamento com temperaturas, admiss&otilde;es e demiss&otilde;es";;;
31;adm;42545;stock_fardamento02;numeric;28;230;"**Author**:   

**Source**: Unknown - Date unknown  

**Please cite**:   



valores de saida de fardamento com temperaturas, admiss&otilde;es e demiss&otilde;es";;;
32;Dem;42545;stock_fardamento02;numeric;36;239;"**Author**:   

**Source**: Unknown - Date unknown  

**Please cite**:   



valores de saida de fardamento com temperaturas, admiss&otilde;es e demiss&otilde;es";;;
33;1990;43809;GDP-per-capita-all-countries;numeric;424,823989;72906,52012;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
34;1991;43809;GDP-per-capita-all-countries;numeric;324,6360462;71753,72956;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
35;1992;43809;GDP-per-capita-all-countries;numeric;300,9789673;71567,82752;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
36;1993;43809;GDP-per-capita-all-countries;numeric;327,3411883;70082,38933;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
37;1994;43809;GDP-per-capita-all-countries;numeric;342,4329064;72471,68729;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
38;1995;43809;GDP-per-capita-all-countries;numeric;345,1363376;74994,38062;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
39;1996;43809;GDP-per-capita-all-countries;numeric;379,151098;76848,79224;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
40;1997;43809;GDP-per-capita-all-countries;numeric;417,8391769;80390,06411;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
41;1998;43809;GDP-per-capita-all-countries;numeric;452,6620933;77421,10866;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
42;1999;43809;GDP-per-capita-all-countries;numeric;469,1280301;76654,25591;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
43;2000;43809;GDP-per-capita-all-countries;numeric;455,8150878;86169,39432;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
44;2001;43809;GDP-per-capita-all-countries;numeric;443,5747121;88138,42244;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
45;2002;43809;GDP-per-capita-all-countries;numeric;450,4504171;92091,2766;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
46;2003;43809;GDP-per-capita-all-countries;numeric;469,7704098;91451,60854;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
47;2004;43809;GDP-per-capita-all-countries;numeric;498,9798703;101329,4787;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
48;2005;43809;GDP-per-capita-all-countries;numeric;528,9747838;97768,57115;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
49;2006;43809;GDP-per-capita-all-countries;numeric;555,799958;107541,4558;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
50;2007;43809;GDP-per-capita-all-countries;numeric;586,9952654;109362,5076;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
51;2008;43809;GDP-per-capita-all-countries;numeric;615,0719745;111255,9944;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
52;2009;43809;GDP-per-capita-all-countries;numeric;616,6586194;108953,6771;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
53;2010;43809;GDP-per-capita-all-countries;numeric;646,2953953;117518,7009;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
54;2011;43809;GDP-per-capita-all-countries;numeric;682,007332;124024,5682;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
55;2012;43809;GDP-per-capita-all-countries;numeric;719,914259;126618,3727;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
56;2013;43809;GDP-per-capita-all-countries;numeric;699,5928807;139962,1749;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
57;2014;43809;GDP-per-capita-all-countries;numeric;710,8121645;137832,9615;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
58;2015;43809;GDP-per-capita-all-countries;numeric;744,7345426;123822,0833;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
59;2016;43809;GDP-per-capita-all-countries;numeric;743,9035976;123573,6308;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
60;2017;43809;GDP-per-capita-all-countries;numeric;737,9785829;124609,3041;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
61;2018;43809;GDP-per-capita-all-countries;numeric;744,182072;126898,4259;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
62;2019;43809;GDP-per-capita-all-countries;numeric;;;"Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate.
This dataset contains the GDP based on Purchasing Power Parity (PPP). 
GDP comparisons using PPP are arguably more useful than those using nominal GDP when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income
Acknowledgement
Thanks to World Databank";;;
63;Unnamed:_0;43825;Nutritional-values-for-common-foods-and-products;numeric;0;8788;"Context
I found this data occasionally and I just could not pass by. So I hope that this dasatet will help anyone who interested in food nutrition values.
Content
This dataset contains nutrition values for about 8.8k types of food. The features names is very self-explanatory, so I'll not make a description for them.";;;
64;calories;43825;Nutritional-values-for-common-foods-and-products;numeric;0;902;"Context
I found this data occasionally and I just could not pass by. So I hope that this dasatet will help anyone who interested in food nutrition values.
Content
This dataset contains nutrition values for about 8.8k types of food. The features names is very self-explanatory, so I'll not make a description for them.";;;
65;lucopene;43825;Nutritional-values-for-common-foods-and-products;numeric;0;0;"Context
I found this data occasionally and I just could not pass by. So I hope that this dasatet will help anyone who interested in food nutrition values.
Content
This dataset contains nutrition values for about 8.8k types of food. The features names is very self-explanatory, so I'll not make a description for them.";;;
66;Year;43831;Consumer-Price-Index;numeric;2013;2020;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
67;Cereals_and_products;43831;Consumer-Price-Index;numeric;107,5;152,7;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
68;Meat_and_fish;43831;Consumer-Price-Index;numeric;106,3;197;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
69;Egg;43831;Consumer-Price-Index;numeric;102,7;157;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
70;Milk_and_products;43831;Consumer-Price-Index;numeric;103,6;155,6;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
71;Oils_and_fats;43831;Consumer-Price-Index;numeric;101,1;138,2;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
72;Fruits;43831;Consumer-Price-Index;numeric;102,3;157,5;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
73;Vegetables;43831;Consumer-Price-Index;numeric;101,4;231,5;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
74;Pulses_and_products;43831;Consumer-Price-Index;numeric;103,5;191,6;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
75;Sugar_and_Confectionery;43831;Consumer-Price-Index;numeric;85,3;123,9;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
76;Spices;43831;Consumer-Price-Index;numeric;101,8;159,8;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
77;Non-alcoholic_beverages;43831;Consumer-Price-Index;numeric;104,8;142,1;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
78;Prepared_meals,_snacks,_sweets_etc.;43831;Consumer-Price-Index;numeric;106,7;161,8;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
79;Food_and_beverages;43831;Consumer-Price-Index;numeric;105,5;157;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
80;Pan,_tobacco_and_intoxicants;43831;Consumer-Price-Index;numeric;105,1;186,7;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
81;Clothing;43831;Consumer-Price-Index;numeric;105,9;154,7;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
82;Footwear;43831;Consumer-Price-Index;numeric;105;150;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
83;Clothing_and_footwear;43831;Consumer-Price-Index;numeric;105,8;154,1;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
84;Housing;43831;Consumer-Price-Index;numeric;100,3;155,6;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
85;Fuel_and_light;43831;Consumer-Price-Index;numeric;105,4;153,4;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
86;Household_goods_and_services;43831;Consumer-Price-Index;numeric;104,8;151,8;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
87;Health;43831;Consumer-Price-Index;numeric;104;158,2;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
88;Transport_and_communication;43831;Consumer-Price-Index;numeric;103,2;141,4;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
89;Recreation_and_amusement;43831;Consumer-Price-Index;numeric;102,9;153,2;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
90;Education;43831;Consumer-Price-Index;numeric;103,5;161,9;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
91;Personal_care_and_effects;43831;Consumer-Price-Index;numeric;102,1;152,2;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
92;Miscellaneous;43831;Consumer-Price-Index;numeric;103,7;151,7;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
93;General_index;43831;Consumer-Price-Index;numeric;104;152,7;Consumer Price Indices (CPI) measure changes over time in general level of prices of goods and services that households acquire for the purpose of consumption. CPI numbers are widely used as a macroeconomic indicator of inflation, as a tool by governments and central banks for inflation targeting and for monitoring price stability, and as deflators in the national accounts. CPI is also used for indexing dearness allowance to employees for increase in prices. CPI is therefore considered as one of the most important economic indicators. For construction of CPI numbers, two requisite components are weighting diagrams (consumption patterns) and price data collected at regular intervals. The data refers to group wise all India Consumer Price Index for Rural  Urban with base year 2010. The dataset is published by Central Statistical Office and released on 12th of every month.;;;
94;Unnamed:_0;43836;features-and-price-of-computer-components;numeric;0;919;"Context
The most common website that provided computer hardware components we chose the Newegg website it has hardware systems, Buy PC Parts, Laptops, Electronics  More. Now Shipping to Saudi Arabia! Track Order and more with fast shipping.
to determine which the best component with the best price here we can provide you this dataset. 
Content
Implement the Web scraping by using  the python language and using selenium on python, to extract the data from newegg that contain CPU, GPU, power, ram, monitor, storage 
the** data contains**:

the brand name
items_Decribtion
ratings
prices
Category (CPU, GPU,motherboard, ram, powersuplly, storage  )

Acknowledgements
Thank you for the MISK academy and general assembly for guiding us.
Inspiration
we recommend using EDA to clean data and also recommend to build model predictive price or build assumption analysis";;;
95;MEAN_TEMPERATURE_CALGARY;43843;Eighty-years-of-Canadian-climate-data;numeric;-37,5;26,2;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
96;TOTAL_PRECIPITATION_CALGARY;43843;Eighty-years-of-Canadian-climate-data;numeric;0;92,6;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
97;MEAN_TEMPERATURE_EDMONTON;43843;Eighty-years-of-Canadian-climate-data;numeric;-40,8;24,7;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
98;TOTAL_PRECIPITATION_EDMONTON;43843;Eighty-years-of-Canadian-climate-data;numeric;0;75,6;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
99;MEAN_TEMPERATURE_HALIFAX;43843;Eighty-years-of-Canadian-climate-data;numeric;-23,5;27;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
100;TOTAL_PRECIPITATION_HALIFAX;43843;Eighty-years-of-Canadian-climate-data;numeric;0;218,2;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
101;MEAN_TEMPERATURE_MONCTON;43843;Eighty-years-of-Canadian-climate-data;numeric;-27,4;27,2;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
102;TOTAL_PRECIPITATION_MONCTON;43843;Eighty-years-of-Canadian-climate-data;numeric;0;131,8;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
103;MEAN_TEMPERATURE_MONTREAL;43843;Eighty-years-of-Canadian-climate-data;numeric;-30,9;30,3;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
104;TOTAL_PRECIPITATION_MONTREAL;43843;Eighty-years-of-Canadian-climate-data;numeric;0;93,5;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
105;MEAN_TEMPERATURE_OTTAWA;43843;Eighty-years-of-Canadian-climate-data;numeric;-31,3;30;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
106;TOTAL_PRECIPITATION_OTTAWA;43843;Eighty-years-of-Canadian-climate-data;numeric;0;135,4;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
107;MEAN_TEMPERATURE_QUEBEC;43843;Eighty-years-of-Canadian-climate-data;numeric;-30,6;28,9;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
108;TOTAL_PRECIPITATION_QUEBEC;43843;Eighty-years-of-Canadian-climate-data;numeric;0;108,5;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
109;MEAN_TEMPERATURE_SASKATOON;43843;Eighty-years-of-Canadian-climate-data;numeric;-41,7;32,1;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
110;TOTAL_PRECIPITATION_SASKATOON;43843;Eighty-years-of-Canadian-climate-data;numeric;0;96,6;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
111;MEAN_TEMPERATURE_STJOHNS;43843;Eighty-years-of-Canadian-climate-data;numeric;-21,3;25,2;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
112;TOTAL_PRECIPITATION_STJOHNS;43843;Eighty-years-of-Canadian-climate-data;numeric;0;121,2;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
113;MEAN_TEMPERATURE_TORONTO;43843;Eighty-years-of-Canadian-climate-data;numeric;-24,7;31,8;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
114;TOTAL_PRECIPITATION_TORONTO;43843;Eighty-years-of-Canadian-climate-data;numeric;0;126;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
115;MEAN_TEMPERATURE_VANCOUVER;43843;Eighty-years-of-Canadian-climate-data;numeric;-14,5;28,4;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
116;TOTAL_PRECIPITATION_VANCOUVER;43843;Eighty-years-of-Canadian-climate-data;numeric;0;91,6;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
117;MEAN_TEMPERATURE_WHITEHORSE;43843;Eighty-years-of-Canadian-climate-data;numeric;-48,1;23,9;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
118;TOTAL_PRECIPITATION_WHITEHORSE;43843;Eighty-years-of-Canadian-climate-data;numeric;0;44,9;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
119;MEAN_TEMPERATURE_WINNIPEG;43843;Eighty-years-of-Canadian-climate-data;numeric;-38,6;30,9;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
120;TOTAL_PRECIPITATION_WINNIPEG;43843;Eighty-years-of-Canadian-climate-data;numeric;0;83,8;"This dataset has been compiled from public sources. The dataset consists of daily temperatures and precipitation from 13 Canadian centres. Precipitation is either rain or snow (likely snow in winter months). In 1940, there is daily data for seven out of the 13 centres, but by 1960 there is daily data from all 13 centres, with the occasional missing value.
Few of Canadas weather stations have been operating continuously, so we did need to patch together the data. Our source data is from https://climate-change.canada.ca/climate-data//daily-climate-data and here are the weather stations that we queried:
CALGARY INTL A
CALGARY INT'L A
EDMONTON INTL A
EDMONTON INT'L A
HALIFAX STANFIELD INT'L A
HALIFAX STANFIELD INT'L A
MONCTON A
MONCTON A
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL
MONTREAL/PIERRE ELLIOTT TRUDEAU INTL A
OTTAWA INTL A
OTTAWA MACDONALD-CARTIER INT'L A
QUEBEC/JEAN LESAGE INTL
QUEBEC/JEAN LESAGE INTL A
SASKATOON DIEFENBAKER INT'L A
SASKATOON INTL A
ST JOHN'S A
ST JOHNS WEST CLIMATE
TORONTO INTL A
TORONTO LESTER B. PEARSON INT'L A
VANCOUVER INTL A
VANCOUVER INT'L A
WHITEHORSE A
WHITEHORSE A
WINNIPEG RICHARDSON INT'L A
WINNIPEG THE FORKS
Suggested uses: The data is suitable for time series forecasting.  At Penny Analytics, we are using this dataset to demonstrate outlier detection (anomaly detection) in multiple time series and here is the relevant blogpost: https://pennyanalytics.com/2020/01/28/climate-change-canadian-weather-anomalies-are-now-warmer-and-wetter/";;;
121;total_cases;43844;Coronavirus-Worldwide-Dataset;numeric;0;20075600;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
122;new_cases;43844;Coronavirus-Worldwide-Dataset;numeric;-2461;298083;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
123;total_deaths;43844;Coronavirus-Worldwide-Dataset;numeric;0;736372;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
124;new_deaths;43844;Coronavirus-Worldwide-Dataset;numeric;-1918;10504;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
125;total_cases_per_million;43844;Coronavirus-Worldwide-Dataset;numeric;0;39312,614;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
126;new_cases_per_million;43844;Coronavirus-Worldwide-Dataset;numeric;-265,189;4944,376;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
127;total_deaths_per_million;43844;Coronavirus-Worldwide-Dataset;numeric;0;1237,551;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
128;new_deaths_per_million;43844;Coronavirus-Worldwide-Dataset;numeric;-41,023;200,04;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
129;new_tests;43844;Coronavirus-Worldwide-Dataset;numeric;-3743;926876;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
130;total_tests;43844;Coronavirus-Worldwide-Dataset;numeric;1;61792571;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
131;total_tests_per_thousand;43844;Coronavirus-Worldwide-Dataset;numeric;0;707,957;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
132;new_tests_per_thousand;43844;Coronavirus-Worldwide-Dataset;numeric;-0,398;22,359;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
133;new_tests_smoothed;43844;Coronavirus-Worldwide-Dataset;numeric;0;822470;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
134;new_tests_smoothed_per_thousand;43844;Coronavirus-Worldwide-Dataset;numeric;0;15,82;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
135;tests_per_case;43844;Coronavirus-Worldwide-Dataset;numeric;1,398;47299;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
136;positive_rate;43844;Coronavirus-Worldwide-Dataset;numeric;0;0,715;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
137;stringency_index;43844;Coronavirus-Worldwide-Dataset;numeric;0;100;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
138;population;43844;Coronavirus-Worldwide-Dataset;numeric;809;7794798729;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
139;population_density;43844;Coronavirus-Worldwide-Dataset;numeric;0,137;19347,5;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
140;median_age;43844;Coronavirus-Worldwide-Dataset;numeric;15,1;48,2;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
141;aged_65_older;43844;Coronavirus-Worldwide-Dataset;numeric;1,144;27,049;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
142;aged_70_older;43844;Coronavirus-Worldwide-Dataset;numeric;0,526;18,493;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
143;gdp_per_capita;43844;Coronavirus-Worldwide-Dataset;numeric;661,24;116935,6;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
144;extreme_poverty;43844;Coronavirus-Worldwide-Dataset;numeric;0,1;77,6;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
145;cardiovasc_death_rate;43844;Coronavirus-Worldwide-Dataset;numeric;79,37;724,417;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
146;diabetes_prevalence;43844;Coronavirus-Worldwide-Dataset;numeric;0,99;23,36;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
147;female_smokers;43844;Coronavirus-Worldwide-Dataset;numeric;0,1;44;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
148;male_smokers;43844;Coronavirus-Worldwide-Dataset;numeric;7,7;78,1;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
149;handwashing_facilities;43844;Coronavirus-Worldwide-Dataset;numeric;1,188;98,999;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
150;hospital_beds_per_thousand;43844;Coronavirus-Worldwide-Dataset;numeric;0,1;13,8;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
151;life_expectancy;43844;Coronavirus-Worldwide-Dataset;numeric;53,28;86,75;"Context
From World Health Organization - On 31 December 2019, WHO was alerted to several cases of pneumonia in Wuhan City, Hubei Province of China. The virus did not match any other known virus. This raised concern because when a virus is new, we do not know how it affects people.
So daily level information on the affected people can give some interesting insights when it is made available to the broader data science community.
The European CDC publishes daily statistics on the COVID-19 pandemic. Not just for Europe, but for the entire world. We rely on the ECDC as they collect and harmonize data from around the world which allows us to compare what is happening in different countries.
Content
This dataset has daily level information on the number of affected cases, deaths and recovery etc. from coronavirus. It also contains various other parameters like average life expectancy, population density, smocking population etc. which users can find useful in further prediction that they need to make.
The data is available from 31 Dec,2019.
Inspiration
Give people weekly data so that they can use it to make accurate predictions.";;;
152;Unnamed:_0;43845;Music-Dataset--1950-to-2019;numeric;0;82451;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
153;release_date;43845;Music-Dataset--1950-to-2019;numeric;1950;2019;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
154;len;43845;Music-Dataset--1950-to-2019;numeric;1;199;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
155;dating;43845;Music-Dataset--1950-to-2019;numeric;0,000290782;0,647705684;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
156;violence;43845;Music-Dataset--1950-to-2019;numeric;0,000284495;0,981781376;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
157;world/life;43845;Music-Dataset--1950-to-2019;numeric;0,000290782;0,962105263;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
158;night/time;43845;Music-Dataset--1950-to-2019;numeric;0,000289185;0,97368421;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
159;shake_the_audience;43845;Music-Dataset--1950-to-2019;numeric;0,000284495;0,497463245;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
160;family/gospel;43845;Music-Dataset--1950-to-2019;numeric;0,000289185;0,54530302;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
161;romantic;43845;Music-Dataset--1950-to-2019;numeric;0,000284495;0,940789474;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
162;communication;43845;Music-Dataset--1950-to-2019;numeric;0,000290782;0,645829372;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
163;obscene;43845;Music-Dataset--1950-to-2019;numeric;0,000289185;0,992297817;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
164;music;43845;Music-Dataset--1950-to-2019;numeric;0,000289185;0,956937798;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
165;movement/places;43845;Music-Dataset--1950-to-2019;numeric;0,000284495;0,638020876;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
166;light/visual_perceptions;43845;Music-Dataset--1950-to-2019;numeric;0,000284495;0,667781877;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
167;family/spiritual;43845;Music-Dataset--1950-to-2019;numeric;0,000284495;0,618072522;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
168;like/girls;43845;Music-Dataset--1950-to-2019;numeric;0,000284495;0,594458741;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
169;sadness;43845;Music-Dataset--1950-to-2019;numeric;0,000284495;0,981424148;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
170;feelings;43845;Music-Dataset--1950-to-2019;numeric;0,000289185;0,958810069;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
171;danceability;43845;Music-Dataset--1950-to-2019;numeric;0,005415358;0,99350157;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
172;loudness;43845;Music-Dataset--1950-to-2019;numeric;0;1;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
173;acousticness;43845;Music-Dataset--1950-to-2019;numeric;2,81E-07;1;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
174;instrumentalness;43845;Music-Dataset--1950-to-2019;numeric;0;0,996963563;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
175;valence;43845;Music-Dataset--1950-to-2019;numeric;0;1;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
176;energy;43845;Music-Dataset--1950-to-2019;numeric;0;1;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
177;age;43845;Music-Dataset--1950-to-2019;numeric;0,014285714;1;"Context
This dataset provides a list of lyrics from 1950 to 2019 describing music metadata as sadness, danceability, loudness, acousticness, etc. Authors also provide some information as lyrics which can be used to natural language processing. 
Acknowledgements
Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; Frana, Mardnio (2020), Music Dataset: Lyrics and Metadata from 1950 to 2019, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3";;;
178;age;43904;law-school-admission-bianry;numeric;3;69;"Law School Admissions (Binarized) 
 Survey among students attending law school in the U.S. in 1991. 
 The dataset was obtained from the R-package fairml. 
 The response variable has been changed to a binary version: Whether ugpa is greater than 3.
 The race1 variables has been binarized to labels white and non-white.";;;
179;decile1;43904;law-school-admission-bianry;numeric;1;10;"Law School Admissions (Binarized) 
 Survey among students attending law school in the U.S. in 1991. 
 The dataset was obtained from the R-package fairml. 
 The response variable has been changed to a binary version: Whether ugpa is greater than 3.
 The race1 variables has been binarized to labels white and non-white.";;;
180;decile3;43904;law-school-admission-bianry;numeric;1;10;"Law School Admissions (Binarized) 
 Survey among students attending law school in the U.S. in 1991. 
 The dataset was obtained from the R-package fairml. 
 The response variable has been changed to a binary version: Whether ugpa is greater than 3.
 The race1 variables has been binarized to labels white and non-white.";;;
181;fam_inc;43904;law-school-admission-bianry;numeric;1;5;"Law School Admissions (Binarized) 
 Survey among students attending law school in the U.S. in 1991. 
 The dataset was obtained from the R-package fairml. 
 The response variable has been changed to a binary version: Whether ugpa is greater than 3.
 The race1 variables has been binarized to labels white and non-white.";;;
182;lsat;43904;law-school-admission-bianry;numeric;11;48;"Law School Admissions (Binarized) 
 Survey among students attending law school in the U.S. in 1991. 
 The dataset was obtained from the R-package fairml. 
 The response variable has been changed to a binary version: Whether ugpa is greater than 3.
 The race1 variables has been binarized to labels white and non-white.";;;
183;CreditScore;45062;shrutime;numeric;350;850;This data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.Source: https://www.kaggle.com/datasets/shrutimechlearn/churn-modelling;;;
184;Age;45062;shrutime;numeric;18;92;This data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.Source: https://www.kaggle.com/datasets/shrutimechlearn/churn-modelling;;;
185;Balance;45062;shrutime;numeric;0;250898,09;This data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.Source: https://www.kaggle.com/datasets/shrutimechlearn/churn-modelling;;;
186;EstimatedSalary;45062;shrutime;numeric;11,58;199992,48;This data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.Source: https://www.kaggle.com/datasets/shrutimechlearn/churn-modelling;;;
187;class;45062;shrutime;numeric;0;1;This data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.Source: https://www.kaggle.com/datasets/shrutimechlearn/churn-modelling;;;
188;year;45106;MTPL_SHAP_Tutorial;numeric;2018;2019;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";;;
189;town;45106;MTPL_SHAP_Tutorial;numeric;0;1;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";;;
190;driver_age;45106;MTPL_SHAP_Tutorial;numeric;18;88;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";;;
191;car_weight;45106;MTPL_SHAP_Tutorial;numeric;950;3120;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";;;
192;car_power;45106;MTPL_SHAP_Tutorial;numeric;50;341;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";;;
193;car_age;45106;MTPL_SHAP_Tutorial;numeric;0;23;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";;;
194;claim_nb;45106;MTPL_SHAP_Tutorial;numeric;0;4;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";;;
195;year;45106;MTPL_SHAP_Tutorial;numeric;2018;2019;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";;;
196;town;45106;MTPL_SHAP_Tutorial;numeric;0;1;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";;;
197;driver_age;45106;MTPL_SHAP_Tutorial;numeric;18;88;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";;;
198;car_weight;45106;MTPL_SHAP_Tutorial;numeric;950;3120;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";;;
199;car_power;45106;MTPL_SHAP_Tutorial;numeric;50;341;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";;;
200;car_age;45106;MTPL_SHAP_Tutorial;numeric;0;23;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";;;
201;claim_nb;45106;MTPL_SHAP_Tutorial;numeric;0;4;"This motor third-part liability (MTPL) pricing dataset describes 1 Mio insurance policies and their corresponding claim counts, see
      Mayer, M., Meier, D. and Wuthrich, M.V. (2023) SHAP for Actuaries: Explain any Model. http://dx.doi.org/10.2139/ssrn.4389797";;;
202;normalized-losses;45080;autos;numeric;37,625922;273,722584;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 65
Maximum: 256";"min: -3

max: +3"
203;wheel-base;45080;autos;numeric;83,069816;127,194382;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;min: 86.6  max: 120.9;"The range of values for the feature ""wheel-base"" in the dataset is the minimum and maximum values."
204;length;45080;autos;numeric;134,019251;216,548564;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: Assumed to be 150 inches
Maximum: Assumed to be 230 inches";"The range of values for the feature ""length"" in the dataset is as follows:
Min: 141.1
Max: 208.1"
205;width;45080;autos;numeric;60,270307;75,596629;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: Unknown
Maximum: Unknown";"The range of values for the feature ""width"" in the dataset is approximately 60.3 to 72.3."
206;height;45080;autos;numeric;46,979469;62,50061;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Based on the given dataset features, the range of values for the feature ""height"" is between a minimum of 47 inches and a maximum of 59 inches.";"The range of values for the feature ""height"" in the given dataset is as follows:
Min: 47.8
Max: 59.8"
207;curb-weight;45080;autos;numeric;1509,552607;4716,212861;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 1488
Maximum: 4066";"The range of values for the feature ""curb-weight"" in the given dataset is:

Min: 1488

Max: 4066"
208;engine-size;45080;autos;numeric;9,891578;381,012483;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 61
Maximum: 326";"The range of values for the feature ""engine-size"" in the dataset is as follows: 

Minimum: 61 
Maximum: 326"
209;bore;45080;autos;numeric;2,554261;4,072103;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 2.54
Maximum: 3.94";"The range of values for the feature ""bore"" in the dataset is 2.54-3.94."
210;stroke;45080;autos;numeric;1,713911;4,458423;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 2.36
Maximum: 4.17";"The range of values for the feature ""stroke"" in the dataset is 2.07 to 4.17."
211;compression-ratio;45080;autos;numeric;-11,806341;42,161764;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 7
Maximum: 23";"Based on the given dataset, the range of values for the feature ""compression-ratio"" is 7.0 to 23.0."
212;horsepower;45080;autos;numeric;39,520425;303,922617;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 48
Maximum: 288";"The range of values for the feature ""horsepower"" in the dataset is from 48 to 288."
213;peak-rpm;45080;autos;numeric;3406,968387;6931,555398;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: 3800
Maximum: 7000";"min: 4150
max: 6600"
214;city-mpg;45080;autos;numeric;11,110762;54,824617;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"The range of values for the feature ""city-mpg"" is 8 to 49.";"min: 13
max: 49"
215;highway-mpg;45080;autos;numeric;11,470231;61,696829;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;Minimum: 10, Maximum: 54;"The range of values for the feature ""highway-mpg"" in this dataset is 16 to 54."
216;price;45080;autos;numeric;-12038,16054;63918,81917;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum price: $5118
Maximum price: $45400";"The range of values for the feature ""price"" in the dataset is: 
Minimum price: $5,118 
Maximum price: $45,400."
217;class;45080;autos;numeric;-3;3;"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Source: https://www.kaggle.com/datasets/toramky/automobile-dataset";;"Minimum: compact

Maximum: suv";"The range of values for the feature ""class"" in the dataset is given as follows:

Min: -
Max: -"
218;Vehicle_Reference_df_res;45079;road-safety;numeric;1;37;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 18";"The range of values for the feature ""Vehicle_Reference_df_res"" cannot be determined without analyzing the dataset."
219;Vehicle_Type;45079;road-safety;numeric;2;98;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;Vehicle_Type range: min = 1, max = 20;"Based on the given information, the min and max values for the feature ""Vehicle_Type"" cannot be determined without access to the actual dataset."
220;Vehicle_Manoeuvre;45079;road-safety;numeric;1;18;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: 18";"The minimum and maximum values for the feature ""Vehicle_Manoeuvre"" in the dataset are not provided."
221;Vehicle_Location-Restricted_Lane;45079;road-safety;numeric;0;9;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 9";"Min: 0
Max: 2"
222;Hit_Object_in_Carriageway;45079;road-safety;numeric;0;12;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 9";"The range of values for the feature ""Hit_Object_in_Carriageway"" in the dataset is not provided. Please refer to the dataset or provide more information to determine the range."
223;Hit_Object_off_Carriageway;45079;road-safety;numeric;0;11;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Min: 0
Max: 9";"The range of values for the feature ""Hit_Object_off_Carriageway"" is not provided in the list of features."
224;Age_of_Driver;45079;road-safety;numeric;12;97;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum Age_of_Driver: 0
Maximum Age_of_Driver: 120";"The range of values for the feature ""Age_of_Driver"" in this dataset is from the minimum value to the maximum value. However, without the dataset itself, I cannot provide the specific min and max values for the age of the driver."
225;Age_Band_of_Driver;45079;road-safety;numeric;3;11;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 16
Maximum: 96";"min: 1
max: 25"
226;Engine_Capacity_(CC);45079;road-safety;numeric;48;18000;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0 CC
Maximum: Unknown";"Min Engine_Capacity_(CC): 1
Max Engine_Capacity_(CC): 99999"
227;Propulsion_Code;45079;road-safety;numeric;1;12;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: 9";"The range of values for the feature ""Propulsion_Code"" in the dataset is not provided."
228;Age_of_Vehicle;45079;road-safety;numeric;1;91;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 99";Age_of_Vehicle: Min = 1, Max = 36
229;Location_Easting_OSGR;45079;road-safety;numeric;90609;655282;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 999999";min: 23242, max: 655646
230;Location_Northing_OSGR;45079;road-safety;numeric;10628;1142228;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0

Maximum: 999999";"min: -100000
max: 1760000"
231;Longitude;45079;road-safety;numeric;-6,311427;1,758443;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: -180
Maximum: 180";"The range of values for the feature ""Longitude"" in the dataset is approximately -11.511 to 1.7595."
232;Latitude;45079;road-safety;numeric;49,915618;60,161843;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: -90
Maximum: 90";The min value of the feature Latitude is not provided in the dataset description. The max value of the feature Latitude is also not provided in the dataset description.
233;Police_Force;45079;road-safety;numeric;1;98;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: 98";"Min: 1
Max: 98"
234;Number_of_Vehicles;45079;road-safety;numeric;1;37;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: Unknown";"The range of values for the feature ""Number_of_Vehicles"" in the dataset is from the minimum value of 1 to the maximum value of 67."
235;Number_of_Casualties;45079;road-safety;numeric;1;38;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;Minimum: 0  Maximum: 10;"The range of values for the feature ""Number_of_Casualties"" in this dataset is from 1 to the maximum number of casualties reported in a single accident."
236;Local_Authority_(District);45079;road-safety;numeric;1;940;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;Minimum: 1, Maximum: 999;"Min: 1

Max: 941"
237;1st_Road_Number;45079;road-safety;numeric;0;9914;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1st_Road_Number = 1
Maximum: 1st_Road_Number = 9999";"The range of values for the feature ""1st_Road_Number"" is: 
Minimum: 1 
Maximum: 9998"
238;2nd_Road_Number;45079;road-safety;numeric;0;9999;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 9999";"min(2nd_Road_Number) = 0
max(2nd_Road_Number) = 9999"
239;Vehicle_Reference_df;45079;road-safety;numeric;1;27;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: 30";"Min: 1
Max: 5"
240;Casualty_Reference;45079;road-safety;numeric;1;38;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: Unknown (not enough information provided)";"The range of values for the feature ""Casualty_Reference"" in the dataset is from 1 to the maximum value in the dataset."
241;Age_of_Casualty;45079;road-safety;numeric;0;101;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 120";"The range of values for the feature ""Age_of_Casualty"" in the given dataset is from the minimum value of 0 to the maximum value of 98."
242;Age_Band_of_Casualty;45079;road-safety;numeric;1;11;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: 11";"The range of values for the feature ""Age_Band_of_Casualty"" in the dataset is from the minimum value to the maximum value. However, without access to the actual dataset, it is not possible to determine the specific range of values."
243;Pedestrian_Location;45079;road-safety;numeric;0;10;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;Minimum: 1 Maximum: 8;"Based on the given dataset, the range of values for the feature ""Pedestrian_Location"" cannot be determined without further information or exploration of the dataset."
244;Pedestrian_Movement;45079;road-safety;numeric;0;9;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;Minimum: 1 Maximum: 9;"To set a range of values for the feature ""Pedestrian_Movement"", we need to know the minimum and maximum values from the dataset. Unfortunately, the dataset description provided does not include this information. Could you please provide the minimum and maximum values for the ""Pedestrian_Movement"" feature?"
245;Casualty_Type;45079;road-safety;numeric;0;98;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1

Maximum: 9";"The range of values for the feature ""Casualty_Type"" is as follows:
Min: 1
Max: 9"
246;Casualty_IMD_Decile;45079;road-safety;numeric;1;10;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 1
Maximum: 10";The range of values for the feature Casualty_IMD_Decile is not possible to determine without access to the actual dataset or further information.
247;class;45079;road-safety;numeric;1;2;Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979, and the maker and model information of vehicles involved in the respective accident.This version includes data up to 2015.;;"Minimum: 0
Maximum: 1";"The range of values for the feature ""class"" is not provided in the dataset description."
248;0;45077;qsar;numeric;2;6,496;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 0
Maximum: 40";The range of values for feature 0 in the QSAR biodegradation dataset is from the minimum value to the maximum value.
249;1;45077;qsar;numeric;0,8039;9,1775;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 0
Maximum: 1";The range of values for feature 1 in the QSAR biodegradation dataset is [0, 40].
250;7;45077;qsar;numeric;0;60,7;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 7
Maximum: 7";"Min: -3.105
Max: 8.456"
251;11;45077;qsar;numeric;-5,256;4,722;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 11
Maximum: 11";min: 0, max: 40
252;12;45077;qsar;numeric;1,544;5,701;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 11
Maximum: 14";Based on the given dataset, the range of values for feature 12 is not specified. To determine the range, you would need to access the dataset directly or refer to the reference paper mentioned in the dataset description.
253;13;45077;qsar;numeric;0;4,491;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;The range of values for feature 13 in the dataset is 0-40.;Based on the provided details, the range of values for feature 13 in the dataset is not available.
254;14;45077;qsar;numeric;4,174;12,609;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"minimum: 0
maximum: 40";The minimum and maximum values for feature 14 in the QSAR biodegradation dataset are not provided in the given information.
255;16;45077;qsar;numeric;0,957;1,311;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 16
Maximum: 16";Based on the given dataset, the range of values for feature 16 is not provided.
256;17;45077;qsar;numeric;1,022;1,377;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 17

Maximum: 17";Based on the given dataset description, the minimum and maximum values for feature 17 cannot be determined without access to the actual data.
257;21;45077;qsar;numeric;0,863;1,641;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 21  
Maximum: 21";The range of values for feature 21 in the QSAR biodegradation dataset is not provided.
258;26;45077;qsar;numeric;1;2,859;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 26
Maximum: 26";The range of values for feature 26 in the QSAR biodegradation dataset is not provided in the information provided.
259;27;45077;qsar;numeric;-1,099;1,073;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Min: 27
Max: 27";Based on the given dataset description, the range of values for feature 27 cannot be determined without examining the actual data.
260;29;45077;qsar;numeric;0;71,167;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Min: 29
Max: 29";Based on the given dataset, the minimum and maximum values for feature 29 are not provided.
261;30;45077;qsar;numeric;0,444;17,537;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;Minimum: 30, Maximum: 37;Based on the provided dataset, the range of values for feature 30 is not known.
262;35;45077;qsar;numeric;2,267;10,695;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum value: 35 
Maximum value: 35";Based on the given dataset description, the range of values for feature 35 cannot be determined without further information.
263;36;45077;qsar;numeric;1,467;5,825;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 36
Maximum: 36";The range of values for feature 36 in the QSAR biodegradation dataset is unknown as the specific values are not provided in the given dataset description.
264;38;45077;qsar;numeric;4,917;14,7;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 38
Maximum: 38";"Min: 0
Max: 38"
265;2;45077;qsar;numeric;0;12;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 2
Maximum: 40";The range of values for feature 2 in the QSAR biodegradation dataset is from the minimum value to the maximum value. Unfortunately, without the actual dataset, the exact range cannot be determined.
266;4;45077;qsar;numeric;0;36;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 2
Maximum: 40";The range of values for feature 4 in the QSAR biodegradation dataset is 0 to 1.
267;5;45077;qsar;numeric;0;13;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 2
Maximum: 40";The range of values for feature 5 in the QSAR biodegradation dataset is from min: 0 to max: 2.326.
268;6;45077;qsar;numeric;0;18;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 6 

Maximum: 6";
269;8;45077;qsar;numeric;0;24;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 4
Maximum: 10";The range of values for feature 8 is not provided in the Dataset description.
270;9;45077;qsar;numeric;0;12;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 9
Maximum: 9";The range of values for feature 9 in the QSAR biodegradation dataset is from the minimum value to the maximum value.
271;10;45077;qsar;numeric;0;44;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;The range of values for feature 10 in the dataset can be 6 to 10.;For feature 10 in the QSAR biodegradation dataset, the range of values is not specified in the given information.
272;15;45077;qsar;numeric;0;40;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;The range of values for feature 15 in the dataset is 0 to 40.;The minimum and maximum values for feature 15 in the QSAR biodegradation dataset are not provided in the given information. To determine the range, you would need to analyze the dataset or access the data source directly.
273;31;45077;qsar;numeric;0;8;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Min: 31
Max: 31";The range of values for feature 31 is not provided in the dataset description.
274;32;45077;qsar;numeric;0;12;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 32
Maximum: 32";The range of values for feature 32 is as follows: min = 3.113, max = 8.464.
275;33;45077;qsar;numeric;0;18;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 33
Maximum: 33";Based on the given dataset description, I cannot determine the range of values for feature 33 without access to the actual data.
276;37;45077;qsar;numeric;0;8;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 37
Maximum: 37";The minimum and maximum values for feature 37 in the QSAR biodegradation dataset are not provided in the given information.
277;40;45077;qsar;numeric;0;27;The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group. The research leading to these results has received funding from the European Communitys Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation;;"Minimum: 40
Maximum: 40";"The min and max values for feature 40 in the QSAR biodegradation dataset are as follows:

Min: 0
Max: 1"
278;Customer_care_calls;45074;Shipping;numeric;2;7;An international e-commerce company based wants to discover key insights from their customer database. They want to use some of the most advanced machine learning techniques to study their customers. The company sells electronic products;;"Minimum: 1
Maximum: 10";The range of values for the feature Customer_care_calls is between the minimum value of 1 and the maximum value of 10.
279;Customer_rating;45074;Shipping;numeric;1;5;An international e-commerce company based wants to discover key insights from their customer database. They want to use some of the most advanced machine learning techniques to study their customers. The company sells electronic products;;"Minimum: 1
Maximum: 5";Min: 1, Max: 5
280;Prior_purchases;45074;Shipping;numeric;2;10;An international e-commerce company based wants to discover key insights from their customer database. They want to use some of the most advanced machine learning techniques to study their customers. The company sells electronic products;;"Minimum: 0
Maximum: 100";"The range of values for the feature ""Prior_purchases"" is from 0 (min) to an unspecified maximum value (max)."
281;Discount_offered;45074;Shipping;numeric;1;65;An international e-commerce company based wants to discover key insights from their customer database. They want to use some of the most advanced machine learning techniques to study their customers. The company sells electronic products;;"Minimum: 0
Maximum: 100";"min: 0
max: 100"
282;Weight_in_gms;45074;Shipping;numeric;1001;7846;An international e-commerce company based wants to discover key insights from their customer database. They want to use some of the most advanced machine learning techniques to study their customers. The company sells electronic products;;"Min: 100 g

Max: 5000 g";"Min: 0 gms
Max: Unknown"
283;class;45074;Shipping;numeric;0;1;An international e-commerce company based wants to discover key insights from their customer database. They want to use some of the most advanced machine learning techniques to study their customers. The company sells electronic products;;"Minimum: 0
Maximum: 1";"The range of values for the feature ""class"" is min: 1 and max: 10."
284;lineNo;45073;eye_movements;numeric;1;10927;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 1
Maximum: It depends on the number of lines in the dataset.";"The min and max values for the feature ""lineNo"" in this dataset are not mentioned in the provided description. Additional information or access to the dataset would be required to determine the range of values for this feature."
285;assgNo;45073;eye_movements;numeric;1;336;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 1
Maximum: Unknown";"The range of values for the feature ""assgNo"" in the dataset is from the minimum value to the maximum value. Unfortunately, without access to the dataset, we cannot provide the specific range. Please refer to the dataset source for the actual minimum and maximum values."
286;prevFixDur;45073;eye_movements;numeric;0;1036;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: unspecified";"The range of values for the feature ""prevFixDur"" is not provided in the dataset description."
287;firstfixDur;45073;eye_movements;numeric;20;777;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: unknown";"The range of values for the feature ""firstfixDur"" in the dataset is:

Min: 0
Max: (Unknown)"
288;firstPassFixDur;45073;eye_movements;numeric;20;1392;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";"min(firstPassFixDur) = 0.0  
max(firstPassFixDur) = 78.5"
289;nextFixDur;45073;eye_movements;numeric;0;1133;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";"The minimum value for the feature ""nextFixDur"" is not provided in the given dataset description."
290;firstSaccLen;45073;eye_movements;numeric;0;1686,4404;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";"The min and max values for the feature ""firstSaccLen"" are not provided in the given description."
291;lastSaccLen;45073;eye_movements;numeric;0;1924,1347;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";The range of values for the feature lastSaccLen is not provided in the given dataset description.
292;prevFixPos;45073;eye_movements;numeric;0;1070,3616;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";The range of values for the feature prevFixPos is not provided in the given dataset description.
293;landingPos;45073;eye_movements;numeric;1,118;1348,7161;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum landingPos: 0
Maximum landingPos: Unknown";"Based on the given dataset description, the feature ""landingPos"" represents the landing position of the eye fixations on each word in the eye movement trajectory. To provide a range of values for this feature, we would need access to the actual dataset. Without the dataset, it is not possible to determine the minimum and maximum values for the ""landingPos"" feature."
294;leavingPos;45073;eye_movements;numeric;0,5;1343,5316;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Any positive value within the dataset.";"The range for the feature ""leavingPos"" is not provided in the dataset description."
295;totalFixDur;45073;eye_movements;numeric;20;1392;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";"The range of values for the feature ""totalFixDur"" in the dataset is not provided in the given information."
296;meanFixDur;45073;eye_movements;numeric;20;757;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";"Based on the given dataset description, we can see that one of the features is ""meanFixDur"". To determine the range of values for this feature, we need to analyze the dataset itself. Unfortunately, without access to the dataset, we cannot provide the specific range of values for ""meanFixDur"" (i.e., the minimum and maximum values)."
297;regressLen;45073;eye_movements;numeric;0;24987;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: Unknown";"The range of values for the feature ""regressLen"" in the given dataset is as follows:

Min: Minimum value of regressLen in the dataset
Max: Maximum value of regressLen in the dataset"
298;regressDur;45073;eye_movements;numeric;0;11140;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: unknown";"Based on the given dataset description, the minimum and maximum values for the feature ""regressDur"" are not provided."
299;pupilDiamMax;45073;eye_movements;numeric;-4,3255;4,4917;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: -infinity
Maximum: +infinity";"The range of values for the feature ""pupilDiamMax"" from the given dataset is not available without analyzing the data."
300;pupilDiamLag;45073;eye_movements;numeric;-1,206;4,4917;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0.1
Maximum: 5.0";"Based on the given dataset description, the range of values for the feature ""pupilDiamLag"" is not provided. Therefore, it is not possible to determine the minimum and maximum values for this feature."
301;timePrtctg;45073;eye_movements;numeric;0,0005;0,318;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 0
Maximum: 100";"The range of values for the feature ""timePrtctg"" is not provided in the dataset description. Therefore, we cannot determine the minimum and maximum values for this feature."
302;titleNo;45073;eye_movements;numeric;1;10;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 1
Maximum: unknown";"The range of values for the feature ""titleNo"" in the dataset is from the minimum value to the maximum value. Unfortunately, without access to the dataset, we cannot provide the specific numerical range."
303;wordNo;45073;eye_movements;numeric;1;10;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;"Minimum: 1
Maximum: Unknown (data not provided)";"The minimum value for the feature ""wordNo"" is not specified in the provided information."
304;class;45073;eye_movements;numeric;0;1;Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/Competition 1 (preprocessed data) A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.;;Minimum: 0, Maximum: 1;"The range of the feature ""class"" in the dataset is from ""I"" to ""R""."
305;wage_eur;45012;fifa;numeric;500;350000;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;Minimum: 0, Maximum: 1000000;"Min wage_eur: 1000
Max wage_eur: 5000000"
306;age;45012;fifa;numeric;16;54;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 15
Maximum: 45";"Min age: 16
Max age: 45"
307;height_cm;45012;fifa;numeric;155;206;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 150 cm
Maximum: 220 cm";"Based on the given dataset, the range of values for the feature ""height_cm"" can be determined by finding the minimum and maximum values."
308;weight_kg;45012;fifa;numeric;49;110;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;Min: 50 kg, Max: 100 kg;The range of values for the feature weight_kg is approximately: min = 50 kg, max = 110 kg.
309;overall;45012;fifa;numeric;47;93;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: Unknown
Maximum: Unknown";"The range of values for the feature ""overall"" in the dataset is from the minimum value of overall to the maximum value of overall."
310;potential;45012;fifa;numeric;49;95;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 1
Maximum: 99";"To set a range of values for the feature ""potential"" in the dataset, we need to find the minimum and maximum values. 
From the given dataset description, the min and max values for the feature ""potential"" are as follows:

Min: Unknown
Max: Unknown

Unfortunately, without access to the actual dataset, we cannot determine the specific values for the range of ""potential""."
311;attacking_crossing;45012;fifa;numeric;6;94;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;;"Based on the information provided, I will provide the range of values for the feature ""attacking_crossing"" from the dataset.

Minimum value: 1
Maximum value: 99"
312;attacking_finishing;45012;fifa;numeric;2;95;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 99";"The range of values for the feature ""attacking_finishing"" is:

Minimum value: unknown
Maximum value: unknown

Since no specific information about the range of values for the feature ""attacking_finishing"" is provided, we cannot determine the minimum and maximum values."
313;attacking_heading_accuracy;45012;fifa;numeric;5;93;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 99";"The range of values for the feature ""attacking_heading_accuracy"" in the dataset is from the minimum value to the maximum value."
314;attacking_short_passing;45012;fifa;numeric;7;94;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 100";"The range of values for the feature ""attacking_short_passing"" is not specified in the given dataset. In order to determine the min and max values for this feature, you would need to analyze the dataset or consult the data source."
315;attacking_volleys;45012;fifa;numeric;3;90;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 99";"The range of values for the feature ""attacking_volleys"" is from the minimum to the maximum value in the dataset. Unfortunately, I don't have access to the dataset, so I cannot provide the exact range."
316;skill_dribbling;45012;fifa;numeric;4;96;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 99";"Min skill_dribbling: 1
Max skill_dribbling: 99"
317;skill_curve;45012;fifa;numeric;6;94;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 1  
Maximum: 99";"The range of values for the feature ""skill_curve"" is from the minimum to the maximum value in the dataset."
318;skill_fk_accuracy;45012;fifa;numeric;4;94;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 99";The range of values for the feature skill_fk_accuracy in the dataset is from 1 to 99.
319;skill_long_passing;45012;fifa;numeric;9;93;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 100";"The min value for the feature ""skill_long_passing"" is not provided in the given dataset. The max value for this feature is also not provided."
320;skill_ball_control;45012;fifa;numeric;8;96;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 1
Maximum: 99";The range of values for the feature skill_ball_control is [1, 99].
321;movement_acceleration;45012;fifa;numeric;14;97;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 0
Maximum: 100";"The range of values for the feature ""movement_acceleration"" in the dataset is from the minimum to the maximum value."
322;movement_sprint_speed;45012;fifa;numeric;15;97;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 1
Maximum: 99";"The range of values for the feature ""movement_sprint_speed"" in the dataset is from the minimum value to the maximum value."
323;movement_agility;45012;fifa;numeric;18;96;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: Undetermined
Maximum: Undetermined";"The range of values for the feature ""movement_agility"" from the dataset is as follows:

Min: The minimum value of movement_agility.
Max: The maximum value of movement_agility."
324;movement_reactions;45012;fifa;numeric;25;94;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: unknown
Maximum: unknown";"The range of values for the feature ""movement_reactions"" in the dataset is from the minimum value to the maximum value."
325;movement_balance;45012;fifa;numeric;15;96;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum value: 0
Maximum value: 100";"The range of values for the feature ""movement_balance"" in the dataset is minimum: 10, maximum: 98."
326;defending_standing_tackle;45012;fifa;numeric;5;93;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum value: 0
Maximum value: 99";"The range of values for the feature ""defending_standing_tackle"" is not provided in the dataset description."
327;defending_sliding_tackle;45012;fifa;numeric;5;92;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Min: 0
Max: 99";"The range of values for the feature ""defending_sliding_tackle"" in the dataset is from the minimum value to the maximum value."
328;goalkeeping_diving;45012;fifa;numeric;2;91;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 1
Maximum: 99";"The range of values for the feature ""goalkeeping_diving"" in the dataset is minimum = 14 and maximum = 92."
329;goalkeeping_handling;45012;fifa;numeric;2;92;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 5
Maximum: 95";
330;goalkeeping_kicking;45012;fifa;numeric;2;93;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 5
Maximum: 95";"The range of values for the feature ""goalkeeping_kicking"" is as follows:

Minimum: Unknown
Maximum: Unknown

Without access to the dataset or information on the range of values, it is not possible to determine the exact minimum and maximum values for the feature."
331;goalkeeping_positioning;45012;fifa;numeric;2;92;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 1
Maximum: 99";"The range of values for the feature ""goalkeeping_positioning"" is from 1 to 99."
332;goalkeeping_reflexes;45012;fifa;numeric;2;90;"**Data Description**

The datasets provided include the players data for the Career Mode from FIFA 22.
It only includes male football players with known wage.

The goal is to predict the wage of the player based on his attributes.

**Attribute Description**

The features describe self-explanatory properties and skills of the player.";;"Minimum: 1
Maximum: 99";"The range of values for the feature ""goalkeeping_reflexes"" is from 1 to 99."
333;passenger_count;44986;nyc_taxi_green;numeric;0;9;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 1
Maximum: 6";"The range of values for the feature ""passenger_count"" in the dataset is from 0 (minimum value) to 9 (maximum value)."
334;tip_amount;44986;nyc_taxi_green;numeric;-10,56;250,7;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 0
Maximum: 100";The range of values for the feature 'tip_amount' in the dataset is minimum = 0 and maximum = unknown.
335;tolls_amount;44986;nyc_taxi_green;numeric;0;98;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 0
Maximum: 200";"The minimum and maximum values for the feature ""tolls_amount"" are not provided in the given information."
336;total_amount;44986;nyc_taxi_green;numeric;-63,36;712,38;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 0
Maximum: 100000";"The range of values for the feature ""total_amount"" in the given dataset can be determined by examining the minimum and maximum values. 

Min total_amount: $0.00 
Max total_amount: $338.00"
337;lpep_pickup_datetime_day;44986;nyc_taxi_green;numeric;1;31;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;Minimum: 1, Maximum: 31;"The range of values for the feature ""lpep_pickup_datetime_day"" is from the minimum value to the maximum value in the dataset."
338;lpep_pickup_datetime_hour;44986;nyc_taxi_green;numeric;0;23;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 0
Maximum: 23";"The minimum and maximum values for the feature ""lpep_pickup_datetime_hour"" are not provided in the given dataset. To determine the range, you would need to analyze the data or calculate it based on the actual values in the dataset."
339;lpep_pickup_datetime_minute;44986;nyc_taxi_green;numeric;0;59;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 0 
Maximum: 59";"The range of values for the feature ""lpep_pickup_datetime_minute"" is from 0 to 59."
340;lpep_dropoff_datetime_day;44986;nyc_taxi_green;numeric;1;31;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 1

Maximum: 31";"The range of values for the feature ""lpep_dropoff_datetime_day"" is the minimum value and the maximum value in the dataset."
341;lpep_dropoff_datetime_hour;44986;nyc_taxi_green;numeric;0;23;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 0
Maximum: 23";"The range of values for the feature ""lpep_dropoff_datetime_hour"" is from 0 to 23."
342;lpep_dropoff_datetime_minute;44986;nyc_taxi_green;numeric;0;59;"**Data Description**

The dataset includes New York City Taxi and Limousine Commission (TLC) trips of the green line in December 2016. All trips are paid with a credit card leaving some tip.

The variable 'tip_amount' was chosen as target variable.

**Attribute Description**

1. *VendorID* - A code indicating the LPEP provider that provided the record. 1: Creative Mobile Technologies, LLC; 2: VeriFone Inc.
2. *store_and_fwd_flag*
3. *RatecodeID*
4. *PULocationID*
5. *DOLocationID* - TLC Taxi Zone in which the taximeter was disengaged.
6. *passenger_count* - the number of passengers in the vehicle. This is a driver-entered value
7. *extra* - miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges
8. *mta_tax* - $0.50 MTA tax that is automatically triggered based on the metered rate in use.
9. *tip_amount* - target feature
10. *tolls_amount*
11. *improvement_surcharge* - $0.30 improvement surcharge assessed on hailed trips at the flag drop
12. *total_amount*
13. *trip_type* - 1: Street-hail, 2: Dispatch
14. *lpep_pickup_datetime_day*
15. *lpep_pickup_datetime_hour*
16. *lpep_pickup_datetime_minute*
17. *lpep_dropoff_datetime_day*
18. *lpep_dropoff_datetime_hour*
19. *lpep_dropoff_datetime_minute*";;"Minimum: 0
Maximum: 59";"The range of values for the feature ""lpep_dropoff_datetime_minute"" in the dataset is from 0 to 59."
343;ln_votes_pop;44985;space_ga;numeric;-3,057045019;0,100083459;"**Data Description**

The dataset contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.

Given population, education levels in the population, number of owned houses, incomes and coordinates, the goal is to predict the number of votes per population (logarithmic).

**Attribute Description**

1. *ln_votes_pop* - logarithm of total number of votes - logarithm of populaiton (ln(votes/pop)), target feature
2. *pop* - the population in each county of 18 years of age or older
3. *education* - the population in each county with a 12th grade or higher education
4. *houses* - the number of owner-occupied housing units
5. *income* - the aggregate income
6. *xcoord* - X spatial coordinate of the county
7. *ycoord* - Y spatial coordinate of the county";;"Minimum: -∞
Maximum: ∞";The range of values for the feature ln_votes_pop is not provided in the dataset description.
344;pop;44985;space_ga;numeric;4,369447852;15,51043143;"**Data Description**

The dataset contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.

Given population, education levels in the population, number of owned houses, incomes and coordinates, the goal is to predict the number of votes per population (logarithmic).

**Attribute Description**

1. *ln_votes_pop* - logarithm of total number of votes - logarithm of populaiton (ln(votes/pop)), target feature
2. *pop* - the population in each county of 18 years of age or older
3. *education* - the population in each county with a 12th grade or higher education
4. *houses* - the number of owner-occupied housing units
5. *income* - the aggregate income
6. *xcoord* - X spatial coordinate of the county
7. *ycoord* - Y spatial coordinate of the county";;min(pop), max(pop);"The range of values for the feature ""pop"" is from the minimum value to the maximum value in the dataset. 

Min: Minimum value of ""pop"" feature
Max: Maximum value of ""pop"" feature"
345;education;44985;space_ga;numeric;3,63758616;14,94512462;"**Data Description**

The dataset contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.

Given population, education levels in the population, number of owned houses, incomes and coordinates, the goal is to predict the number of votes per population (logarithmic).

**Attribute Description**

1. *ln_votes_pop* - logarithm of total number of votes - logarithm of populaiton (ln(votes/pop)), target feature
2. *pop* - the population in each county of 18 years of age or older
3. *education* - the population in each county with a 12th grade or higher education
4. *houses* - the number of owner-occupied housing units
5. *income* - the aggregate income
6. *xcoord* - X spatial coordinate of the county
7. *ycoord* - Y spatial coordinate of the county";;"Minimum: 0
Maximum: 100";education (min, max): 12.0, 100.0
346;houses;44985;space_ga;numeric;3,135494216;14,09571247;"**Data Description**

The dataset contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.

Given population, education levels in the population, number of owned houses, incomes and coordinates, the goal is to predict the number of votes per population (logarithmic).

**Attribute Description**

1. *ln_votes_pop* - logarithm of total number of votes - logarithm of populaiton (ln(votes/pop)), target feature
2. *pop* - the population in each county of 18 years of age or older
3. *education* - the population in each county with a 12th grade or higher education
4. *houses* - the number of owner-occupied housing units
5. *income* - the aggregate income
6. *xcoord* - X spatial coordinate of the county
7. *ycoord* - Y spatial coordinate of the county";;"min(houses) = unknown,
max(houses) = unknown";"The range of values for the feature ""houses"" is from the minimum value of 65 to the maximum value of 5,456."
347;income;44985;space_ga;numeric;7,586803535;17,94399105;"**Data Description**

The dataset contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.

Given population, education levels in the population, number of owned houses, incomes and coordinates, the goal is to predict the number of votes per population (logarithmic).

**Attribute Description**

1. *ln_votes_pop* - logarithm of total number of votes - logarithm of populaiton (ln(votes/pop)), target feature
2. *pop* - the population in each county of 18 years of age or older
3. *education* - the population in each county with a 12th grade or higher education
4. *houses* - the number of owner-occupied housing units
5. *income* - the aggregate income
6. *xcoord* - X spatial coordinate of the county
7. *ycoord* - Y spatial coordinate of the county";;"Minimum income: 0
Maximum income: 9999999999999";Minimum value for feature 'income': Not provided in the given dataset description.
348;xcoord;44985;space_ga;numeric;-124229902;-67609990;"**Data Description**

The dataset contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.

Given population, education levels in the population, number of owned houses, incomes and coordinates, the goal is to predict the number of votes per population (logarithmic).

**Attribute Description**

1. *ln_votes_pop* - logarithm of total number of votes - logarithm of populaiton (ln(votes/pop)), target feature
2. *pop* - the population in each county of 18 years of age or older
3. *education* - the population in each county with a 12th grade or higher education
4. *houses* - the number of owner-occupied housing units
5. *income* - the aggregate income
6. *xcoord* - X spatial coordinate of the county
7. *ycoord* - Y spatial coordinate of the county";;"Min: -180
Max: 180";"The minimum and maximum values for the feature ""xcoord"" in the given dataset are not provided."
349;ycoord;44985;space_ga;numeric;25117067;48833747;"**Data Description**

The dataset contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.

Given population, education levels in the population, number of owned houses, incomes and coordinates, the goal is to predict the number of votes per population (logarithmic).

**Attribute Description**

1. *ln_votes_pop* - logarithm of total number of votes - logarithm of populaiton (ln(votes/pop)), target feature
2. *pop* - the population in each county of 18 years of age or older
3. *education* - the population in each county with a 12th grade or higher education
4. *houses* - the number of owner-occupied housing units
5. *income* - the aggregate income
6. *xcoord* - X spatial coordinate of the county
7. *ycoord* - Y spatial coordinate of the county";;"Minimum: lowest value in the dataset for ycoord
Maximum: highest value in the dataset for ycoord";"The range of values for the feature ""ycoord"" in the dataset is: 

Min: Minimum value of ycoord in the dataset
Max: Maximum value of ycoord in the dataset"
350;theta1;44981;pumadyn32nh;numeric;-2,3559788;2,3560933;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value for theta1: Unknown
Maximum value for theta1: Unknown";"The range of values for the feature theta1 in the dataset is:
Minimum: -3.1416
Maximum: 3.1416"
351;theta2;44981;pumadyn32nh;numeric;-2,3560923;2,3559392;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";To determine the range of values for the feature theta2, we need to analyze the dataset. Unfortunately, you have not provided the dataset itself. Without the dataset, it is not possible to calculate the minimum and maximum values for theta2. Please provide the dataset so that I can help you with this task.
352;theta3;44981;pumadyn32nh;numeric;-2,3561923;2,3560761;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: No information provided

Maximum: No information provided";"Min: Theta3 cannot be determined without the actual data. 

Max: Theta3 cannot be determined without the actual data."
353;theta4;44981;pumadyn32nh;numeric;-2,3561554;2,3554484;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value of theta4: Unknown.
Maximum value of theta4: Unknown.";The range of values for the feature theta4 in the dataset can be determined by calculating its minimum and maximum values.
354;theta5;44981;pumadyn32nh;numeric;-2,3558931;2,3557348;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";To determine the range of values for the feature theta5, we need to look at the dataset or the actual values. As a language model AI, I don't have access to the specific dataset and cannot compute the range for you. However, you can compute it using any programming language or statistical software by finding the minimum and maximum values of theta5 from the dataset.
355;theta6;44981;pumadyn32nh;numeric;-2,356149;2,3555894;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value: -Infinity 
Maximum value: +Infinity";"The range of values for the feature theta6 in the dataset is:
Min: -pi (approximately -3.1416)
Max: pi (approximately 3.1416)"
356;thetad1;44981;pumadyn32nh;numeric;-2,3558835;2,3561468;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";"Min: -10.0
Max: 10.0"
357;thetad2;44981;pumadyn32nh;numeric;-2,3553779;2,3558753;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: -∞
Maximum: +∞";"The range of values for the feature thetad2 in this dataset is:

Minimum: Not provided
Maximum: Not provided"
358;thetad3;44981;pumadyn32nh;numeric;-2,3555789;2,3558805;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";The range of values for the feature thetad3 in the dataset is from the minimum value to the maximum value.
359;thetad4;44981;pumadyn32nh;numeric;-2,3557642;2,3561293;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value: Unknown
Maximum value: Unknown";The range of values for the feature thetad4 is from the minimum value to the maximum value in the dataset.
360;thetad5;44981;pumadyn32nh;numeric;-2,3559181;2,3559142;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: unknown
Maximum: unknown";The feature thetad5 has a range of values from the minimum to the maximum in the dataset.
361;thetad6;44981;pumadyn32nh;numeric;-2,3556409;2,3558045;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Sorry, but as a language model AI, I don't have access to the specific data or domain knowledge required to determine the range of values for the feature ""thetad6"" from the provided dataset. Guessing without any context would not provide meaningful results.";"The range of values for the feature thetad6 in this dataset is as follows:
Min: -2.0
Max: 2.0"
362;tau1;44981;pumadyn32nh;numeric;-74,986429;74,982066;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value: Unknown
Maximum value: Unknown";The min and max values for the feature tau1 in the dataset are not provided.
363;tau2;44981;pumadyn32nh;numeric;-74,985392;74,98269;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;The range of values for feature tau2 in the dataset is unknown.;The minimum and maximum values for the feature tau2 can be determined by examining the dataset. However, since the dataset is not provided, I am unable to provide the exact range.
364;tau3;44981;pumadyn32nh;numeric;-74,99187;74,963215;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";"min(tau3) = <minimum value from the dataset>
max(tau3) = <maximum value from the dataset>"
365;tau4;44981;pumadyn32nh;numeric;-74,996111;74,965567;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: -infinity
Maximum: +infinity";"The range of values for the feature tau4 in the dataset is as follows:
Min: -3.1477
Max: 3.0156"
366;tau5;44981;pumadyn32nh;numeric;-74,994011;74,964614;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";"To set the range of values for the feature `tau5`, we need to look at the minimum and maximum values in the dataset. Here is the range:

Min: Minimum value of `tau5` in the dataset.
Max: Maximum value of `tau5` in the dataset.

Unfortunately, without the actual dataset, I cannot provide the specific values for the range."
367;dm1;44981;pumadyn32nh;numeric;0,2503663;2,4998416;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";The range of values for the feature 'dm1' is not provided in the given dataset description.
368;dm2;44981;pumadyn32nh;numeric;0,25009217;2,499883;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";"The minimum and maximum values for the feature ""dm2"" are not provided in the given information."
369;dm3;44981;pumadyn32nh;numeric;0,25050915;2,4999468;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";"The range of values for the feature dm3 in the dataset is:

Min: Minimum value of dm3 in the dataset
Max: Maximum value of dm3 in the dataset"
370;dm4;44981;pumadyn32nh;numeric;0,2500787;2,4998424;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value: Unknown
Maximum value: Unknown";"The range of values for the feature ""dm4"" is: min = 0, max = Any real number."
371;dm5;44981;pumadyn32nh;numeric;0,25074914;2,4995216;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";For the feature dm5, the range of values is not provided in the dataset description. In order to determine the minimum and maximum values, further analysis of the dataset is required.
372;da1;44981;pumadyn32nh;numeric;0,25021364;2,4997496;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";"The range of values for the feature ""da1"" in the dataset is from the minimum value to the maximum value. To determine the exact range, we would need access to the dataset."
373;da2;44981;pumadyn32nh;numeric;0,25014345;2,4999086;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;The range of values for the feature da2 is unknown.;"The range of values for the feature ""da2"" is: 

Min: -0.1134
Max: 0.1191"
374;da3;44981;pumadyn32nh;numeric;0,25043444;2,4998912;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown  
Maximum: Unknown";"To determine the range of values for the feature ""da3"" in the dataset, we need to find the minimum and maximum values. Unfortunately, without access to the dataset, we cannot provide the specific values. However, you can compute the range yourself by examining the ""da3"" feature column in the dataset and finding the minimum and maximum values within that column."
375;da4;44981;pumadyn32nh;numeric;0,25008951;2,4998174;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;The range of values for feature da4 in the dataset is unknown.;"The range of values for the feature ""da4"" is not mentioned in the dataset description. I would need access to the dataset or further information to determine the min and max values for ""da4""."
376;da5;44981;pumadyn32nh;numeric;0,25052101;2,4997306;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";"The range of values for the feature da5 is as follows:

Minimum value: -4.6853
Maximum value: 3.4436"
377;db1;44981;pumadyn32nh;numeric;0,25015474;2,4999003;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value of db1: -infinity
Maximum value of db1: +infinity";The range of values for the feature db1 in the dataset is from the minimum value to the maximum value.
378;db2;44981;pumadyn32nh;numeric;0,25065343;2,499937;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value for db2: 0
Maximum value for db2: 1.0";"The range of values for the feature db2 in the dataset is:

Min: Minimum value of db2 in the dataset
Max: Maximum value of db2 in the dataset"
379;db3;44981;pumadyn32nh;numeric;0,25008243;2,4995813;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: Unknown
Maximum: Unknown";The range of values for the feature db3 is not provided in the dataset description. To determine the range, you would need to analyze the actual values in the dataset.
380;db4;44981;pumadyn32nh;numeric;0,2504841;2,4995562;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum: N/A
Maximum: N/A";The min and max value for the feature db4 in the dataset are not provided.
381;db5;44981;pumadyn32nh;numeric;0,25003647;2,4996671;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Minimum value for db5: 0
Maximum value for db5: 1";For the feature db5, the range of values is not specified in the given information. To determine the range, you would need to analyze the dataset or consult the data source.
382;thetadd6;44981;pumadyn32nh;numeric;-0,11351719;0,13014103;"**Data Description**

A realistic simulation of the dynamics of a Puma 560 robot arm. The task in this dataset is to predict the angular acceleration of one of the robot arm's links. The task is nonlinear and has high noise.

The similator got as input the angular positions, velocities and torques and other dynamic parameters of the Puma arm.

The goal was to predict the acceleration of link 6 *thetad6*.

**Attribute Description**

1. *theta[1-6]* - angular positions of links 1 to 6
2. *thetad[1-6]* - angular velocities of links 1 to 6
3. *tau[1-5]* - torques at joints 1 to 5
4. *dm[1-5]* - change in mass of links 1 to 5
5. *da[1-5]* - change in length of links 1 to 5
6. *db[1-5]* - change in viscous friction of links 1 - 5
7. *thetadd6* - acceleration of link 6, target feature";;"Unfortunately, without knowing the specific dataset and its values, it is not possible to determine the range of values for the feature ""thetadd6"". As a data scientist, it is important to have access to the data in order to make accurate calculations and estimations.";The range of values for the feature thetadd6 is not given in the dataset description. To determine the range, we would need to analyze the actual data.
383;RMSD;44963;physiochemical_protein;numeric;0;20,999;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Sorry, but as an AI language model, I don't have access to the specific dataset or its characteristics. Without any additional information, it would be impossible to guess or estimate a range of values for the feature ""RMSD.""";The range of values for the feature RMSD is from 0 to 21.
384;F1;44963;physiochemical_protein;numeric;2392,05;40034,9;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: unknown
Maximum: unknown";The range of values for feature F1 is from 0 to 21.
385;F2;44963;physiochemical_protein;numeric;403,5;15312;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: unknown
Maximum: unknown";The minimum and maximum values for feature F2 are not provided in the dataset description. Without that information, it is not possible to determine the range of values for feature F2.
386;F3;44963;physiochemical_protein;numeric;0,0925;0,57769;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: Unknown
Maximum: Unknown";The range of values for feature F3 is from 0 to 1.
387;F4;44963;physiochemical_protein;numeric;10,3101;369,317;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: Unknown
Maximum: Unknown";The min and max values for feature F4 are not provided in the given dataset description.
388;F5;44963;physiochemical_protein;numeric;319490,2166;5472011,408;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: 
Maximum:";F5: [0, maximum value in the dataset]
389;F6;44963;physiochemical_protein;numeric;31,9704;598,408;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: Unknown
Maximum: Unknown";Based on the given description, the range of values for feature F6 is not provided.
390;F7;44963;physiochemical_protein;numeric;0;105948,17;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: Cannot determine without knowledge of the dataset.
Maximum: Cannot determine without knowledge of the dataset.";"Based on the given dataset description, the range of values for feature F7 (Euclidian distance) can be summarized as follows:

F7 (Euclidian distance): Minimum value = Unknown, Maximum value = Unknown"
391;F8;44963;physiochemical_protein;numeric;0;350;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;"Minimum: Unknown
Maximum: Unknown";The range of values for feature F8 is from the minimum value to the maximum value in the dataset. However, without specific information on the actual values, it is not possible to provide an accurate range for feature F8.
392;F9;44963;physiochemical_protein;numeric;15,228;55,3009;"**Data Description**

This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.

The goal of the dataset is to predict the size of the residue for a tertiary protein structure (a 3d protein structure). Once linked in the protein chain, an individual amino acid is called a residue. The target feature is root mean square error of the residue.

**Attribute Description**

1. *RMSD* - size of the residue
2. *F1* - total surface area
3. *F2* - non polar exposed area
4. *F3* - fractional area of exposed non polar residue
5. *F4* - fractional area of exposed non polar part of residue
6. *F5* - molecular mass weighted exposed area
7. *F6* - average deviation from standard exposed area of residue
8. *F7* - Euclidian distance
9. *F8* - secondary structure penalty
10. *F9* - Spacial Distribution constraints (N,K Value)";;min(F9), max(F9);The range of values for feature F9 is not provided in the given dataset description.
393;Label;44270;turing_course_binary_data;numeric;0;1;Turing Binary Classification Dataset (with normalised features);;"Minimum: 0
Maximum: 49";The minimum and maximum values for the feature 'Label' in the Turing Binary Classification Dataset are 0 and 1, respectively.
394;0;44270;turing_course_binary_data;numeric;-6,557421594;3,011165206;Turing Binary Classification Dataset (with normalised features);;The range of values for feature 0 is 0 to 49.;"min: 0
max: 49"
395;1;44270;turing_course_binary_data;numeric;-2,372782976;2,855915688;Turing Binary Classification Dataset (with normalised features);;"Minimum: 0
Maximum: 49";Since there is no specific feature mentioned, I cannot provide the range of values for a particular feature. Please specify the feature number or provide additional information.
396;2;44270;turing_course_binary_data;numeric;-2,743479089;2,841569729;Turing Binary Classification Dataset (with normalised features);;"Minimum: 0
Maximum: 49";Based on the given description, we need to identify the range of values for Feature 2 in the dataset. Since no specific information about the dataset is provided, we cannot determine the range.
397;3;44270;turing_course_binary_data;numeric;-3,046481894;3,362094633;Turing Binary Classification Dataset (with normalised features);;"Minimum: 0
Maximum: 49";The range of values for feature 3 in the Turing Binary Classification Dataset is [0, 49].
398;4;44270;turing_course_binary_data;numeric;-3,741947895;3,186604246;Turing Binary Classification Dataset (with normalised features);;"Minimum: 0
Maximum: 49";The range of values for feature 4 in the Turing Binary Classification Dataset is 0 to 49.
399;5;44270;turing_course_binary_data;numeric;-2,732906096;2,776735341;Turing Binary Classification Dataset (with normalised features);;"Minimum: 5
Maximum: 49";The minimum value for feature 5 in the Turing Binary Classification Dataset is 0 and the maximum value is 49.
400;6;44270;turing_course_binary_data;numeric;-2,917721763;3,610133993;Turing Binary Classification Dataset (with normalised features);;;The minimum and maximum values for feature 6 in the Turing Binary Classification Dataset (with normalized features) are not provided in the given information. Please provide the specific values for feature 6, and I will assist you in determining the range.
401;7;44270;turing_course_binary_data;numeric;-3,653304369;4,504961104;Turing Binary Classification Dataset (with normalised features);;;The minimum and maximum values for feature 7 in the Turing Binary Classification Dataset are not provided.
402;8;44270;turing_course_binary_data;numeric;-3,844105676;4,242365376;Turing Binary Classification Dataset (with normalised features);;;Min: 8, Max: 8
403;9;44270;turing_course_binary_data;numeric;-3,828703126;4,251090843;Turing Binary Classification Dataset (with normalised features);;;"Based on the given dataset and feature list, here is the range of values for feature 9 (index-based):

Min: 9
Max: 9"
404;10;44270;turing_course_binary_data;numeric;-3,650459474;3,638061759;Turing Binary Classification Dataset (with normalised features);;;The range of values for feature 10 is not provided in the dataset description.
405;11;44270;turing_course_binary_data;numeric;-3,780620312;4,589164322;Turing Binary Classification Dataset (with normalised features);;;The min and max values for feature 11 are not provided in the given dataset description.
406;12;44270;turing_course_binary_data;numeric;-3,979526402;3,57194333;Turing Binary Classification Dataset (with normalised features);;;To provide you with the range of values for feature 12, I would need the specific values or the dataset itself.
407;13;44270;turing_course_binary_data;numeric;-3,286132269;4,077405164;Turing Binary Classification Dataset (with normalised features);;;Sorry, but as an AI language model, I cannot access specific datasets or analyze their features directly. However, if given the dataset, you can easily determine the minimum and maximum values for feature 13 by examining the dataset yourself or by using data analysis tools such as Python's pandas library or Excel.
408;14;44270;turing_course_binary_data;numeric;-3,617918338;4,005752013;Turing Binary Classification Dataset (with normalised features);;;For the feature 14 in the Turing Binary Classification Dataset, the range of values is 0 to 1.
409;15;44270;turing_course_binary_data;numeric;-3,673686504;4,252638968;Turing Binary Classification Dataset (with normalised features);;;The range of values for Feature 15 is not provided in the dataset description.
410;16;44270;turing_course_binary_data;numeric;-3,434010475;4,175181662;Turing Binary Classification Dataset (with normalised features);;;The minimum and maximum values for feature 16 in the Turing Binary Classification Dataset are not provided.
411;17;44270;turing_course_binary_data;numeric;-3,798010779;4,242842645;Turing Binary Classification Dataset (with normalised features);;;Based on the given information, the range of values for feature 17 cannot be determined as the values for features 0 to 49 are not provided.
412;18;44270;turing_course_binary_data;numeric;-4,578622404;5,445014301;Turing Binary Classification Dataset (with normalised features);;;The minimum and maximum values for Feature 18 in the Turing Binary Classification Dataset are not provided in the given information.
413;19;44270;turing_course_binary_data;numeric;-3,903017364;3,484305959;Turing Binary Classification Dataset (with normalised features);;;Based on the given description and dataset, we cannot determine the range of values for feature 19 without any information about the values in the dataset.
414;20;44270;turing_course_binary_data;numeric;-4,085853144;4,922359252;Turing Binary Classification Dataset (with normalised features);;;Based on the information provided, it is not possible to determine the range of values for feature 20 without access to the dataset itself.
415;21;44270;turing_course_binary_data;numeric;-3,50383497;3,845776402;Turing Binary Classification Dataset (with normalised features);;;
416;22;44270;turing_course_binary_data;numeric;-3,577675751;4,256484991;Turing Binary Classification Dataset (with normalised features);;;
417;23;44270;turing_course_binary_data;numeric;-3,329408248;3,679952669;Turing Binary Classification Dataset (with normalised features);;;
418;24;44270;turing_course_binary_data;numeric;-4,364380779;4,706710848;Turing Binary Classification Dataset (with normalised features);;;
419;25;44270;turing_course_binary_data;numeric;-3,712648533;4,231201037;Turing Binary Classification Dataset (with normalised features);;;
420;26;44270;turing_course_binary_data;numeric;-3,806062263;4,211679237;Turing Binary Classification Dataset (with normalised features);;;
421;27;44270;turing_course_binary_data;numeric;-3,998474416;3,851805443;Turing Binary Classification Dataset (with normalised features);;;
422;28;44270;turing_course_binary_data;numeric;-3,510997723;5,056180979;Turing Binary Classification Dataset (with normalised features);;;
423;29;44270;turing_course_binary_data;numeric;-4,076485179;3,759742357;Turing Binary Classification Dataset (with normalised features);;;
424;30;44270;turing_course_binary_data;numeric;-4,05088874;4,205652967;Turing Binary Classification Dataset (with normalised features);;;
425;31;44270;turing_course_binary_data;numeric;-3,747531385;4,667299681;Turing Binary Classification Dataset (with normalised features);;;
426;32;44270;turing_course_binary_data;numeric;-4,407333724;4,363621871;Turing Binary Classification Dataset (with normalised features);;;
427;33;44270;turing_course_binary_data;numeric;-3,848385751;3,883111332;Turing Binary Classification Dataset (with normalised features);;;
428;34;44270;turing_course_binary_data;numeric;-3,357139721;3,421823042;Turing Binary Classification Dataset (with normalised features);;;
429;35;44270;turing_course_binary_data;numeric;-3,706062399;4,409661718;Turing Binary Classification Dataset (with normalised features);;;
430;36;44270;turing_course_binary_data;numeric;-3,832276621;3,495382871;Turing Binary Classification Dataset (with normalised features);;;
431;37;44270;turing_course_binary_data;numeric;-4,11389775;4,472711652;Turing Binary Classification Dataset (with normalised features);;;
432;38;44270;turing_course_binary_data;numeric;-3,829966402;4,090507141;Turing Binary Classification Dataset (with normalised features);;;
433;39;44270;turing_course_binary_data;numeric;-3,776095194;3,537766923;Turing Binary Classification Dataset (with normalised features);;;
434;40;44270;turing_course_binary_data;numeric;-3,81352595;4,298351398;Turing Binary Classification Dataset (with normalised features);;;
435;41;44270;turing_course_binary_data;numeric;-4,006245929;4,079524273;Turing Binary Classification Dataset (with normalised features);;;
436;42;44270;turing_course_binary_data;numeric;-3,937434802;4,310215174;Turing Binary Classification Dataset (with normalised features);;;
437;43;44270;turing_course_binary_data;numeric;-3,559484094;4,817294204;Turing Binary Classification Dataset (with normalised features);;;
438;44;44270;turing_course_binary_data;numeric;-3,550758803;4,516028592;Turing Binary Classification Dataset (with normalised features);;;
439;45;44270;turing_course_binary_data;numeric;-3,781448658;4,057196949;Turing Binary Classification Dataset (with normalised features);;;
440;46;44270;turing_course_binary_data;numeric;-3,71405855;4,377162701;Turing Binary Classification Dataset (with normalised features);;;
441;47;44270;turing_course_binary_data;numeric;-3,388576086;3,536917952;Turing Binary Classification Dataset (with normalised features);;;
442;48;44270;turing_course_binary_data;numeric;-4,004913848;4,18470256;Turing Binary Classification Dataset (with normalised features);;;
443;49;44270;turing_course_binary_data;numeric;-3,526862745;3,954275831;Turing Binary Classification Dataset (with normalised features);;;
444;temperature;44195;Weather;numeric;64;85;The weather problem is a tiny dataset that we will use repeatedly to illustrate machine learning methods. Entirely fictitious, it supposedly concerns the conditions that are suitable for playing some unspecified game. In general, instances in a dataset are characterized by the values of features, or attributes, that measure different aspects of the instance. In this case there are four attributes: outlook, temperature, humidity, and windy. The outcome is whether to play or not.;;;
445;humidity;44195;Weather;numeric;65;96;The weather problem is a tiny dataset that we will use repeatedly to illustrate machine learning methods. Entirely fictitious, it supposedly concerns the conditions that are suitable for playing some unspecified game. In general, instances in a dataset are characterized by the values of features, or attributes, that measure different aspects of the instance. In this case there are four attributes: outlook, temperature, humidity, and windy. The outcome is whether to play or not.;;;
446;paramList;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
447;cyclomaticNum;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
448;loopNum;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
449;nestingDegree;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
450;SLOC;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
451;ALOC;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
452;localVars;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
453;localPtrVars;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
454;pointerArgs;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
455;callees;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
456;callers;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
457;height;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
458;conditions;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
459;cmps;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
460;jmps;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
461;ptrAssn;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
462;lable;44150;VulNoneVul;numeric;0;1;Vulnerability Dataset For Binary Classification;;;
463;AveragePrice;43927;avocado_sales;numeric;0,44;3,25;Historical data on avocado prices and sales volume in multiple US markets. For this version Date column is dropped and month and day information in kept.;;;